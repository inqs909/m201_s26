---
title: |
  Simple <br>
  Logistic Regression
description: |
  Begins the discussion for logistic regression.
format:
  revealjs:
    width: 1200
    scrollable: true
    sc-sb-title: true
    footer: m201.inqs.info/lectures/6
    theme: [default, styles.scss]
    navigation-mode: vertical
    controls-layout: edges
    controls-tutorial: true
    slide-number: true
    pointer:
      pointerSize: 32
    incremental: false 
    chalkboard:
      theme: whiteboard
      chalk-width: 4
knitr:
  opts_chunk: 
    echo: true
    eval: true
    code-fold: true
    warnings: false
    comment: "#>" 
    
revealjs-plugins:
  - pointer
  
filters: 
  - reveal-header
  - code-fullscreen
  - reveal-auto-agenda

editor: source
---

## R Packages
```{r}
#| include: false
#| message: false

library(tidyverse)
library(rcistats)

theme_set(theme_bw() + 
            theme(
              axis.text.x = element_text(size = 24),
              axis.title = element_text(size = 30),
              plot.title = element_text(size = 48),
              strip.text = element_text(size = 20),
              legend.title = element_blank(),
              legend.text = element_text(size = 24)))


heart_disease <- kmed::heart
heart_disease$disease <- factor(ifelse(heart_disease$class == 0, "no", "yes")) 
heart_disease$sex <- ifelse(heart_disease$sex == T, "Male", "Female") |> factor()
heart_disease$cp <- ifelse(heart_disease$cp == 1, "Typical Angina",
                           ifelse(heart_disease$cp == 2, "Atypical Angina", 
                                  ifelse(heart_disease$cp == 3, "Non-anginal Pain", "Asymptomatic"))) |> 
                    factor(levels = c("Asymptomatic", "Non-anginal Pain", "Atypical Angina", "Typical Angina"))
heart_disease$fbs <- ifelse(heart_disease$fbs == T, "Fasting Blood Sugar >120" , "Fasting Blood Sugar <= 120") |> factor()
heart_disease$restecg <- ifelse(heart_disease$restecg == 0, "Normal",
                                ifelse(heart_disease$restecg == 1, "ST-T wave Abnormality", "Left Ventricular Hypertrophy")) |> 
                          factor(levels = c("Normal", "ST-T wave Abnormality", "Left Ventricular Hypertrophy"))
heart_disease$slope <- ifelse(heart_disease$slope == 1, "Positive Slope",
                              ifelse(heart_disease$slope == 2, "Zero Slope", "Negative Slope")) |> 
                              factor(levels = c("Zero Slope", "Positive Slope", "Negative Slope"))
heart_disease$thal <- ifelse(heart_disease$thal==3, "Normal",
                             ifelse(heart_disease$thal == 6, "Fixed Defect", "Reversible Defect")) |> 
                              factor(levels = c("Normal", "Fixed Defect", "Reversible Defect"))

```

-   rcistats
-   tidyverse


## Heart Disease Data

::: {.columns}
::: {.column}

### Variables of Interest

- `age`: Age of patient
- `disease`: Indicating if they have heart disease

:::
::: {.column}
![](img/heart_df.png){fig-alt="An image of a graph and a heart."}
:::
:::



# Modeling Binary Outcomes

## Modeling Binary Outcomes

```{r}
#| code-fold: false 
#| echo: false
# Fit logistic model
hdf <- heart_disease
hdf$plot <- ifelse(hdf$disease=="yes", 1, 0)
ggplot(hdf, aes(trestbps, plot)) +
  geom_point(alpha = 0.3) +
  stat_smooth(method = "glm",
              method.args = list(family = "binomial"),
              se = FALSE) +
  labs(x = NULL, y = NULL)
```



## Modeling Binary Outcomes

```{r}
#| code-fold: false
#| echo: false
# Fit logistic model
ggplot(hdf, aes(thalach, plot)) +
  geom_point(alpha = 0.3) +
  stat_smooth(method = "glm",
              method.args = list(family = "binomial"),
              se = FALSE) +
  labs(x = NULL, y = NULL)

```

## Mathematical Model

$$
\left(\begin{array}{c}
Yes \\
No
\end{array}\right) = \beta_0 + \beta_1X
$$

## Let ...

$$
Y = \left\{\begin{array}{cc}
1 & Yes \\
0 & No
\end{array}\right.
$$

## Construct a Model

$$
P\left(Y = 1\right) = \beta_0 + \beta_1X
$$

## Construct a Model

$$
P\left(Y = 1\right) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}
$$

## Construct a Model

$$
\frac{P(Y = 1)}{P(Y = 0)} = e^{\beta_0 + \beta_1X}
$$

where $\frac{P(Y = 1)}{P(Y = 0)}$ are considered the odds of observing $Y = 1$.

## The Logistic Model

$$
\log\left\{\frac{P(Y = 1)}{P(Y = 0)}\right\} = \beta_0 + \beta_1X
$$

## Notation

$$
\log\left\{\frac{P(Y = 1)}{P(Y = 0)}\right\} = 
\log\left\{odds\ of \ 1\right\} =
lo(1)
$$

# Logistic Regression

## Logistic Regression

Logistic Regression is used to model the association between a predictor and a **binary** outcome variable.

::: fragment
This is similar Linear Regression which models the association between a predictor and a **numerical** outcome variable.
:::

## Logistic Regression

Logistic Regression uses the logistic model to formulate the relationship between a predictor and the outcome.

::: fragment

More specifically, for an outcome of Y:

$$
Y = \left\{\begin{array}{cc}
1 & \text{Category 1} \\
0 & \text{Category 2}
\end{array}\right.
$$

The predictor variable will model the probability of observing category 1 ($P(Y=1)$)

:::


## Logistic Model

$$
\log\left\{\frac{P(Y = 1)}{P(Y = 0)}\right\} = \beta_0 + \beta_1X
$$

## Regression Coefficients $\beta$

The regression coefficients quantify how a specific predictor changes the odds of observing the first category of the outcome ($Y = 1$)

## Estimating $\beta$

To obtain the numerical value for $\beta$, denoted as $\hat \beta$, we will be finding the values of $\hat \beta$ that maximizes the likelihood function:

$$
L(\boldsymbol \beta) = \prod_{i=1}^n \left(\frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}\right)^{Y_i}\left(\frac{1}{1 + e^{\beta_0 + \beta_1X}}\right)^{1-Y_i}
$$

The likelihood function can be thought as the probability of observing the entire data set. Therefore, we want to choose the values the $\beta_0$ and $\beta_1$ that will result in the highest probability of observing the data.


## Estimated Parameters

The values you obtain ($\hat \beta$) tell you the relationship between the a predictor variable and the log odds of observing the first category of the outcome $Y=1$.

::: fragment
Exponentiating the estimate ($e^{\hat \beta}$) will give you the relationship between a predictor variable and the odds of observing the first category of the outcome $Y=1$.
:::

## Interpreting $\hat \beta$

For a continuous predictor variable:

As X increases by 1 unit, the odds of observing the first category ($Y = 1$) increases by a factor of $e^{\hat\beta}$.

# Logistic Regression in R

## Logistic Regression in R

```r
xglm <- glm(Y ~ X,
            data = DATA,
            family = binomial())
xglm
```

- `DATA`: Name of the data frame
- `Y`: Outcome Variable of Interest in the data frame `DATA`
- `X`: Predictor Variable in the data frame `DATA`


## Model Information

The `model_info` function can provide basic information about a linear or logistic regression model. 


::: fragment
It can provide what is being modeled (yes, 1) in logistic regression.
:::


::: fragment
It can provide basic info of the predictor variables.
:::

## Model Information in R

```r
model_info(MODEL)
```

- `MODEL`: fitted model from `lm()` or `glm`


## Example

Modelling `disease` by `age`: 

```{r}
xglm <- glm(disease ~ cp + age + sex + restecg + fbs,
            data = heart_disease,
            family = binomial())
model_info(xglm)
xglm
```

##


$$
lo(disease) = -3.0512 + 0.0529 (age)
$$


## Interpretation

$$
lo(disease) = -3.0512 + 0.0529 (age)
$$



```{r}
exp(0.05291)
```

::: fragment
As age increases by 1 year, the odds of having heart disease increases by a factor of 1.054.
:::

# Prediction with Models

## Working with probabilities

As you can see, working with odds may be unintuitive for the average person. It will be better to predict the probability and display those results to individuals.

## Predicting Probability


$$
\hat P\left(Y = 1\right) = \frac{e^{\hat\beta_0 + \hat\beta_1X}}{1 + e^{\hat\beta_0 + \hat\beta_1X}}
$$

## Prediction in R

```r
xglm <- glm(Y ~ X,
            data = DATA,
            family = binomial())
ndf <- data.frame(X = VAL)
predict(xglm,
        ndf,
        type = "response")
```


## Example 1

Predict the probability of having heart disease for a patient who is 40 years old.

```{r}
xglm <- glm(disease ~ age,
            data = heart_disease,
            family = binomial())
ndf <- data.frame(age = 40)
predict(xglm, ndf, type = "response")
```


## Example 2

Predict the probability of having heart disease for a patient who is 55 years old.

```{r}
xglm <- glm(disease ~ age,
            data = heart_disease,
            family = binomial())
ndf <- data.frame(age = 55)
predict(xglm, ndf, type = "response")
```

## Example 3

Predict the probability of having heart disease for a patient who is 70 years old.

```{r}
xglm <- glm(disease ~ age,
            data = heart_disease,
            family = binomial())
ndf <- data.frame(age = 70)
predict(xglm, ndf, type = "response")
```

## Example

| Age | 40 | 55 | 70 |
|:-|:-|:-|:-|
| Probabiltiy | 28.2% | 46.5% | 65.8% |




