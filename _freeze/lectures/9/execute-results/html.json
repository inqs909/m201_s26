{
  "hash": "f323ecd8b14f45d03e9f6454c376951a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Sampling Distribution\"\ndescription: |\n  Discuss for sampling distributions.\nformat:\n  revealjs:\n    width: 1200\n    scrollable: true\n    sc-sb-title: true\n    footer: m201.inqs.info/lectures/9\n    theme: [default, styles.scss]\n    navigation-mode: vertical\n    controls-layout: edges\n    controls-tutorial: true\n    slide-number: true\n    pointer:\n      pointerSize: 32\n    incremental: false \n    chalkboard:\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    code-fold: true\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  \nfilters:\n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\n\neditor: source\n---\n\n\n\n# Sampling Distribution\n\n## Sampling Distribution\n\nSampling Distribution is the idea that the statistics that you generate (slopes and intercepts) have their own data generation process.\n\n::: fragment\nIn other words, the numerical values you obtain from the `lm` and `glm` function can be different if we got a different data set.\n:::\n\n::: fragment\nSome values will be more common than others. Because of this, they have their own data generating process, like the outcome of interest has it's own data generating process.\n:::\n\n## Sampling Distributions\n\n- Distribution of a statistic over repeated samples\n\n- Different Samples yield different statistics\n\n::: notes\nIf we took many samples, the statistics (like mean) would vary. Their distribution helps us quantify uncertainty.\n:::\n\n## Standard Error\n\nThe Standard Error (SE) is the standard deviation of a statistic itself.\n\n::: fragment\nSE tells us how much a statistic varies from sample to sample. Smaller SE = more precision.\n:::\n\n\n\n## Modelling the Data\n\n$$\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n$$ \n\n- $Y_i$: Outcome data \n- $X_i$: Predictor data \n- $\\beta_0, \\beta_1$: parameters \n- $\\varepsilon_i$: error term\n\n## Error Term\n\n$$\n\\varepsilon_i \\sim DGP\n$$\n\n::: notes\n-   The error terms forces the outcome variable to be different from the mathematical model.\n-   The numbers being generated are random and cannot be predicted.\n:::\n\n## Randomness Effect\n\nThe randomness effect is a sampling phenomenom where you will get different samples every time you sample a population.\n\n::: fragment\n\nGetting different samples means you will get different statistics.\n\n:::\n\n\n::: fragment\n\nThese statistics will have a distribution on their own.\n\n::: \n\n## Randomness Effect 1\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Randomness Effect 2\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## Randomness Effect 3\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Randomness Effect 4\n\n\n::: {.cell ecode-fold='true'}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Randomness Effect 5\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nx <- rnorm(1000)\ny <- 4 + 5 * x + rnorm(1000)\nbb <- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8) \n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n# Simulating Unicorns\n\n## Simulating Unicorns\n\nTo better understand the variation in statistics, let's simulate a data set of unicorn characteristics to visualize and understand the variation.\n\n::: fragment\nWe will simulate a data set using the `unicorns` function and only we need to specify how many unicorns you want to simulate.\n:::\n\n## Simulating Unicorn Data\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nunicorns(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>    Unicorn_ID Age      Gender  Color Type_of_Unicorn Type_of_Horn Horn_Length\n#> 1           1  17        Male  Black         Rainbow         Opal    5.159713\n#> 2           2   3     Agender  White         Rainbow         Opal    5.349291\n#> 3           3   3        Male   Gold           Jewel         Opal    4.921934\n#> 4           4  14  Non-binary Silver           Ruvas         Opal    5.142722\n#> 5           5  14        Male  Black           Jewel   Aquamarine    5.014010\n#> 6           6  18  Non-binary  White           Ember         Opal    4.575182\n#> 7           7  13     Agender  Brown           Ember   Aquamarine    4.652912\n#> 8           8   9        Male  White           Ruvas         Opal    4.804055\n#> 9           9  19 Genderfluid  Black         Rainbow   Aquamarine    4.728726\n#> 10         10   7     Agender   Gold         Rainbow         Opal    5.406721\n#>    Horn_Strength    Weight Health_Score Personality_Score Magical_Score\n#> 1       31.23058 125.01323            8        0.08726362      11160.81\n#> 2       26.08787 139.13117            5        1.06409501      10763.96\n#> 3       28.40993 138.40186            9        0.06998508      10812.65\n#> 4       25.25602 123.27227            2        0.43582575      11124.84\n#> 5       28.09037 182.68155            6        0.36849131      11085.01\n#> 6       28.21399 115.08631            5        1.26001491      11219.71\n#> 7       31.07708  93.28854            1        1.56113264      11039.32\n#> 8       28.02443 158.23565            8        0.13079778      10966.47\n#> 9       28.15657 103.28272            9        0.73177954      11196.21\n#> 10      27.23401  99.24704            2        0.02588088      10908.71\n#>    Elusiveness_Score Gentleness_Score Nature_Score\n#> 1           39.92823         4.022313     967.4888\n#> 2           41.18782        -0.306242     917.8104\n#> 3           36.80664        30.182490     923.7942\n#> 4           32.05847        11.572373     963.0666\n#> 5           32.26507        41.121799     957.6649\n#> 6           34.05079        38.861432     974.2426\n#> 7           33.88469        22.589412     952.2323\n#> 8           31.70641        31.826690     942.7393\n#> 9           29.49732        25.123159     971.1747\n#> 10          35.27492        55.037350     935.9875\n```\n\n\n:::\n:::\n\n\n## Unicorn Data Variables\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nnames(unicorns(10))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>  [1] \"Unicorn_ID\"        \"Age\"               \"Gender\"           \n#>  [4] \"Color\"             \"Type_of_Unicorn\"   \"Type_of_Horn\"     \n#>  [7] \"Horn_Length\"       \"Horn_Strength\"     \"Weight\"           \n#> [10] \"Health_Score\"      \"Personality_Score\" \"Magical_Score\"    \n#> [13] \"Elusiveness_Score\" \"Gentleness_Score\"  \"Nature_Score\"\n```\n\n\n:::\n:::\n\n\nWe will only look at `Magical_Score` and `Nature_Score`.\n\n## Magical and Nature Score\n\n$$\nMagical =  3423 + 8 \\times Nature + \\varepsilon\n$$ \n\n$$\n\\varepsilon \\sim N(0, 3.24)\n$$\n\n## Simulating $N(0, 3.24)$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nrnorm(1, 0, sqrt(3.24))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> [1] 0.03355853\n```\n\n\n:::\n:::\n\n\n## Collecting\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nunicorns(10) |> select(Nature_Score, Magical_Score)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>    Nature_Score Magical_Score\n#> 1      956.8501      11079.18\n#> 2      948.2833      11010.02\n#> 3      922.2285      10801.39\n#> 4      950.0886      11023.15\n#> 5      919.9003      10782.13\n#> 6      940.7481      10950.28\n#> 7      936.7638      10917.78\n#> 8      957.4549      11083.05\n#> 9      951.0337      11028.50\n#> 10     933.6375      10889.47\n```\n\n\n:::\n:::\n\n\n## DGP of Magical Score 1\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(unicorns(500), aes(Magical_Score)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## DGP of Magical Score 2\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(unicorns(500), aes(Magical_Score)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## Estimating $\\beta_1$ via `lm`\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu1 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u1)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3428.325         7.994\n```\n\n\n:::\n:::\n\n\n## Collecting a new sample\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu2 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u2)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3419.678         8.004\n```\n\n\n:::\n:::\n\n\n## Collecting a new sample\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu3 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u3)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3425.272         7.998\n```\n\n\n:::\n:::\n\n\n## Collecting a new sample\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nu4 <- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> lm(formula = Magical_Score ~ Nature_Score, data = u4)\n#> \n#> Coefficients:\n#>  (Intercept)  Nature_Score  \n#>     3423.582         7.999\n```\n\n\n:::\n:::\n\n\n## Replicating Processes\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nreplicate(N, CODE)\n```\n:::\n\n\n\n- `N`: number of times to repeat a process \n- `CODE`: what is to repeated\n\n\n## Extracting $\\hat \\beta$ Coefficeints\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nb(MODEL, INDEX)\n```\n:::\n\n\n\n- `MODEL`: a model that can be used to extract components\n- `INDEX`: which component do you want to use\n    - `0`: Intercept\n    - `1`: first slope\n    - `2`: second slope\n    - `...`\n\n\n\n## Collecting 1000 Samples\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbetas <- replicate(1000,\n                   b(lm(Magical_Score ~ Nature_Score, unicorns(500)), 1))\n\nbetas\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>    [1] 7.999058 8.001284 8.003015 8.001723 7.999699 7.999543 8.001061 8.005151\n#>    [9] 7.997525 7.995141 7.995543 8.001705 7.996154 8.009942 7.995987 8.005716\n#>   [17] 8.001538 8.001452 8.003764 8.003436 7.994475 8.002542 8.004248 8.002921\n#>   [25] 7.995876 8.004102 8.007194 8.001239 7.997467 7.995963 8.008214 7.998190\n#>   [33] 7.994710 8.002575 8.003458 7.991704 8.001514 7.999528 7.995102 7.999667\n#>   [41] 7.992973 8.002481 8.000392 8.003299 7.997944 7.992422 8.003528 8.002389\n#>   [49] 8.005239 8.008222 7.996733 8.004356 8.000755 8.000506 7.996979 7.993738\n#>   [57] 7.994851 7.990159 7.990023 7.996209 7.996620 7.998136 7.999115 8.009377\n#>   [65] 8.000606 8.004656 8.000492 7.999073 7.993028 8.000835 8.008084 8.000809\n#>   [73] 8.007108 8.007785 8.006152 7.991655 8.005789 8.000456 8.004318 8.002491\n#>   [81] 7.992786 7.996776 8.003359 7.997009 7.997196 7.997317 8.003630 7.994337\n#>   [89] 8.001114 8.000243 7.995484 7.999136 8.003271 8.001934 8.003030 7.995497\n#>   [97] 7.998813 7.997768 8.002609 7.994512 8.001277 8.000454 8.000431 8.007002\n#>  [105] 8.007032 7.998614 8.001930 8.000572 7.997554 8.007711 8.002343 7.997769\n#>  [113] 7.994473 7.997757 8.004009 7.999483 7.996561 8.004363 7.999075 8.001202\n#>  [121] 7.998125 7.994212 7.991159 8.005360 8.005407 8.000977 8.003288 8.002088\n#>  [129] 7.996428 8.001811 7.991212 7.996278 7.996554 7.996924 8.000239 8.003165\n#>  [137] 7.997931 8.001342 8.004769 8.003970 8.000112 7.996665 7.996578 8.003052\n#>  [145] 7.998709 8.003077 7.997980 8.003831 8.000676 7.997772 8.002517 7.994271\n#>  [153] 7.998639 7.999209 8.006683 8.003302 7.997694 7.998205 7.998531 8.000597\n#>  [161] 8.000580 8.001941 7.996421 7.997185 8.006902 7.994370 8.002982 8.001087\n#>  [169] 7.997271 8.002311 7.999462 8.000321 7.995683 7.999430 8.001817 8.000594\n#>  [177] 7.996918 8.005227 7.995079 8.008535 7.993402 8.001760 7.997172 7.999890\n#>  [185] 8.000010 7.995641 8.000674 8.002143 7.998532 7.988820 8.007411 8.007531\n#>  [193] 8.005508 8.002937 7.996615 8.000870 7.998277 8.000077 8.005246 7.991536\n#>  [201] 7.999563 8.005798 7.998051 8.002029 7.997753 8.007735 7.998467 8.004218\n#>  [209] 7.997969 7.998549 7.995732 8.011966 8.001469 8.003811 7.996074 7.997296\n#>  [217] 8.001260 8.002587 8.001834 7.994674 8.002200 8.008143 7.999542 8.000206\n#>  [225] 7.993937 8.004645 7.997159 7.991832 7.994914 8.003535 7.991969 7.998527\n#>  [233] 7.997504 8.002881 7.999675 8.003099 8.001533 7.991417 8.000721 7.999079\n#>  [241] 7.996456 7.999168 7.997706 7.994879 8.000442 7.994722 8.003079 8.006139\n#>  [249] 8.004305 8.002659 8.006830 8.000450 8.000284 7.999645 7.998924 7.999971\n#>  [257] 7.996167 7.997762 7.993058 8.000538 7.999176 8.002347 7.998030 7.997619\n#>  [265] 8.000277 7.999608 7.994550 8.006820 8.001762 8.001006 8.001449 7.998368\n#>  [273] 8.001002 7.995714 8.002392 7.996623 8.002158 8.003643 8.000869 7.999366\n#>  [281] 7.997883 7.999263 7.998924 8.009048 8.004146 8.000059 7.995638 7.994283\n#>  [289] 7.999022 8.002256 7.995999 8.004061 8.001601 7.996447 7.998409 7.996253\n#>  [297] 7.995793 7.999310 8.004006 8.000035 8.001703 8.004500 8.001887 7.997558\n#>  [305] 8.005465 7.992635 8.002396 8.000338 8.000861 7.996008 7.999460 7.995250\n#>  [313] 7.991951 8.002691 7.998730 7.996647 7.997104 7.998513 7.994552 8.001386\n#>  [321] 8.002563 7.992235 7.999936 7.996917 7.999319 7.994159 8.002237 7.993558\n#>  [329] 7.996539 8.008284 7.999505 8.001737 7.998547 7.996291 7.998856 7.993456\n#>  [337] 8.000052 7.998744 8.004127 8.001825 8.000926 7.999243 8.001372 8.002686\n#>  [345] 8.002894 8.002896 7.999451 7.998944 7.996182 7.993538 8.004601 8.002539\n#>  [353] 7.994070 7.993740 7.997797 7.997078 8.014582 8.001647 8.001115 7.997676\n#>  [361] 8.000668 7.996279 8.000493 7.995563 7.995122 7.998903 8.006546 8.004565\n#>  [369] 7.997873 8.001463 7.994824 8.006142 8.004564 7.995225 8.000325 7.996172\n#>  [377] 8.004171 7.998432 8.005243 7.998182 7.999072 8.000374 8.003688 7.993503\n#>  [385] 8.001923 8.003760 8.006840 7.997050 7.997808 7.994031 7.996361 8.001114\n#>  [393] 8.001058 8.001174 7.994258 8.001375 7.994453 8.005230 7.992934 8.010133\n#>  [401] 7.999092 7.998358 8.001593 7.999249 8.000906 8.000587 8.003999 8.006982\n#>  [409] 7.997466 8.003016 8.005171 7.997777 8.006813 7.997522 8.002658 8.001711\n#>  [417] 7.998327 7.996098 8.000193 7.999975 7.998561 7.995167 8.001802 7.997900\n#>  [425] 8.004488 7.997693 8.004759 8.002457 7.995524 7.995009 8.003116 7.995572\n#>  [433] 8.002136 7.998903 8.007351 7.998827 8.003266 7.998501 7.994203 8.001189\n#>  [441] 8.001185 8.003555 7.997101 8.005736 7.994012 8.006925 7.991076 7.996301\n#>  [449] 8.000865 7.990773 8.001256 7.996274 7.999323 7.999623 8.001862 7.997042\n#>  [457] 7.999672 8.005188 7.995078 8.001565 8.003295 7.997779 8.002517 7.998173\n#>  [465] 8.001294 8.000150 7.999919 8.001849 7.993644 7.999581 7.995539 8.001133\n#>  [473] 7.999658 8.004184 7.997780 8.001612 7.999548 7.998350 8.001565 8.000954\n#>  [481] 7.997035 7.997367 8.007418 8.009484 8.003337 8.002156 7.998549 8.001630\n#>  [489] 7.995070 7.995497 7.995287 7.997601 8.006728 7.993364 8.002292 7.992517\n#>  [497] 8.005762 8.002836 7.999774 7.998518 7.991102 7.987547 7.997824 8.004201\n#>  [505] 7.999396 7.994614 7.999456 8.006582 8.002954 7.999257 7.989188 8.002287\n#>  [513] 8.001923 7.997810 7.998598 7.998266 8.003530 8.007433 8.001367 7.997604\n#>  [521] 7.995953 8.002879 8.000786 8.003829 8.001978 8.003294 7.997018 8.002396\n#>  [529] 8.002861 8.003505 7.997858 8.001123 8.003277 7.994884 8.003748 8.000247\n#>  [537] 7.999567 8.004518 7.997606 8.001901 7.999018 7.991830 8.004167 8.000956\n#>  [545] 7.998679 7.999544 7.998674 8.002894 8.002242 8.000422 8.006436 7.996685\n#>  [553] 8.002349 7.997142 7.998196 8.000023 8.000089 7.994089 7.991204 7.999791\n#>  [561] 8.001851 8.005043 8.000078 8.003605 8.002007 8.002835 8.001856 8.000942\n#>  [569] 8.003150 8.006647 8.003365 7.993733 8.002648 8.003740 8.003218 7.998067\n#>  [577] 7.998627 7.999217 7.993779 8.000631 7.997666 7.999035 8.002223 8.006505\n#>  [585] 7.996960 7.997865 7.989457 7.994748 7.999920 7.999279 7.997390 7.999724\n#>  [593] 8.001418 8.003385 7.997233 7.999908 8.006641 7.989428 7.999539 8.000685\n#>  [601] 7.992663 7.996205 7.998423 8.004342 7.998067 8.001334 7.994251 8.001688\n#>  [609] 8.000099 8.002666 7.996468 7.996076 7.999824 8.003579 7.996624 8.000029\n#>  [617] 7.996224 8.001286 7.996299 7.999248 7.998108 8.000611 7.998115 8.009404\n#>  [625] 8.007464 8.005877 7.995433 7.997385 7.997233 7.995741 7.993181 7.999818\n#>  [633] 7.999051 7.992966 7.994716 7.995958 7.992526 7.997139 8.004885 7.996549\n#>  [641] 8.003502 7.998208 8.003092 8.003858 7.998842 8.004271 7.996402 8.002304\n#>  [649] 8.003088 7.996906 7.998476 7.999784 7.991926 7.997565 7.996576 8.003679\n#>  [657] 7.999474 7.993416 7.999013 8.005057 8.006308 7.997966 7.995530 7.995466\n#>  [665] 7.997778 7.998722 7.996312 8.005064 8.002665 7.999747 8.002369 8.001909\n#>  [673] 7.998768 7.993312 8.009708 8.007825 8.001872 8.003068 7.995594 7.996707\n#>  [681] 8.000692 7.995426 7.990401 7.997331 8.002796 7.995617 7.996151 7.997422\n#>  [689] 8.004505 8.001209 7.999305 7.993160 8.001707 7.999278 8.000740 8.004560\n#>  [697] 7.998549 7.992744 8.007158 8.001917 7.999354 7.995240 8.001993 8.002193\n#>  [705] 8.001069 8.003675 8.003114 7.998721 7.996229 7.995959 8.001464 7.997327\n#>  [713] 8.001808 8.001485 8.000135 8.003725 7.996906 7.995795 8.004432 8.003387\n#>  [721] 7.995073 8.004583 8.003632 8.002961 7.998372 8.000008 7.996090 7.999222\n#>  [729] 7.992302 8.009816 8.006600 8.006073 8.001339 8.002203 7.995103 8.000046\n#>  [737] 7.999748 8.000201 8.003152 7.995092 8.002624 8.006290 8.000052 7.993177\n#>  [745] 7.993960 7.996433 8.000231 8.005083 8.000079 7.991971 8.000361 8.003407\n#>  [753] 7.999660 7.997946 8.000384 8.003196 8.002482 8.004890 7.996217 8.001067\n#>  [761] 7.999418 7.998358 7.999793 8.002724 8.003416 8.002396 8.005964 7.992279\n#>  [769] 7.995484 7.997145 8.002313 7.999607 8.001061 8.006991 8.008765 8.000137\n#>  [777] 8.002408 8.004433 7.994796 7.999589 8.007430 7.999473 7.994223 8.003615\n#>  [785] 8.003587 7.995608 8.004619 8.004791 8.001599 8.002554 7.999553 7.992444\n#>  [793] 7.998295 7.997197 7.997708 8.005425 8.001348 7.994398 7.993650 8.004764\n#>  [801] 8.000935 7.996868 8.004280 8.002403 8.002437 8.005270 7.996759 7.999344\n#>  [809] 7.992111 8.003905 7.997932 7.995000 8.001564 8.003305 8.002611 7.999324\n#>  [817] 7.999733 7.999670 7.998837 7.998315 8.000604 7.998923 7.997720 8.000344\n#>  [825] 7.991621 7.989166 8.005709 8.002415 7.998451 8.003340 8.005756 7.997744\n#>  [833] 7.997788 7.996084 7.995332 8.003393 7.997915 8.009244 7.999019 7.999166\n#>  [841] 8.008514 8.003047 7.993680 8.003005 8.005246 7.996513 7.998261 8.002620\n#>  [849] 7.999489 7.999166 8.000550 8.002233 7.992652 7.992870 8.003923 7.997194\n#>  [857] 8.003922 7.995512 7.998784 7.999649 8.006221 7.998029 7.999679 7.999664\n#>  [865] 8.002463 8.003889 7.997776 7.999038 7.998881 7.995224 7.996219 7.999594\n#>  [873] 8.002716 7.998797 7.990529 7.998840 7.996077 8.000823 8.006255 8.000982\n#>  [881] 7.994779 7.997413 7.999029 7.994881 7.997782 8.005269 8.003427 7.998489\n#>  [889] 8.000028 7.999089 7.998329 7.988976 8.004076 8.000302 7.996289 8.001408\n#>  [897] 8.001290 7.995535 7.993238 7.999515 7.997286 8.000420 7.999755 8.001753\n#>  [905] 7.996435 8.001111 8.003317 7.995838 8.005864 8.004819 8.006673 7.994467\n#>  [913] 7.995361 8.002492 7.997888 7.994674 8.002783 8.002403 7.998158 7.997431\n#>  [921] 8.000297 8.001005 8.001094 8.003566 7.993891 7.997606 7.999400 8.001073\n#>  [929] 7.997651 8.001826 8.002996 7.997653 8.001373 7.993195 7.996600 8.003369\n#>  [937] 8.004152 8.001956 8.001218 8.000501 7.998706 8.002251 7.995792 8.001860\n#>  [945] 8.004996 7.993354 7.997343 8.000216 7.994800 8.003021 8.006246 8.002810\n#>  [953] 7.996064 7.999405 7.998814 8.002066 8.000198 7.991919 8.003170 8.003142\n#>  [961] 8.004331 7.997680 7.998687 7.994020 7.998892 8.001936 8.005735 7.996316\n#>  [969] 8.002397 8.001961 8.001180 8.005278 7.997247 7.994314 8.004344 7.999017\n#>  [977] 8.000006 7.998309 8.001975 7.998606 8.003615 7.996396 8.002158 8.002094\n#>  [985] 7.999069 7.999147 8.000810 7.999297 7.995871 8.000381 7.995799 7.993958\n#>  [993] 8.003294 8.002257 7.997751 7.994004 7.996365 8.003833 8.000969 8.002762\n```\n\n\n:::\n:::\n\n\n## Distributions of $\\hat \\beta_1$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(data.frame(x = betas), aes(x = x)) +\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n# Central Limit Theorem\n\n## Central Limit Theorem\n\nThe Central Limit Theorem (CLT) is a fundamental concept in probability and statistics. It states that the distribution of the sum (or average) of a large number of independent, identically distributed (i.i.d.) random variables will be approximately normal, regardless of the underlying distribution of those individual variables.\n\n\n## Formal Statement of the CLT\n\n- Let $X_1$, $X_2$, ..., $X_n$ be a sequence of i.i.d. random variables with mean $\\mu$ and standard deviation $\\sigma$.\n- Let $\\bar X$ be the sample mean of these variables.\n- As n (the sample size) approaches infinity, the distribution of $\\bar X$ approaches a normal distribution with:\n    - Mean: $\\mu$\n    - Standard Deviation: $\\sigma/\\sqrt{n}$\n\n## CLT Example\n\n- **Imagine:** You're flipping a fair coin many times. \n    - Each flip is an independent event (heads or tails).\n    - The probability of heads/tails is the same for each flip.\n- **Now:** Calculate the average number of heads after each set of 10 flips, then each set of 100 flips, and so on.\n- **Observation:** As the number of flips in each set increases, the distribution of these averages will start to resemble a bell-shaped curve (normal distribution), even though the individual coin flips are not normally distributed.\n\n## CLT Implications\n\n- **Approximation:** Even if the underlying data is not normally distributed, the distribution of the sample means will be approximately normal for large enough sample sizes.\n- **Practical Rule:** A common rule of thumb is that the sample size (n) should be at least 30 for the CLT to provide a good approximation. However, this is a guideline, and the actual required sample size can vary depending on the shape of the original distribution.\n\n## Normal Example $n = 10$\n\nSimulating 500 samples of size 10 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#rnorm(10, 5, 2)\nsims <- replicate(500, rnorm(10, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(10)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n## Normal Example $n = 30$\n\nSimulating 500 samples of size 30 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# rnorm(30, 5, 2)\nsims <- replicate(500, rnorm(30, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(30)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n## Normal Example $n = 50$\n\nSimulating 500 samples of size 50 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# rnorm(50, 5, 2)\nsims <- replicate(500, rnorm(50, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(50)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n## Normal Example $n = 100$\n\nSimulating 500 samples of size 100 from a normal distribution with mean 5 and standard deviation of 2.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# rnorm(100, 5, 2)\nsims <- replicate(500, rnorm(100, 5, 2))\nsims_mean <- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(100)),\n                col = \"red\")\n```\n\n::: {.cell-output-display}\n![](9_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n# Common Sampling Distributions\n\n## Normal DGP\n\nWhen the data is said to have a normal distribution (DGP), there are special properties with both the mean and standard deviation, regardless of sample size.\n\n## Statistics\n\n::: {.columns}\n::: {.column}\n**Mean**\n$$\n\\bar X = \\sum ^n_{i=1} X_i\n$$\n:::\n::: {.column}\n**Standard Deviation**\n$$\ns^2 = \\frac{1}{n}\\sum ^n_{i=1} (X_i - \\bar X)^2\n$$\n\n:::\n:::\n\n\n## When the true $\\mu$ and $\\sigma$ are known\nA data sample of size $n$ is generated from:\n$$\nX_i \\sim N(\\mu, \\sigma)\n$$\n\n## Distribution of $\\bar X$\n\n$$\n\\bar X \\sim N(\\mu, \\sigma/\\sqrt{n})\n$$\n\n## Distribution of Z\n\n$$\nZ = \\frac{\\bar X - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n$$\n\n## When the true $\\mu$ and $\\sigma$ are unknown\nA data sample of size $n$ is generated from:\n$$\nX_i \\sim N(\\mu, \\sigma)\n$$\n\n## Distribution of $s^2$ (unknown $\\mu$)\n$$\n(n-1)s^2/\\sigma^2 \\sim \\chi^2(n-1)\n$$\n\n## Distribution of Z (unknown $\\sigma$)\n\n$$\nZ = \\frac{\\bar X - \\mu}{\\sigma/\\sqrt{n}} \\rightarrow \\frac{\\bar X - \\mu}{s/\\sqrt{n}} \\sim t(n-1)\n$$\n\n\n\n# Sampling Distributions for Regression Models\n\n\n## Regression Coefficients\n\nThe estimates of regression coefficients (slopes) have a distribution!\n\n::: fragment\n\nBased on our outcome, we will have 2 different distributions to work with: Normal or t.\n\n:::\n\n## Linear Regression\n\n$$\n\\frac{\\hat\\beta_j-\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p^\\prime}\n$$\n\n\n## $\\beta_j = 0$\n\n$$\n\\frac{\\hat\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p^\\prime}\n$$\n\n\n## Logistic Regression\n\n$$\n\\frac{\\hat\\beta_j - \\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1)\n$$\n\n## $\\beta_j = 0$\n\n$$\n\\frac{\\hat\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1)\n$$\n\n# Scientific Notation\n\n## Scientific Notation\n\nWe often work with **very large** or **very small** numbers.\n\n- Earth → Sun distance: 150,000,000 km  \n- Diameter of a hydrogen atom: 0.0000000001 m\n\nProblems with standard form:\n\n- Hard to **read**\n- Easy to **copy wrong**\n- Difficult to **compare**\n\n**Scientific notation** makes numbers compact and standardized.\n\n\n## The Scientific Notation Form\n\nA number is in scientific notation if:\n\n$$\na \\times 10^n\n$$\n\nwhere:\n\n- $a$ is **at least 1 and less than 10**\n- $n$ is an integer (positive, negative, or zero)\n- $10^n$ is a **power of ten**\n\n\n## Example: Large Number\n\nWrite 45,000 in scientific notation.\n\nMove decimal:\n\n$$\n45000 \\rightarrow 4.5\n$$\n\nMoved **4 places left**:\n\n$$\n4.5 \\times 10^4\n$$\n\n## Example: Small Number\n\nWrite 0.00072 in scientific notation.\n\nMove decimal:\n\n$$\n0.00072 \\rightarrow 7.2\n$$\n\nMoved **4 places right**:\n\n$$\n7.2 \\times 10^{-4}\n$$\n\n\n## Understanding Positive Exponent\n\nPositive exponents → big numbers\n\n- $10^3 = 1{,}000$\n- $10^6 = 1{,}000{,}000$\n\nExample:\n\n$$\n2.1 \\times 10^6 = 2{,}100{,}000\n$$\n\n\n## Understanding Negative Exponent\n\nNegative exponents → small numbers\n\n- $10^{-2} = 0.01$\n- $10^{-5} = 0.00001$\n\nExample:\n\n$$\n4.3 \\times 10^{-3} = 0.0043\n$$\n\n\n## Converting Back to Standard Form\n\nRule:\n\n- $10^{+n}$: move decimal **right** $n$ places\n- $10^{-n}$: move decimal **left** $n$ places\n\n\n## Convert Example (Positive Exponent)\n\n$$\n6.2 \\times 10^5\n$$\n\nMove decimal 5 places right:\n\n$$\n620{,}000\n$$\n\n---\n\n## Convert Example (Negative Exponent)\n\n$$\n9.1 \\times 10^{-4}\n$$\n\nMove decimal 4 places left:\n\n$$\n0.00091\n$$\n\n\n## Comparing Numbers in Scientific Notation\n\nStep 1: Compare exponents\n\n- Bigger exponent → bigger number\n\nStep 2: If exponents match, compare coefficients $a$\n\nExample:\n\n- $3.2 \\times 10^5$\n- $7.1 \\times 10^4$\n\nSince $10^5 > 10^4$, the first number is larger.\n\n\n\n## Scientific Notation in R\n\nR often displays very large/small numbers using **`e` notation**.\n\n$$\na \\times 10^n \\quad \\text{is shown as} \\quad a\\text{e}n\n$$\n\nExamples:\n\n- `3e+06` means $3 \\times 10^6$\n- `4.5e-04` means $4.5 \\times 10^{-4}$\n\n\n",
    "supporting": [
      "9_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}