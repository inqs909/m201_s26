---
title: "Statistical Inference"
subtitle: "Group Model Inference"
description: |
  Testing the difference in groups.

format:
  revealjs:
    width: 1200
    scrollable: true
    sc-sb-title: true
    footer: m201.inqs.info/lectures/11
    theme: [default, styles.scss]
    navigation-mode: vertical
    controls-layout: edges
    controls-tutorial: true
    slide-number: true
    pointer:
      pointerSize: 32
    incremental: false 
    chalkboard:
      theme: whiteboard
      chalk-width: 4
knitr:
  opts_chunk: 
    echo: true
    eval: true
    code-fold: true
    warnings: false
    comment: "#>" 
    
revealjs-plugins:
  - pointer
  - verticator
  
filters: 
  - reveal-header
  - code-fullscreen
  - reveal-auto-agenda

editor: source
---

```{r}
#| include: false
library(tidyverse)
library(rcistats)
library(emmeans)
library(patchwork)
penguins <- penguins |> drop_na()
heart_disease <- kmed::heart
heart_disease$disease <- factor(ifelse(heart_disease$class == 0, "no", "yes")) 
heart_disease$sex <- ifelse(heart_disease$sex == T, "Male", "Female") |> factor()
heart_disease$cp <- ifelse(heart_disease$cp == 1, "Typical Angina",
                           ifelse(heart_disease$cp == 2, "Atypical Angina", 
                                  ifelse(heart_disease$cp == 3, "Non-anginal Pain", "Asymptomatic"))) |> 
                    factor(levels = c("Asymptomatic", "Non-anginal Pain", "Atypical Angina", "Typical Angina"))
heart_disease$fbs <- ifelse(heart_disease$fbs == T, "Fasting Blood Sugar >120" , "Fasting Blood Sugar <= 120") |> factor()
heart_disease$restecg <- ifelse(heart_disease$restecg == 0, "Normal",
                                ifelse(heart_disease$restecg == 1, "ST-T wave Abnormality", "Left Ventricular Hypertrophy")) |> 
                          factor(levels = c("Normal", "ST-T wave Abnormality", "Left Ventricular Hypertrophy"))
heart_disease$slope <- ifelse(heart_disease$slope == 1, "Positive Slope",
                              ifelse(heart_disease$slope == 2, "Zero Slope", "Negative Slope")) |> 
                              factor(levels = c("Zero Slope", "Positive Slope", "Negative Slope"))
heart_disease$thal <- ifelse(heart_disease$thal==3, "Normal",
                             ifelse(heart_disease$thal == 6, "Fixed Defect", "Reversible Defect")) |> 
                              factor(levels = c("Normal", "Fixed Defect", "Reversible Defect"))
theme_set(theme_bw() + 
          theme(axis.text = element_text(size = 24),
                axis.title = element_text(size = 30),
                plot.title = element_text(size = 48),
                strip.text = element_text(size = 20),
                legend.title = element_blank(),
                legend.text = element_text(size = 24)))
```

# Motivating Example

## Species and Body Mass

:::: {.columns}
::: {.column width="40%"}

- Is there a difference in body mass between the penguins species?
- Is the difference due to a natural phenomenon or randomness?
:::
::: {.column width="60%"}

```{r}
#| fig-align: center
#| fig-alt: "A box plot and jitter plot being displayed for body mass by penguin species."
penguins |> ggplot(aes(x=species, y = body_mass)) +
  geom_jitter() + 
  geom_boxplot() + 
  labs(x = "Species", y = "Body Mass")
```

:::
::::



## Chest Pain and Heart Disease

:::: {.columns}
::: {.column width="40%"}

- Is there a difference in proportions between the different chest pains?

- Is the difference due to a natural phenomenon or randomness?
:::
::: {.column width="60%"}

```{r}
#| fig-alt: "A stacked bar plot showing chest pain and count by having heart disease or not."
heart_disease |> ggplot(aes(x=cp, fill = disease)) +
  geom_bar(position = "fill") +
  labs(x = "Chest Pain") + 
  theme(axis.text.x = element_text(size = 14)) 
```

:::
::::

# Group Model Inference

## Group Model Inference



## Group Model Inference

**Group Model Inference** is the act of conducting a hypothesis test on the entire group model. We do this to determine if the group model is **significantly** different from just using the sample mean or proportion.

::: fragment
Group model inference determines if more variation is explained by including categorical variables.
:::

## Group Model Inference

- We will conduct group model inference to determine if a group model explains more variation . Both Linear and Logistic Regression have techniques to test different models. 

- For Linear Regression, we determine the significance of the variation explained using an Analysis of Variance (ANOVA) table and F test.

- For Logistic Regression, we determine the significance of the variation explained using a Likelihood Ratio test.

- Conducting Model Inference first ensures that the **Family-wise Error Rate** is controlled.

## Group Model Inference

- Group model inference compares a **Full** and **Reduced** model to determine if they are different.
- **Full**: The group model containing the categorical variable.
- **Reduced**: Either the sample mean or proportion.

## Linear Models

::: {.columns}
::: {.column}

#### Full Model

$$
Y =  \beta_0 + \beta_1 D_1 + \cdots + \beta_p D_p
$$

- $D_1, \cdots, D_p$: Dummy variables for categorical variables
- $\beta_0, \beta_1, \cdots, \beta_p$: Regression coefficients

:::
::: {.column}

#### Reduced Model

$$
Y =  \bar y
$$

- $\bar y$: Average of the outcome

:::
:::

## Generalized Linear Models

::: {.columns}
::: {.column}

#### Full Model

$$
Y =  \beta_0 + \beta_1 D_1 + \cdots + \beta_p D_p
$$

- $D_1, \cdots, D_p$: Dummy variables for categorical variables
- $\beta_0, \beta_1, \cdots, \beta_p$: Regression coefficients

:::
::: {.column}

#### Reduced Model

$$
lo(Y) =  \hat p
$$

- $\hat p$: Sample proportion of the outcome

:::
:::

## Null and Alt Hypothesis

$H_0$: The different categories do not have significantly different means/proportions from each other.

$H_a$: At least two categories have significantly different means/proportions from each other. 


# Family-wise Error Rate

## Motivation

* In multiple hypothesis testing, we test several hypotheses simultaneously.
* The probability of making **at least one Type I error** increases with the number of tests.
* Hence, we need **error control** methods.


## Type I Error and Its Rate

**Type I Error (False Positive):** Rejecting a null hypothesis ($H_0$), when it is true.

**Type I Error Rate ($\alpha$):**
The probability of making a Type I error in a single hypothesis test.

$$
\alpha = P(\text{Reject } H_0 \mid H_0 \text{ is true})
$$

Typically, $\alpha = 0.05$, meaning a 5% chance of incorrectly rejecting a true null hypothesis.


## Definition of FWER

**Family-Wise Error Rate (FWER):**
The probability of making **one or more Type I errors** among all hypotheses tested.

$$
\text{FWER} = P(\text{At least one false rejection}) = P(V \ge 1)
$$

where:

* $V$ = number of false positives (incorrect rejections)

## Why Control FWER?

* Maintains overall confidence in conclusions.
* Avoids claiming false discoveries when many tests are run.
* Trade-off: Strong control of FWER reduces **power** (increases Type II error).


## Methods to Control FWER

1. Bonferroni Correction

2. Holm-Bonferroni Procedure (Step-down)

3. Tukeyâ€™s Honest Significant Difference (HSD)



# Linear Model Inference

## Linear Model Inference

Given 2 models:

$$
\hat Y = \hat\beta_0 + \hat\beta_1 X_1 + \hat\beta_2 X_2 + \cdots + \hat\beta_p X_p
$$

or

$$
\hat Y = \bar y
$$

::: fragment
Is the model with predictors do a better job than using the average?
:::

## Linear Models: Difference Groups

Given a categorical variable with 4 categories, which model is better:

$$
\hat Y = \hat\beta_0 + \hat\beta_1 C_1 + \hat\beta_2 C_2 + \hat\beta_3 C_3  
$$

or

$$
\hat Y = \bar y
$$


::: fragment
Are the 2 models different from each other?
:::


## ANOVA Table

| Source | DF        | SS            | MS                    | F                        |
|---------------|---------------|---------------|---------------|---------------|
| Model  | $DFR=k-1$ | $SSR$         | $MSR=\frac{SSM}{DFR}$ | $\hat F=\frac{MSR}{MSE}$ |
| Error  | $DFE=n-k$ | $SSE$         | $MSE=\frac{SSE}{DFE}$ |                          |
| Total  | $TDF=n-1$ | $TSS=SSR+SSE$ |                       |                          |

$$
\hat F \sim F(DFR, DFE)
$$

## Conducting an ANOVA in R

```r
xlm <- lm(Y ~ X, data = DATA)
anova(xlm)
```

- `Y`: Outcome variable in DATA
- `X`: Categorical variable in DATA
- `DATA`: Name of the data (frame) set

## Species and Body Mass

:::: {.columns}
::: {.column width="40%"}

- Is there a difference in body mass between the penguins species?
- Is the difference due to a natural phenomenon or randomness?
:::
::: {.column width="60%"}

```{r}
#| fig-align: center
#| fig-alt: "A box plot and jitter plot being displayed for body mass by penguin species."
penguins |> ggplot(aes(x=species, y = body_mass)) +
  geom_jitter() + 
  geom_boxplot() + 
  labs(x = "Species", y = "Body Mass")
```

:::
::::


## Example: Hypothesis

- $H_0$: The mean body mass are the same between the 3 penguin species.

- $H_1$: At least one species pairing have different mean body mass.

## Example: ANOVA

```{r}
#| code-fold: show
xlm <- lm(body_mass ~ species, data = penguins)
anova(xlm)
```


# Logistic Model Inference

## Logistic Model Inference

Given 2 models:

$$
g(\hat Y) = \hat\beta_0 + \hat\beta_1 X_1 + \hat\beta_2 X_2 + \cdots + \hat\beta_p X_p
$$

or

$$
g(\hat Y) = \bar y
$$

::: fragment
Is the model with predictors do a better job than using the average?
:::

## Logistic Model Inference

Given a categorical variable with 4 categories, which model is better:

$$
g(\hat Y) = \hat\beta_0 + \hat\beta_1 C_1 + \hat\beta_2 C_2 + \hat\beta_3 C_3  
$$

or

$$
g(\hat Y) = \bar y
$$

::: fragment
Are the 2 models different from each other?
:::

## Likelihood Ratio Test (Logistic)

The Likelihood Ratio Test is a test to determine whether the likelihood of observing the outcome is significantly bigger in a larger, more complicated model, than a simpler model. 


It conducts a hypothesis tests to see if models are significantly different from each other.


## Conducting an LRT in R

```r
xlm <- glm(Y ~ X, data = DATA, family = binomial)
anova(xlm)
```

- `Y`: Outcome variable in DATA
- `X`: Categorical variable in DATA
- `DATA`: Name of the data (frame) set

## Chest Pain and Heart Disease

:::: {.columns}
::: {.column width="40%"}

- Is there a difference in proportions between the different chest pains?

- Is the difference due to a natural phenomenon or randomness?
:::
::: {.column width="60%"}

```{r}
#| fig-alt: "A stacked bar plot showing chest pain and count by having heart disease or not."
heart_disease |> ggplot(aes(x=cp, fill = disease)) +
  geom_bar(position = "fill") +
  labs(x = "Chest Pain") + 
  theme(axis.text.x = element_text(size = 14)) 
```

:::
::::


## Example: Hypothesis

- $H_0$: The proportion of having heart disease are the same between the 4 chest pain types.

- $H_1$: At least one chest pain pairing have different proportions of having heart disease.

## Example: LRT

```{r}
#| code-fold: show
xglm <- glm(disease ~ cp, data = heart_disease,
            family = binomial)
anova(xglm)
```


# Post-Hoc Analysis

## Post-Hoc Analysis

- If we found to reject the null hypothesis from our model inference, we conduct a **post-hoc** analysis to determine which groups are significantly different from each other.

- We will conduct multiple comparisons test, while maintaining the family-wise error rate, to determine which groups are different from each other.


## Group Proportions Or Means

We will use the `emmeans` function from the `emmeans` R package to obtain the group proportions or means.


## Group Means

```r
m <- lm(Y ~ X, data = DATA)
emmeans(m, ~X)
```

- `Y`: Outcome variable in DATA
- `X`: Categorical variable in DATA
- `DATA`: Name of the data (frame) set

## Group Proportions

```r
m <- glm(Y ~ X, data = DATA, family = binomial)
emmeans(m, ~X, type = "response")
```

- `Y`: Outcome variable in DATA
- `X`: Categorical variable in DATA
- `DATA`: Name of the data (frame) set

## Body Mass by Species

```{r}
#| code-fold: show
m1 <- lm(body_mass ~ species, data = penguins)
emmeans(m1, ~species)
```

## Heart Disease by Chest Pain

```{r}
#| code-fold: show
m2 <- glm(disease ~ cp, data = heart_disease, family = binomial)
emmeans(m2, ~ cp, type = "response")
```

## Multiple Comparisons Test

- A multi-comparison test can be achieved by using the `pairs` function from the output of the `emmeans` function.

- This function will automatically adjust the p-values using Tukey's method to fix the family-wise error rate.

## Multi-Comparison Test: Means

```r
m <- lm(Y ~ X, data = DATA)
e <- emmeans(m, ~X)
pairs(e)
```

- `Y`: Outcome variable in DATA
- `X`: Categorical variable in DATA
- `DATA`: Name of the data (frame) set

## Multi-Comparison Test: Proportions

```r
m <- glm(Y ~ X, data = DATA, family = binomial)
e <- emmeans(m, ~X, type = "response")
pairs(e)
```

- `Y`: Outcome variable in DATA
- `X`: Categorical variable in DATA
- `DATA`: Name of the data (frame) set

## Body Mass by Species

```{r}
#| code-fold: show
m1 <- lm(body_mass ~ species, data = penguins)
e1 <- emmeans(m1, ~species)
pairs(e1)
```

## Heart Disease by Chest Pain

```{r}
#| code-fold: show
m2 <- glm(disease ~ cp, data = heart_disease, family = binomial)
e2 <- emmeans(m2, ~ cp, type = "response")
pairs(e2)
```