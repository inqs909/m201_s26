---
title: "Statistical Inference"
subtitle: "Testing Different Groups"
description: |
  Testing the difference in groups.

format:
  revealjs:
    width: 1200
    scrollable: true
    theme: [default, styles.scss]
    navigation-mode: vertical
    controls-layout: bottom-right
    controls-tutorial: true
    incremental: false 
    chalkboard:
      theme: whiteboard
      chalk-width: 4
knitr:
  opts_chunk: 
    echo: true
    eval: true
    message: false
    code-fold: true
    warnings: false
    comment: "#>" 
    
revealjs-plugins:
  - pointer
  - verticator
  
filters: 
  - reveal-header
  - code-fullscreen
  - reveal-auto-agenda
editor: source
---

```{r}
#| include: false
library(tidyverse)
library(csucistats)
library(patchwork)
library(emmeans)
theme_set(theme_bw() + 
            theme(
              axis.text.x = element_text(size = 24),
              axis.title = element_text(size = 30),
              plot.title = element_text(size = 48),
              strip.text = element_text(size = 20),
              legend.title = element_blank(),
              legend.text = element_text(size = 24)))

penguins <- penguins |> drop_na()
heart_disease <- kmed::heart
heart_disease$disease <- factor(ifelse(heart_disease$class == 0, "no", "yes")) 


```


```{r}
m <- glm(disease ~ cp, 
    data = heart_disease, 
    family = binomial) 
anova(m, method = "lrt")

r <- emmeans(m, ~cp, trans = "response")
pairs(r)
```

# Motivating Example

## Motivating Examples

```{r}
p1 <- penguins |> ggplot(aes(x=species, y = body_mass)) +
  geom_jitter() + 
  geom_boxplot() + 
  labs(x = "Species", y = "Body Mass", title = "Linear")
  
p2 <- heart_disease |> ggplot(aes(x=cp, fill = disease)) +
  geom_bar(stat="count", position=position_dodge()) +
  labs(x = "Chest Pain", title = "Logistic") 
p1 + p2
  
```

# Model Hypothesis Testing

## Model inference

We conduct model inference to determine if different models are better at explaining variation. A common example is to compare a linear model ($\hat Y=\hat\beta_0 + \hat\beta_1 X$) to the mean of Y ($\hat \mu_y$). We determine the significance of the variation explained using an Analysis of Variance (ANOVA) table and F test.

## Linear Model Inference

Given 2 models:

$$
\hat Y = \hat\beta_0 + \hat\beta_1 X_1 + \hat\beta_2 X_2 + \cdots + \hat\beta_p X_p
$$

or

$$
\hat Y = \bar y
$$

::: fragment
Is the model with predictors do a better job than using the average?
:::

## Logistic Model Inference

Given 2 models:

$$
g(\hat Y) = \hat\beta_0 + \hat\beta_1 X_1 + \hat\beta_2 X_2 + \cdots + \hat\beta_p X_p
$$

or

$$
g(\hat Y) = \bar y
$$

::: fragment
Is the model with predictors do a better job than using the average?
:::


## ANOVA (Linear)

## ANOVA Table

| Source | DF        | SS            | MS                    | F                        |
|---------------|---------------|---------------|---------------|---------------|
| Model  | $DFR=k-1$ | $SSR$         | $MSR=\frac{SSM}{DFR}$ | $\hat F=\frac{MSR}{MSE}$ |
| Error  | $DFE=n-k$ | $SSE$         | $MSE=\frac{SSE}{DFE}$ |                          |
| Total  | $TDF=n-1$ | $TSS=SSR+SSE$ |                       |                          |

$$
\hat F \sim F(DFR, DFE)
$$

## Conducting an ANOVA in R

```{r}
#| code-fold: show
#| eval: false
xlm <- lm(Y ~ X, data = DATA)
anova(xlm)
```

## Likelihood Ratio Test (Logistic)

The Likelihood Ratio Test is a test to determine whether the likelihood of observing the outcome is significantly bigger in a larger, more complicated model, than a simpler model. 


It conducts a hypothesis tests to see if models are significantly different from each other.


## Conducting an LRT in R

```{r}
#| code-fold: show
#| eval: false
xlm <- glm(Y ~ X, data = DATA, family = binomial)
anova(xlm)
```

# Significant Difference Between Groups
