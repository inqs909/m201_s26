{
  "hash": "057ccd0c9fcd9327b55ed96e77369800",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Model Inference\"\ndate: 5/05/25\ndescription: |\n  Make the connection between traditional statisitcal inference an regression inference. \nformat:\n  revealjs:\n    width: 1200\n    scrollable: true\n    theme: [default, styles.scss]\n    navigation-mode: vertical\n    controls-layout: bottom-right\n    controls-tutorial: true\n    incremental: false \n    chalkboard:\n      src: notes/chalkboard_1a.json\n      storage: chalkboard_pres\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    code-fold: true\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - reveal-header\n  - code-fullscreen\n  - reveal-auto-agenda\neditor: source\n---\n\n\n\n# Motivating Example\n\n## Motivating Example\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbladder1 |> ggplot(aes(number, color = death2)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](16_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n# $\\beta$ Hypothesis Testing\n\n## Hypothesis\n\n::: columns\n::: {.column width=\"50%\"}\n$$H_0: \\beta = \\theta$$\n:::\n\n::: {.column width=\"50%\"}\n$$H_0: \\beta \\ne \\theta$$\n:::\n:::\n\n## Testing $\\beta_j$\n\n\n$$\n\\frac{\\hat\\beta_j - \\theta}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1)\n$$\n\n## Confidence Intervals\n\n$$\nPE \\pm CV \\times SE\n$$\n\n-   PE: Point Estimate\n\n-   CV: Critical Value $P(X<CV) = 1-\\alpha/2$\n\n-   $\\alpha$: significance level\n\n-   SE: Standard Error\n\n\n## Conducting HT of $\\beta_j$\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nxlm <- glm(Y ~ X, data = DATA, family = binomial())\nsummary(xlm)\n```\n:::\n\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nm1 <- glm(death ~ recur + number + size, bladder1, family = binomial())\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> \n#> Call:\n#> glm(formula = death ~ recur + number + size, family = binomial(), \n#>     data = bladder1)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept) -0.8525259  0.4462559  -1.910 0.056082 .  \n#> recur       -0.3897480  0.1062848  -3.667 0.000245 ***\n#> number       0.0008451  0.1124503   0.008 0.994004    \n#> size        -0.2240419  0.1626749  -1.377 0.168439    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 189.38  on 293  degrees of freedom\n#> Residual deviance: 166.43  on 290  degrees of freedom\n#> AIC: 174.43\n#> \n#> Number of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n## Confidence Interval\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(xlm, level = LEVEL)\n```\n:::\n\n\n\n## Example \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nconfint(m1, level = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                  2.5 %      97.5 %\n#> (Intercept) -1.7353779  0.02529523\n#> recur       -0.6217831 -0.20078281\n#> number      -0.2421738  0.20731479\n#> size        -0.5880581  0.06061498\n```\n\n\n:::\n:::\n\n## Confidence Interval for Odds Ratio\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nexp(confint(m1, level = 0.95))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#>                 2.5 %    97.5 %\n#> (Intercept) 0.1763335 1.0256179\n#> recur       0.5369861 0.8180901\n#> number      0.7849197 1.2303698\n#> size        0.5554048 1.0624898\n```\n\n\n:::\n:::\n\n\n\n# Model Hypothesis Testing\n\n## Model inference\n\nWe conduct model inference to determine if different models are better at explaining variation. A common example is to compare a linear model ($g(\\hat Y)=\\hat\\beta_0 + \\hat\\beta_1 X$) to the mean of Y ($\\hat \\mu_y$). We determine the significance of the variation explained using an Analysis of Variance (ANOVA) table and F test.\n\n## Model Inference\n\nGiven 2 models:\n\n$$\ng(\\hat Y) = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_2 + \\cdots + \\hat\\beta_p X_p\n$$\n\nor\n\n$$\ng(\\hat Y) = \\bar y\n$$\n\n::: fragment\nIs the model with predictors do a better job than using the average?\n:::\n\n## Likelihood Ratio Test\n\nThe Likelihood Ratio Test is a test to determine whether the likelihood of observing the outcome is significantly bigger in a larger, more complicated model, than a simpler model. \n\n\nIt conducts a hypothesis tests to see if models are significantly different from each other.\n\n## Conducting an LRT in R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nxlm <- glm(Y ~ X, data = DATA, family = binomial)\nxlm0 <- glm(Y ~ 1, data = DATA, family = binomial)\nanova(xlm0, xlm, test = \"LRT\")\n```\n:::\n\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nm0 <- update(m1, formula. = ~ 1)\nanova(m0, m1, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Analysis of Deviance Table\n#> \n#> Model 1: death ~ 1\n#> Model 2: death ~ recur + number + size\n#>   Resid. Df Resid. Dev Df Deviance Pr(>Chi)    \n#> 1       293     189.38                         \n#> 2       290     166.43  3   22.953 4.13e-05 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n## Model Inference\n\nModel inference can be extended to compare models that have different number of predictors.\n\n## Model Inference\n\nGiven:\n\n$$\nM1:\\ g(\\hat y) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 \n$$\n\n$$\nM2:\\ g(\\hat y) = \\beta_0 + \\beta_1 X_1  \n$$\n\nLet $M1$ be the FULL (larger) model, and let $M2$ be the RED (Reduced, smaller) model.\n\n## Model Inference\n\nHe can test the following Hypothesis:\n\n-   $H_0$: The error variations between the FULL and RED model are not different.\n-   $H_1$: The error variations between the FULL and RED model are different.\n\n\n## Likelihood Ratio Test in R\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nfull <- glm(Y  ~  X1 + X2 + X3 + X4, DATA, family = binomial())\nred <- glm(Y ~ X1 + X2, DATA, family = binomial())\nanova(red, full, test = \"LRT\")\n```\n:::\n\n\n## Example\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nm1 <- glm(death ~ number + size + recur, bladder1, family = binomial())\nm2 <- glm(death ~ recur, bladder1, family = binomial())\nanova(m2, m1, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#> Analysis of Deviance Table\n#> \n#> Model 1: death ~ recur\n#> Model 2: death ~ number + size + recur\n#>   Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n#> 1       292     168.72                     \n#> 2       290     166.43  2   2.2883   0.3185\n```\n\n\n:::\n:::\n\n\n\n\n# Traditional Statistics\n\n\n## Paired t-Test as Linear Regression\n\nA **paired t-test** compares the means of two related measurements (e.g., before and after). This can be expressed as a linear regression on the **difference scores**.\n\n**Regression on difference scores** (simplest method): \n$$\n    D_i = Y_{i2} - Y_{i1} = \\beta_0 + \\varepsilon_i\n$$\n\n\n## t-Test (Equal Variances) as Linear Regression\n\nA **two-sample t-test** compares the means of two groups. The assumption is that the two groups have equal variance. This is equivalent to a linear regression model with a binary predictor:\n\n$$\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n$$\n\nWhere:\n\n-   $Y_i$: Outcome variable\\\n-   $X_i$: Group indicator (0 = Group A, 1 = Group B)\\\n-   $\\beta_1$: Difference in means between groups\n\n\n**Key Insight:**\nThe t-statistic in the regression output matches the t-test result exactly. Both test if the group means are equal.\n\n\n\n## ANOVA as Linear Regression\n\nANOVA compares means across **three or more groups**. This can also be expressed as a regression model using dummy variables for group membership:\n\n$$\nY_i = \\beta_0 + \\beta_1 D_{1i} + \\beta_2 D_{2i} + \\varepsilon_i\n$$\n\nWhere $D_{1i}, D_{2i}$ are dummy variables for group categories.\n\n**Key Insight:**\n\nThe F-statistic in the ANOVA output is identical to the F-statistic from the regression model with a factor predictor.\n\n## Paired t-Test as Linear Regression\n\nA **paired t-test** compares the means of two related measurements (e.g., before and after). This can be expressed as a linear regression on the **difference scores**.\n\n**Regression on difference scores** (simplest method): \n$$\nD_i = Y_{i2} - Y_{i1} = \\beta_0 + \\varepsilon_i\n$$\n\n\n## More Information\n\nVisit this site to get a more comprehensive picture on how common statistical tests can be done using regression models: https://lindeloev.github.io/tests-as-linear/#51_independent_t-test_and_mann-whitney_u",
    "supporting": [
      "16_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}