[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Term: Spring 2026\nInstructor: Isaac Quintanilla Salinas\nEmail: isaac.qs@csuci.edu\nOffice Location: Marin Hall 2326\nOffice Hours:\nLecture: Gateway Hall 2501 4:30 - 5:45 PM\nWebsite: Canvas (CI Learn)\n\n\n\nCritical reasoning using a quantitative and statistical, problem-solving approach to solving real-world problems. Topics include: probability and statistics, sample data, probability and empirical data distributions, sampling techniques, estimation and hypothesis testing, ANOVA, and correlation and regression analysis. Students will use standard statistical software to analyze real-world and simulated data. GenEd: 2\n\n\n\n\nApply quantitative problem-solving skills to various problems and issues\nSelect, apply and interpret descriptive statistics in an appropriate fashion\nSelect, apply and interpret hypothesis testing methods in an appropriate fashion\nReason both inductively and deductively with quantitative information and data use statistical software to conduct statistical analysis of real-world and simulated data\nOrganize and express ideas clearly and convincingly in oral and written form\n(GE 2.1) Solve problems using mathematical methods\n(GE 2.2) Use graphs, tables, etc. to represent and explain mathematical models and/or quantitative data.\n\n\n\n\nIntroduction to Modern Statistics (IMS)\nStatistical Modeling (SM)\n\n\n\nInstall Google Chrome or any other chromium-based web browser. Used to access google assignments and VoiceThreads.\n\n\n\n\n\n\nCategory\nPercentage\n\n\n\n\nDiscussion Posts\n10%\n\n\nClasswork\n15%\n\n\nVideo Assignments\n15%\n\n\nNotebook Assignments\n15%\n\n\nExam 1\n15%\n\n\nExam 2\n15%\n\n\nExam 3\n15%\n\n\n\nAt the end of the quarter, course grades will be assigned according to the following scale:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA+\n98 – 100\nB+\n87 – &lt;90\nC+\n77 – &lt;80\nD+\n67 – &lt;70\n\n\n\n\nA\n93 – &lt;98\nB\n83 – &lt;87\nC\n73 – &lt;77\nD\n63 – &lt;67\nF\n&lt; 60\n\n\nA–\n90 - &lt;93\nB-\n80 – &lt;83\nC–\n70 – &lt;73\nD–\n60 – &lt;63\n\n\n\n\n\n\n\n\nStudents are expected to attend in-person to class to learn the material.\n\n\n\nStudents are expected to check the course Canvas page 3-4 times a week to view assignments, announcements, and other course-related materials.\n\n\nDiscussion posts are designed to continue the conversation based on the video assignments. Absolutely no late posts will be accepted. Discussion posts will be due every Sunday at 11:59 PM.\n\n\n\nClasswork assignmets are designed to give you an opportunity to practice conceptual topics from the video assignments. The assignments will require you to program in R. The 3 lowest classwork assignments will be dropped. Classwork assignments will be due every Friday at 11:59 PM.\n\n\n\nVideos are used to teach statistical concepts related to the course. Students are expected to watch at least one video a week. The videos are implemented using VoiceThreads. The 3 lowest video assignments will be dropped. Video assignments will be due every Sunday at 11:59 PM.\n\n\n\nNotebook assignments are designed to expand your statistical knowledge. These will be completed in Google Colab which can be accessed from Canvas. There is one notebook assignments every week that you can be completed during class time. Notebook assignments will be due on Sunday at 11:59 PM every week. The 3 lowest notebook assignments will be dropped.\n\n\n\nThere will be three in exams. Exam #1 will be on March 3, 2026, Exam #2 will be on April 16, 2026, and Exam #3 will be on May 19, 2026 from 4-6 PM. While the exams are not considered cumulative, the material builds on each other. Developing a strong understanding of the material through out the course is important for your success. At the end of the semester, your lowest exam grade will be replaced by your median average of all 3 exam grades. This course will operate under a zero-tolerance policy. Talking during the time of the exam, sharing materials, looking at another students’ exam, or not following directions given will be subject to the University’s academic integrity policy.\n\n\n\nThere will be 3 extra credit opportunities worth a total of 5% of your overall grade. (There are no make-ups for missed extra credit assignments!) More information will be provided on the extra credit assignments on a later date. Information on the extra credit can be found here.\n\n\n\n\nThe following outline may be subject to change. Any changes will be announced in class.\n\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nCW Due\nNB Due\nVideo Due\n\n\n\n\n1/26\nWelcome/Intro to Stats and R\n\n1\n1\n\n\n2/2\nData Generating Process\n1\n2\n2\n\n\n2/9\nCategorical Data\n2\n3\n3\n\n\n2/16\nNumerical Data\n3\n4\n4\n\n\n2/23\nDistribution Functions\n4\n5\n\n\n\n3/2\nExam 1/ Linear Regression\n\n\n5\n\n\n3/9\nSimple Linear Regression\n5\n6\n6\n\n\n3/16\nSpring Break\n\n\n\n\n\n3/23\nSimple Logistic Regression\n6\n7\n7\n\n\n3/30\nHoliday/ Group Models\n\n8\n8\n\n\n4/6\nMultivariable Regression\n7\n9\n\n\n\n4/13\nModeling Approaches/Exam 2\n8\n\n9\n\n\n4/20\nSampling Distributions\n9\n10\n10\n\n\n4/27\nInference\n10\n11\n11\n\n\n5/4\nInference\n11\n12\n12\n\n\n5/11\nInference\n12\n\n\n\n\n5/18\nExam 3\n\n\n\n\n\n\n\n\n\nThe use of generative artificial intelligence (AI) in an ethical manner is permitted for this course.\n\n\nYou may use AI for:\n\nObtain clarification\nBrainstorming ideas, examples, outlines, and strategies\nGenerating questions for practice or exploration\nIdentifying keywords or phrasing to match professional goals\n\n\n\n\nYou may not:\n\nSubmit AI-generated work\nUse AI to complete assignments, quizzes, exams, or other assessments meant to reflect only your own work\nUse AI to generate code\n\nAny AI-generated work will receive a 0 in the class. Severe cases will be reported to Academic Misconduct.\nYou may not upload any course material to any AI platforms such as ChatGPT, Claude, Meta AI, and Google Gemini. Exceptions are allowed for DASS-approved services."
  },
  {
    "objectID": "syllabus.html#math-201-elementary-statistics",
    "href": "syllabus.html#math-201-elementary-statistics",
    "title": "Syllabus",
    "section": "",
    "text": "Term: Spring 2026\nInstructor: Isaac Quintanilla Salinas\nEmail: isaac.qs@csuci.edu\nOffice Location: Marin Hall 2326\nOffice Hours:\nLecture: Gateway Hall 2501 4:30 - 5:45 PM\nWebsite: Canvas (CI Learn)\n\n\n\nCritical reasoning using a quantitative and statistical, problem-solving approach to solving real-world problems. Topics include: probability and statistics, sample data, probability and empirical data distributions, sampling techniques, estimation and hypothesis testing, ANOVA, and correlation and regression analysis. Students will use standard statistical software to analyze real-world and simulated data. GenEd: 2\n\n\n\n\nApply quantitative problem-solving skills to various problems and issues\nSelect, apply and interpret descriptive statistics in an appropriate fashion\nSelect, apply and interpret hypothesis testing methods in an appropriate fashion\nReason both inductively and deductively with quantitative information and data use statistical software to conduct statistical analysis of real-world and simulated data\nOrganize and express ideas clearly and convincingly in oral and written form\n(GE 2.1) Solve problems using mathematical methods\n(GE 2.2) Use graphs, tables, etc. to represent and explain mathematical models and/or quantitative data.\n\n\n\n\nIntroduction to Modern Statistics (IMS)\nStatistical Modeling (SM)\n\n\n\nInstall Google Chrome or any other chromium-based web browser. Used to access google assignments and VoiceThreads.\n\n\n\n\n\n\nCategory\nPercentage\n\n\n\n\nDiscussion Posts\n10%\n\n\nClasswork\n15%\n\n\nVideo Assignments\n15%\n\n\nNotebook Assignments\n15%\n\n\nExam 1\n15%\n\n\nExam 2\n15%\n\n\nExam 3\n15%\n\n\n\nAt the end of the quarter, course grades will be assigned according to the following scale:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA+\n98 – 100\nB+\n87 – &lt;90\nC+\n77 – &lt;80\nD+\n67 – &lt;70\n\n\n\n\nA\n93 – &lt;98\nB\n83 – &lt;87\nC\n73 – &lt;77\nD\n63 – &lt;67\nF\n&lt; 60\n\n\nA–\n90 - &lt;93\nB-\n80 – &lt;83\nC–\n70 – &lt;73\nD–\n60 – &lt;63\n\n\n\n\n\n\n\n\nStudents are expected to attend in-person to class to learn the material.\n\n\n\nStudents are expected to check the course Canvas page 3-4 times a week to view assignments, announcements, and other course-related materials.\n\n\nDiscussion posts are designed to continue the conversation based on the video assignments. Absolutely no late posts will be accepted. Discussion posts will be due every Sunday at 11:59 PM.\n\n\n\nClasswork assignmets are designed to give you an opportunity to practice conceptual topics from the video assignments. The assignments will require you to program in R. The 3 lowest classwork assignments will be dropped. Classwork assignments will be due every Friday at 11:59 PM.\n\n\n\nVideos are used to teach statistical concepts related to the course. Students are expected to watch at least one video a week. The videos are implemented using VoiceThreads. The 3 lowest video assignments will be dropped. Video assignments will be due every Sunday at 11:59 PM.\n\n\n\nNotebook assignments are designed to expand your statistical knowledge. These will be completed in Google Colab which can be accessed from Canvas. There is one notebook assignments every week that you can be completed during class time. Notebook assignments will be due on Sunday at 11:59 PM every week. The 3 lowest notebook assignments will be dropped.\n\n\n\nThere will be three in exams. Exam #1 will be on March 3, 2026, Exam #2 will be on April 16, 2026, and Exam #3 will be on May 19, 2026 from 4-6 PM. While the exams are not considered cumulative, the material builds on each other. Developing a strong understanding of the material through out the course is important for your success. At the end of the semester, your lowest exam grade will be replaced by your median average of all 3 exam grades. This course will operate under a zero-tolerance policy. Talking during the time of the exam, sharing materials, looking at another students’ exam, or not following directions given will be subject to the University’s academic integrity policy.\n\n\n\nThere will be 3 extra credit opportunities worth a total of 5% of your overall grade. (There are no make-ups for missed extra credit assignments!) More information will be provided on the extra credit assignments on a later date. Information on the extra credit can be found here.\n\n\n\n\nThe following outline may be subject to change. Any changes will be announced in class.\n\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nCW Due\nNB Due\nVideo Due\n\n\n\n\n1/26\nWelcome/Intro to Stats and R\n\n1\n1\n\n\n2/2\nData Generating Process\n1\n2\n2\n\n\n2/9\nCategorical Data\n2\n3\n3\n\n\n2/16\nNumerical Data\n3\n4\n4\n\n\n2/23\nDistribution Functions\n4\n5\n\n\n\n3/2\nExam 1/ Linear Regression\n\n\n5\n\n\n3/9\nSimple Linear Regression\n5\n6\n6\n\n\n3/16\nSpring Break\n\n\n\n\n\n3/23\nSimple Logistic Regression\n6\n7\n7\n\n\n3/30\nHoliday/ Group Models\n\n8\n8\n\n\n4/6\nMultivariable Regression\n7\n9\n\n\n\n4/13\nModeling Approaches/Exam 2\n8\n\n9\n\n\n4/20\nSampling Distributions\n9\n10\n10\n\n\n4/27\nInference\n10\n11\n11\n\n\n5/4\nInference\n11\n12\n12\n\n\n5/11\nInference\n12\n\n\n\n\n5/18\nExam 3\n\n\n\n\n\n\n\n\n\nThe use of generative artificial intelligence (AI) in an ethical manner is permitted for this course.\n\n\nYou may use AI for:\n\nObtain clarification\nBrainstorming ideas, examples, outlines, and strategies\nGenerating questions for practice or exploration\nIdentifying keywords or phrasing to match professional goals\n\n\n\n\nYou may not:\n\nSubmit AI-generated work\nUse AI to complete assignments, quizzes, exams, or other assessments meant to reflect only your own work\nUse AI to generate code\n\nAny AI-generated work will receive a 0 in the class. Severe cases will be reported to Academic Misconduct.\nYou may not upload any course material to any AI platforms such as ChatGPT, Claude, Meta AI, and Google Gemini. Exceptions are allowed for DASS-approved services."
  },
  {
    "objectID": "syllabus.html#university-policies",
    "href": "syllabus.html#university-policies",
    "title": "Syllabus",
    "section": "University Policies",
    "text": "University Policies\n\nSyllabus Policies and Assistance\nCSUCI’s Syllabus Policies and Assistance Website provides important details about academic policies, campus expectations, and student support services that are all highly applicable to your success as a student both in and outside of the classroom. Ensure that you review this site on a regular basis to stay informed about the policies and resources that support your success, as campus resources or policies may change semester to semester.\n\n\nAcademic Honesty\nConduct yourself with honesty and integrity. Do not submit others’ work as your own. Foassignments and quizzes that allow you to work with a group, only put your name on what the group submits if you genuinely contributed to the work. Work completely independently on exams, using only the materials that are indicated as allowed. Failure to observe academic honesty results in substantial penalties that can include failing the course.\n\n\nCSUCI Basic Need\nPlease use the link to the Basic Needs Program on the Syllabus Policies and Assistance website (&lt;go.csuci.edu/syllabuspolicies&gt;) for information on emergency food, housing accommodations, toiletries, and connections to critical resources.\n\n\nCSUCI Disability Statement\nIf you are a student with a disability requesting reasonable accommodations in this course, you need to contact Disability Accommodations and Support Services (DASS) located on the second floor of Arroyo Hall, via email accommodations@csuci.edu or call 805-437-3331. All requests for reasonable accommodations require registration with DASS in advance of need: https://www.csuci.edu/dass/students/apply-for-services.htm. Faculty, students and DASS will work together regarding classroom accommodations. You are encouraged to discuss approved.\n\n\nDisruption\n\nIf I Am Out: I will communicate via email and will hold classes asynchronously.\nIf You Are Out: Contact me as soon as possible to talk about your options. Reasonable accommodations will be provided for a brief absence. With proper documentation, extended accommodations will be provided."
  },
  {
    "objectID": "rcode/r_packages.html",
    "href": "rcode/r_packages.html",
    "title": "R Packages",
    "section": "",
    "text": "\\[\nY = \\hat \\beta_i X\n\\]"
  },
  {
    "objectID": "rcode/r_packages.html#data-packages",
    "href": "rcode/r_packages.html#data-packages",
    "title": "R Packages",
    "section": "Data Packages",
    "text": "Data Packages\n\ntaylor\ninstall.packages(\"taylor\")\n\n\nkmed\ninstall.packages(\"kmed\")"
  },
  {
    "objectID": "rcode/r_packages.html#miscellaneous-packages",
    "href": "rcode/r_packages.html#miscellaneous-packages",
    "title": "R Packages",
    "section": "Miscellaneous Packages",
    "text": "Miscellaneous Packages\n\nlatex2exp\ninstall.packages(\"latex2exp\")\n\n\npatchwork\ninstall.packages(\"patchwork\")\n\n\nDT\ninstall.packages(\"DT\")\n\n\nThemePark\ninstall.packages(\"remotes\")\nremotes::install_github(\"MatthewBJane/ThemePark\")\n\n\nggthemes\ninstall.packages(\"ggthemes\")"
  },
  {
    "objectID": "rcode/logistic.html",
    "href": "rcode/logistic.html",
    "title": "Logistic Regression Models",
    "section": "",
    "text": "Copy the following code and put it in a code cell in Google Colab. Only do this if you are using a completely new notebook.\n# This code will load the R packages we will use\ninstall.packages(c(\"rcistats\"),\n                 repos = c(\"https://inqs909.r-universe.dev\", \n                           \"https://cloud.r-project.org\"))\nlibrary(tidyverse)\nlibrary(csucistats)\nlibrary(MASS)\n\n\n# Uncomment and run for themes\n# csucistats::install_themes()\n# library(ThemePark)\n# library(ggthemes)\n\n# Outcome: 1 = died from Melanoma, 0 = did not\nMelanoma$dead &lt;- ifelse(Melanoma$status == 1, 1, 0)"
  },
  {
    "objectID": "rcode/logistic.html#melanoma",
    "href": "rcode/logistic.html#melanoma",
    "title": "Logistic Regression Models",
    "section": "2.1 Melanoma",
    "text": "2.1 Melanoma\nMelanoma is a type of skin cancer arising from melanin‑producing cells. It is dangerous because it can metastasize to other parts of the body."
  },
  {
    "objectID": "rcode/logistic.html#outcome-of-interest",
    "href": "rcode/logistic.html#outcome-of-interest",
    "title": "Logistic Regression Models",
    "section": "2.2 Outcome of interest",
    "text": "2.2 Outcome of interest\nWe want to understand how predictors affect survival during a study period. We therefore code a binary outcome dead."
  },
  {
    "objectID": "rcode/logistic.html#data-1",
    "href": "rcode/logistic.html#data-1",
    "title": "Logistic Regression Models",
    "section": "2.3 Data",
    "text": "2.3 Data\nWe use MASS::Melanoma with:- dead (1 = died of Melanoma, 0 = otherwise),- sex (1 = male, 0 = female),- age (years),- thickness (tumour thickness in mm),- ulcer (1 = present, 0 = absent)."
  },
  {
    "objectID": "rcode/logistic.html#plot",
    "href": "rcode/logistic.html#plot",
    "title": "Logistic Regression Models",
    "section": "2.4 Plot",
    "text": "2.4 Plot\n\n\nCode\nggplot(Melanoma, aes(thickness, dead)) +\n  geom_point(alpha = 0.7) +\n  labs(x = \"Tumour thickness (mm)\", y = \"Dead (1=yes, 0=no)\") +\n  stat_smooth(method = \"glm\",\n              se = F,\n              method.args = list(family = \"binomial\"),\n              color = \"blue\") +\n  theme_bw()"
  },
  {
    "objectID": "rcode/logistic.html#fitting-model",
    "href": "rcode/logistic.html#fitting-model",
    "title": "Logistic Regression Models",
    "section": "3.1 Fitting Model",
    "text": "3.1 Fitting Model\nTemplate:\n# Logistic regression (binomial GLM)\nglm(Y ~ X1 + X2 + ... + Xp,\n    data = DATA,\n    family = binomial())\nExample (Melanoma):\nModel dead by sex, age, thickness, and ulcer:\n\nglm(dead ~ sex + age + thickness + ulcer,\n    data = Melanoma,\n    family = binomial())\n\n#&gt; \n#&gt; Call:  glm(formula = dead ~ sex + age + thickness + ulcer, family = binomial(), \n#&gt;     data = Melanoma)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)          sex          age    thickness        ulcer  \n#&gt;    -2.39860      0.40767      0.00402      0.11253      1.31314  \n#&gt; \n#&gt; Degrees of Freedom: 204 Total (i.e. Null);  200 Residual\n#&gt; Null Deviance:       242.4 \n#&gt; Residual Deviance: 210.3     AIC: 220.3\n\n\nThe fitted logit equation can be written generically as"
  },
  {
    "objectID": "rcode/logistic.html#odds-ratios-exponentiated-coefficients",
    "href": "rcode/logistic.html#odds-ratios-exponentiated-coefficients",
    "title": "Logistic Regression Models",
    "section": "3.2 Odds ratios (exponentiated coefficients)",
    "text": "3.2 Odds ratios (exponentiated coefficients)\nTemplate:\n# Logistic regression (binomial GLM)\nm &lt;- glm(Y ~ X1 + X2 + ... + Xp,\n         data = DATA,\n         family = binomial())\nexp(coef(m))\nExample:\n\nm &lt;- glm(dead ~ sex + age + thickness + ulcer,\n    data = Melanoma,\n    family = binomial())\nexp(coef(m))\n\n#&gt; (Intercept)         sex         age   thickness       ulcer \n#&gt;  0.09084468  1.50331052  1.00402853  1.11910869  3.71781566"
  },
  {
    "objectID": "rcode/logistic.html#model",
    "href": "rcode/logistic.html#model",
    "title": "Logistic Regression Models",
    "section": "4.1 Model",
    "text": "4.1 Model\n\\[\n\\hat P(Y=1) = \\frac{e^{\\hat\\beta_0 + \\hat\\beta_1 X_1 + \\cdots + \\hat\\beta_p X_p}}{1 + e^{\\hat\\beta_0 + \\hat\\beta_1 X_1 + \\cdots + \\hat\\beta_p X_p}}.\n\\]\nTemplate:\nxglm &lt;- glm(Y ~ X1 + X2 + ... + Xp,\n            data = DATA,\n            family = binomial())\n\nnew_df &lt;- data.frame(X1 = VAL1, X2 = VAL2, ..., Xp = VALp)\npredict(xglm, newdata = new_df, type = \"response\")  # probabilities\nExamples (Melanoma):\n\nFit a model with gender, age, thickness, and ulcer present\n\n\nxglm &lt;- glm(dead ~ sex + age + thickness + ulcer,\n    data = Melanoma,\n    family = binomial())\n\n\nMale, age 75, thickness 2.9, ulcer present\n\n\nnew1 &lt;- data.frame(sex = 1, age = 75, thickness = 2.9, ulcer = 1)\npredict(xglm, new1, type = \"response\")\n\n#&gt;         1 \n#&gt; 0.4875223\n\n\n\nMale, age 75, thickness 2.9, ulcer absent\n\n\nnew2 &lt;- data.frame(sex = 1, age = 75, thickness = 2.9, ulcer = 0)\npredict(xglm, new2, type = \"response\")\n\n#&gt;         1 \n#&gt; 0.2037438\n\n\n\nFemale, thickness 2.9, ulcer present — compare ages 55 vs 75\n\n\nnew3 &lt;- tibble(sex = 0, age = c(55, 75), thickness = 2.9, ulcer = 1)\npred3 &lt;- predict(xglm, new3, type = \"response\")\ntibble(age = new3$age, probability = scales::percent(pred3, accuracy = 0.1))\n\n#&gt; # A tibble: 2 × 2\n#&gt;     age probability\n#&gt;   &lt;dbl&gt; &lt;chr&gt;      \n#&gt; 1    55 36.9%      \n#&gt; 2    75 38.8%"
  },
  {
    "objectID": "rcode/logistic.html#simple-logistic-regression",
    "href": "rcode/logistic.html#simple-logistic-regression",
    "title": "Logistic Regression Models",
    "section": "5.1 Simple Logistic Regression",
    "text": "5.1 Simple Logistic Regression\n# Fit\nglm(Y ~ X, data = DATA, family = binomial())\n\nDATA → your data frame (e.g., Melanoma)\nY → the outcome variable (e.g., dead)\nX → predictor variables (e.g thickness)"
  },
  {
    "objectID": "rcode/logistic.html#logistic-regression",
    "href": "rcode/logistic.html#logistic-regression",
    "title": "Logistic Regression Models",
    "section": "5.2 Logistic Regression",
    "text": "5.2 Logistic Regression\n# Fit\nglm(Y ~ X1 + X2 + ... + Xp, data = DATA, family = binomial())\n\nDATA → your data frame (e.g., Melanoma)\nY → the outcome variable (e.g., dead)\nX1, X2, …, Xp → predictor variables (e.g age, thickness)"
  },
  {
    "objectID": "rcode/logistic.html#odds-ratio",
    "href": "rcode/logistic.html#odds-ratio",
    "title": "Logistic Regression Models",
    "section": "5.3 Odds Ratio",
    "text": "5.3 Odds Ratio\nm &lt;- glm(Y ~ X1 + X2 + ... + Xp, data = DATA, family = binomial())\n\n# Odds Ratio\nexp(coef(m))\n\nDATA → your data frame (e.g., Melanoma)\nY → the outcome variable (e.g., dead)\nX1, X2, …, Xp → predictor variables (e.g age, thickness)"
  },
  {
    "objectID": "rcode/logistic.html#predict-probabilities",
    "href": "rcode/logistic.html#predict-probabilities",
    "title": "Logistic Regression Models",
    "section": "5.4 Predict Probabilities",
    "text": "5.4 Predict Probabilities\nm &lt;- glm(Y ~ X1 + X2 + ... + Xp, data = DATA, family = binomial())\n# Predict probabilities\nnew_df &lt;- data.frame(X1 = VAL1, X2 = VAL2, ...,  Xp = VALp)\npredict(m, newdata = new_df, type = \"response\")\n\nDATA → your data frame (e.g., Melanoma)\nY → the outcome variable (e.g., dead)\nX1, X2, …, Xp → predictor variables (e.g age, thickness)\nVAL1, VAL2, …, VALp → predictor values (e.g 55, 2.8)"
  },
  {
    "objectID": "rcode.html",
    "href": "rcode.html",
    "title": "R Code Reference Page",
    "section": "",
    "text": "Categorical Data\n\n\nDescriptive summaries & visualizations (freq, proportion, crosstabs, bar/pie/mosaic/waffle)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression Models\n\n\nExplaining variation, simple & multiple linear models, categorical predictors, correlation, and prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression Models\n\n\nThe logistic regression model, interpreting coefficients (odds & odds ratios), fitting models in R, and predicting probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical Data\n\n\nDescriptive stats & visualizations for quantitative variables (mean/median, spread, hist/box/scatter)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Packages\n\n\nA list of R packages used to run this course.\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lectures/9.html#sampling-distribution-1",
    "href": "lectures/9.html#sampling-distribution-1",
    "title": "Sampling Distribution",
    "section": "Sampling Distribution",
    "text": "Sampling Distribution\nSampling Distribution is the idea that the statistics that you generate (slopes and intercepts) have their own data generation process.\n\nIn other words, the numerical values you obtain from the lm and glm function can be different if we got a different data set.\n\n\nSome values will be more common than others. Because of this, they have their own data generating process, like the outcome of interest has it’s own data generating process."
  },
  {
    "objectID": "lectures/9.html#sampling-distributions",
    "href": "lectures/9.html#sampling-distributions",
    "title": "Sampling Distribution",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\n\nDistribution of a statistic over repeated samples\nDifferent Samples yield different statistics\n\n\nIf we took many samples, the statistics (like mean) would vary. Their distribution helps us quantify uncertainty."
  },
  {
    "objectID": "lectures/9.html#standard-error",
    "href": "lectures/9.html#standard-error",
    "title": "Sampling Distribution",
    "section": "Standard Error",
    "text": "Standard Error\nThe Standard Error (SE) is the standard deviation of a statistic itself.\n\nSE tells us how much a statistic varies from sample to sample. Smaller SE = more precision."
  },
  {
    "objectID": "lectures/9.html#modelling-the-data",
    "href": "lectures/9.html#modelling-the-data",
    "title": "Sampling Distribution",
    "section": "Modelling the Data",
    "text": "Modelling the Data\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n\\]\n\n\\(Y_i\\): Outcome data\n\\(X_i\\): Predictor data\n\\(\\beta_0, \\beta_1\\): parameters\n\\(\\varepsilon_i\\): error term"
  },
  {
    "objectID": "lectures/9.html#error-term",
    "href": "lectures/9.html#error-term",
    "title": "Sampling Distribution",
    "section": "Error Term",
    "text": "Error Term\n\\[\n\\varepsilon_i \\sim DGP\n\\]\n\n\nThe error terms forces the outcome variable to be different from the mathematical model.\nThe numbers being generated are random and cannot be predicted."
  },
  {
    "objectID": "lectures/9.html#randomness-effect",
    "href": "lectures/9.html#randomness-effect",
    "title": "Sampling Distribution",
    "section": "Randomness Effect",
    "text": "Randomness Effect\nThe randomness effect is a sampling phenomenom where you will get different samples every time you sample a population.\n\nGetting different samples means you will get different statistics.\n\n\nThese statistics will have a distribution on their own."
  },
  {
    "objectID": "lectures/9.html#randomness-effect-1",
    "href": "lectures/9.html#randomness-effect-1",
    "title": "Sampling Distribution",
    "section": "Randomness Effect 1",
    "text": "Randomness Effect 1\n\n\nCode\nx &lt;- rnorm(1000)\ny &lt;- 4 + 5 * x + rnorm(1000)\nbb &lt;- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8)"
  },
  {
    "objectID": "lectures/9.html#randomness-effect-2",
    "href": "lectures/9.html#randomness-effect-2",
    "title": "Sampling Distribution",
    "section": "Randomness Effect 2",
    "text": "Randomness Effect 2\n\n\nCode\nx &lt;- rnorm(1000)\ny &lt;- 4 + 5 * x + rnorm(1000)\nbb &lt;- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8)"
  },
  {
    "objectID": "lectures/9.html#randomness-effect-3",
    "href": "lectures/9.html#randomness-effect-3",
    "title": "Sampling Distribution",
    "section": "Randomness Effect 3",
    "text": "Randomness Effect 3\n\n\nCode\nx &lt;- rnorm(1000)\ny &lt;- 4 + 5 * x + rnorm(1000)\nbb &lt;- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8)"
  },
  {
    "objectID": "lectures/9.html#randomness-effect-4",
    "href": "lectures/9.html#randomness-effect-4",
    "title": "Sampling Distribution",
    "section": "Randomness Effect 4",
    "text": "Randomness Effect 4\n\n\nCode\nx &lt;- rnorm(1000)\ny &lt;- 4 + 5 * x + rnorm(1000)\nbb &lt;- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8)"
  },
  {
    "objectID": "lectures/9.html#randomness-effect-5",
    "href": "lectures/9.html#randomness-effect-5",
    "title": "Sampling Distribution",
    "section": "Randomness Effect 5",
    "text": "Randomness Effect 5\n\n\nCode\nx &lt;- rnorm(1000)\ny &lt;- 4 + 5 * x + rnorm(1000)\nbb &lt;- round(b(lm(y ~ x),1),2)\nggplot(tibble(x = x, y = y), aes(x,y)) +\n  geom_point() +\n  annotate(\"text\", \n           x = -1, y = 15, \n           label = TeX(sprintf(r'($\\hat{\\beta} = %g$)', bb),\n                       output = \"character\"),\n           parse = TRUE,\n           size = 8)"
  },
  {
    "objectID": "lectures/9.html#simulating-unicorns-1",
    "href": "lectures/9.html#simulating-unicorns-1",
    "title": "Sampling Distribution",
    "section": "Simulating Unicorns",
    "text": "Simulating Unicorns\nTo better understand the variation in statistics, let’s simulate a data set of unicorn characteristics to visualize and understand the variation.\n\nWe will simulate a data set using the unicorns function and only we need to specify how many unicorns you want to simulate."
  },
  {
    "objectID": "lectures/9.html#simulating-unicorn-data",
    "href": "lectures/9.html#simulating-unicorn-data",
    "title": "Sampling Distribution",
    "section": "Simulating Unicorn Data",
    "text": "Simulating Unicorn Data\n\n\nCode\nunicorns(10)\n\n\n#&gt;    Unicorn_ID Age      Gender  Color Type_of_Unicorn Type_of_Horn Horn_Length\n#&gt; 1           1   9      Female  Brown         Rainbow   Aquamarine    4.994322\n#&gt; 2           2   3 Genderfluid Silver           Jewel   Aquamarine    5.037469\n#&gt; 3           3  20        Male   Gray           Ember   Aquamarine    5.056295\n#&gt; 4           4  15        Male  White           Ruvas         Opal    5.223600\n#&gt; 5           5   8  Non-binary   Pink           Ruvas   Aquamarine    5.259103\n#&gt; 6           6  15 Genderfluid   Pink         Rainbow   Aquamarine    5.184343\n#&gt; 7           7  20        Male Silver           Jewel         Opal    5.165583\n#&gt; 8           8  16      Female  White           Ruvas   Aquamarine    5.004767\n#&gt; 9           9  20      Female  Brown           Ember         Opal    4.745318\n#&gt; 10         10   2        Male   Gold           Ember   Aquamarine    5.080838\n#&gt;    Horn_Strength    Weight Health_Score Personality_Score Magical_Score\n#&gt; 1       30.08409 168.71275            6        0.89577061      10932.20\n#&gt; 2       33.50022  74.74983            6        1.41482929      10793.15\n#&gt; 3       27.51605 124.15535            5        1.33830632      11237.13\n#&gt; 4       29.28971 169.47461            1        2.30345452      11148.27\n#&gt; 5       30.10456 132.19789            2        0.71493170      10928.32\n#&gt; 6       25.84587 120.78183            2        0.05319500      11105.03\n#&gt; 7       26.95481 158.44752            9        0.32798186      11294.42\n#&gt; 8       27.88828 140.97826            7        0.01576836      11149.77\n#&gt; 9       28.68649 105.45406            7        0.48795033      11252.42\n#&gt; 10      31.11550 151.08176            5        1.82554334      10767.17\n#&gt;    Elusiveness_Score Gentleness_Score Nature_Score\n#&gt; 1           32.14065        -15.62836     938.7377\n#&gt; 2           34.38121         11.26808     921.1353\n#&gt; 3           37.27164         45.42319     977.0197\n#&gt; 4           41.35300         38.48637     965.4457\n#&gt; 5           32.73453         32.94513     938.2499\n#&gt; 6           38.76745         23.41856     960.4899\n#&gt; 7           34.97056        -63.67493     984.1463\n#&gt; 8           34.34268         79.73000     965.3412\n#&gt; 9           34.47902         41.96135     978.8099\n#&gt; 10          27.92188         38.68172     918.1856"
  },
  {
    "objectID": "lectures/9.html#unicorn-data-variables",
    "href": "lectures/9.html#unicorn-data-variables",
    "title": "Sampling Distribution",
    "section": "Unicorn Data Variables",
    "text": "Unicorn Data Variables\n\n\nCode\nnames(unicorns(10))\n\n\n#&gt;  [1] \"Unicorn_ID\"        \"Age\"               \"Gender\"           \n#&gt;  [4] \"Color\"             \"Type_of_Unicorn\"   \"Type_of_Horn\"     \n#&gt;  [7] \"Horn_Length\"       \"Horn_Strength\"     \"Weight\"           \n#&gt; [10] \"Health_Score\"      \"Personality_Score\" \"Magical_Score\"    \n#&gt; [13] \"Elusiveness_Score\" \"Gentleness_Score\"  \"Nature_Score\"\n\n\nWe will only look at Magical_Score and Nature_Score."
  },
  {
    "objectID": "lectures/9.html#magical-and-nature-score",
    "href": "lectures/9.html#magical-and-nature-score",
    "title": "Sampling Distribution",
    "section": "Magical and Nature Score",
    "text": "Magical and Nature Score\n\\[\nMagical =  3423 + 8 \\times Nature + \\varepsilon\n\\]\n\\[\n\\varepsilon \\sim N(0, 3.24)\n\\]"
  },
  {
    "objectID": "lectures/9.html#simulating-n0-3.24",
    "href": "lectures/9.html#simulating-n0-3.24",
    "title": "Sampling Distribution",
    "section": "Simulating \\(N(0, 3.24)\\)",
    "text": "Simulating \\(N(0, 3.24)\\)\n\n\nCode\nrnorm(1, 0, sqrt(3.24))\n\n\n#&gt; [1] -0.8148143"
  },
  {
    "objectID": "lectures/9.html#collecting",
    "href": "lectures/9.html#collecting",
    "title": "Sampling Distribution",
    "section": "Collecting",
    "text": "Collecting\n\n\nCode\nunicorns(10) |&gt; select(Nature_Score, Magical_Score)\n\n\n#&gt;    Nature_Score Magical_Score\n#&gt; 1      945.6075      10989.06\n#&gt; 2      979.8664      11264.19\n#&gt; 3      981.0740      11270.55\n#&gt; 4      959.5636      11099.60\n#&gt; 5      942.6402      10968.49\n#&gt; 6      965.1224      11142.73\n#&gt; 7      942.4521      10961.81\n#&gt; 8      941.6442      10957.45\n#&gt; 9      929.9346      10861.28\n#&gt; 10     960.4694      11106.08"
  },
  {
    "objectID": "lectures/9.html#dgp-of-magical-score-1",
    "href": "lectures/9.html#dgp-of-magical-score-1",
    "title": "Sampling Distribution",
    "section": "DGP of Magical Score 1",
    "text": "DGP of Magical Score 1\n\n\nCode\nggplot(unicorns(500), aes(Magical_Score)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/9.html#dgp-of-magical-score-2",
    "href": "lectures/9.html#dgp-of-magical-score-2",
    "title": "Sampling Distribution",
    "section": "DGP of Magical Score 2",
    "text": "DGP of Magical Score 2\n\n\nCode\nggplot(unicorns(500), aes(Magical_Score)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/9.html#estimating-beta_1-via-lm",
    "href": "lectures/9.html#estimating-beta_1-via-lm",
    "title": "Sampling Distribution",
    "section": "Estimating \\(\\beta_1\\) via lm",
    "text": "Estimating \\(\\beta_1\\) via lm\n\n\nCode\nu1 &lt;- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u1)\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Magical_Score ~ Nature_Score, data = u1)\n#&gt; \n#&gt; Coefficients:\n#&gt;  (Intercept)  Nature_Score  \n#&gt;     3424.116         7.999"
  },
  {
    "objectID": "lectures/9.html#collecting-a-new-sample",
    "href": "lectures/9.html#collecting-a-new-sample",
    "title": "Sampling Distribution",
    "section": "Collecting a new sample",
    "text": "Collecting a new sample\n\n\nCode\nu2 &lt;- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u2)\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Magical_Score ~ Nature_Score, data = u2)\n#&gt; \n#&gt; Coefficients:\n#&gt;  (Intercept)  Nature_Score  \n#&gt;     3426.152         7.997"
  },
  {
    "objectID": "lectures/9.html#collecting-a-new-sample-1",
    "href": "lectures/9.html#collecting-a-new-sample-1",
    "title": "Sampling Distribution",
    "section": "Collecting a new sample",
    "text": "Collecting a new sample\n\n\nCode\nu3 &lt;- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u3)\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Magical_Score ~ Nature_Score, data = u3)\n#&gt; \n#&gt; Coefficients:\n#&gt;  (Intercept)  Nature_Score  \n#&gt;      3413.90          8.01"
  },
  {
    "objectID": "lectures/9.html#collecting-a-new-sample-2",
    "href": "lectures/9.html#collecting-a-new-sample-2",
    "title": "Sampling Distribution",
    "section": "Collecting a new sample",
    "text": "Collecting a new sample\n\n\nCode\nu4 &lt;- unicorns(500)\nlm(Magical_Score ~ Nature_Score, u4)\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = Magical_Score ~ Nature_Score, data = u4)\n#&gt; \n#&gt; Coefficients:\n#&gt;  (Intercept)  Nature_Score  \n#&gt;     3425.913         7.997"
  },
  {
    "objectID": "lectures/9.html#replicating-processes",
    "href": "lectures/9.html#replicating-processes",
    "title": "Sampling Distribution",
    "section": "Replicating Processes",
    "text": "Replicating Processes\n\n\nCode\nreplicate(N, CODE)\n\n\n\nN: number of times to repeat a process\nCODE: what is to repeated"
  },
  {
    "objectID": "lectures/9.html#extracting-hat-beta-coefficeints",
    "href": "lectures/9.html#extracting-hat-beta-coefficeints",
    "title": "Sampling Distribution",
    "section": "Extracting \\(\\hat \\beta\\) Coefficeints",
    "text": "Extracting \\(\\hat \\beta\\) Coefficeints\n\n\nCode\nb(MODEL, INDEX)\n\n\n\nMODEL: a model that can be used to extract components\nINDEX: which component do you want to use\n\n0: Intercept\n1: first slope\n2: second slope\n..."
  },
  {
    "objectID": "lectures/9.html#collecting-1000-samples",
    "href": "lectures/9.html#collecting-1000-samples",
    "title": "Sampling Distribution",
    "section": "Collecting 1000 Samples",
    "text": "Collecting 1000 Samples\n\n\nCode\nbetas &lt;- replicate(1000,\n                   b(lm(Magical_Score ~ Nature_Score, unicorns(500)), 1))\n\nbetas\n\n\n#&gt;    [1] 8.001856 8.001883 7.998773 7.999596 8.000157 7.995356 8.001380 8.002911\n#&gt;    [9] 7.994913 8.001176 8.005149 7.992433 7.993953 8.007605 8.003823 8.005402\n#&gt;   [17] 8.006540 8.002201 8.000466 8.000533 7.996627 8.003610 8.000136 7.997974\n#&gt;   [25] 8.007298 8.000647 7.999048 8.005221 8.003633 8.005895 8.001504 7.999875\n#&gt;   [33] 8.005052 7.999364 7.998575 7.999352 8.003838 8.000444 7.992292 7.996091\n#&gt;   [41] 7.998137 7.995953 8.001793 7.999956 8.002158 7.998151 7.999604 7.998594\n#&gt;   [49] 8.004112 7.997075 8.002263 8.002284 8.004400 7.995783 7.997819 8.001326\n#&gt;   [57] 7.995834 8.000052 8.001096 8.000404 7.997834 8.004152 7.998437 8.001691\n#&gt;   [65] 8.003605 8.000432 8.005405 7.995130 7.998328 7.996954 8.003143 7.993950\n#&gt;   [73] 7.994603 7.995159 8.001507 8.002694 8.005525 7.995885 7.999963 8.002107\n#&gt;   [81] 8.010032 8.002063 7.999891 7.995204 8.001973 7.998097 8.004738 8.005438\n#&gt;   [89] 8.008423 7.990369 8.002009 7.994710 7.996961 8.002969 8.000864 8.000793\n#&gt;   [97] 7.998436 7.999526 8.009635 8.003418 7.997043 7.999127 7.994609 8.004783\n#&gt;  [105] 8.003303 7.998135 8.001647 8.003673 8.002129 7.998779 7.992590 8.001312\n#&gt;  [113] 8.002262 8.001350 8.005555 8.001428 8.005002 7.997713 8.003662 8.000282\n#&gt;  [121] 7.994436 7.998048 7.998816 8.006162 8.001852 7.998517 7.994794 8.002619\n#&gt;  [129] 8.002793 8.002236 8.010092 8.010188 8.001935 8.005347 8.003765 7.999131\n#&gt;  [137] 7.998753 7.994576 8.003868 8.000519 7.999499 7.999741 8.005335 7.996523\n#&gt;  [145] 8.000309 8.009204 8.004037 7.997455 8.002581 7.999953 8.000720 7.999070\n#&gt;  [153] 7.995079 8.000964 7.998369 7.992223 8.000144 7.992759 7.998801 7.994257\n#&gt;  [161] 8.000979 8.002416 8.000106 8.011864 8.005592 7.998166 7.999159 8.000842\n#&gt;  [169] 8.004083 8.007711 8.001632 8.003594 8.001799 8.003897 7.998195 7.996270\n#&gt;  [177] 7.994425 7.998315 8.001831 8.006573 7.997198 8.003385 8.000566 8.001136\n#&gt;  [185] 8.005808 8.000341 7.999131 7.996118 7.992282 7.996617 7.998426 8.000291\n#&gt;  [193] 7.998486 7.996059 8.002878 8.005712 7.999872 7.996845 7.997907 7.998971\n#&gt;  [201] 7.998305 7.999609 8.002352 7.996095 8.001775 8.001439 7.997429 7.998576\n#&gt;  [209] 8.007181 8.003978 7.998265 8.002345 7.999849 7.999755 7.997495 7.998716\n#&gt;  [217] 8.000123 8.002955 8.000914 7.997874 8.007609 8.004568 7.998714 8.003109\n#&gt;  [225] 7.999785 8.002034 8.000172 8.000127 8.002691 8.008047 8.003410 8.003218\n#&gt;  [233] 7.999552 8.001050 7.995540 7.993801 7.997140 8.005822 8.002505 8.001920\n#&gt;  [241] 8.013529 7.999517 7.999970 8.004018 8.005002 7.994568 8.000494 7.997430\n#&gt;  [249] 7.994960 7.999786 8.004654 8.009926 8.002013 7.993326 7.996172 8.003849\n#&gt;  [257] 7.999818 7.994949 7.994083 8.005537 8.000484 8.009684 7.999486 7.999651\n#&gt;  [265] 7.996741 7.998677 8.003868 8.001070 8.002264 7.995621 7.996793 8.003336\n#&gt;  [273] 8.001447 8.003221 8.003640 7.988582 8.005643 7.993136 7.998864 7.995340\n#&gt;  [281] 7.999772 8.007899 7.999839 8.007779 7.996651 8.000959 8.005425 7.998482\n#&gt;  [289] 7.990292 7.998966 7.998150 7.997441 8.005734 7.999722 8.007910 8.006597\n#&gt;  [297] 7.995162 7.996206 7.999160 7.990255 8.000818 8.004499 7.996536 7.997056\n#&gt;  [305] 7.998823 7.991812 7.993187 8.009586 7.999484 7.996161 7.997498 8.006524\n#&gt;  [313] 8.006627 7.999309 7.999513 8.005540 7.995640 8.000585 7.999964 8.006212\n#&gt;  [321] 7.998230 8.002236 8.009180 7.999912 8.004867 7.991823 8.001542 8.003286\n#&gt;  [329] 7.996638 7.997528 7.995947 7.996303 8.000476 7.996530 8.001319 8.002341\n#&gt;  [337] 8.003378 7.994127 8.003649 7.997531 8.003298 7.991985 8.002446 7.992008\n#&gt;  [345] 8.003834 8.005397 8.006695 8.003469 7.999173 8.002521 8.006719 8.006080\n#&gt;  [353] 7.998791 8.004597 8.003429 8.000230 7.992090 7.999839 7.996783 8.000756\n#&gt;  [361] 7.996952 8.000518 7.998502 8.004332 8.001069 7.999281 8.000259 8.000406\n#&gt;  [369] 7.998602 8.000745 7.998558 7.994296 7.996920 8.006711 7.995207 7.999280\n#&gt;  [377] 7.999738 7.998918 8.006675 7.996315 8.003812 8.003001 8.000214 8.001026\n#&gt;  [385] 8.003863 7.998921 7.996012 8.002839 8.004190 7.999530 8.000502 8.005627\n#&gt;  [393] 7.997133 8.003993 8.000850 7.998028 7.999261 8.001494 7.998764 7.997925\n#&gt;  [401] 8.001498 8.003307 8.004705 8.004605 7.998704 7.994607 7.996030 8.000361\n#&gt;  [409] 8.005697 7.992430 7.994714 7.992282 7.998263 8.003150 8.002454 7.998235\n#&gt;  [417] 8.002167 8.008431 7.996992 8.001572 8.002824 8.001064 7.997937 8.003677\n#&gt;  [425] 7.998367 8.001279 7.995657 8.005156 8.002096 8.002845 8.004487 7.992459\n#&gt;  [433] 7.999922 7.995216 8.005241 7.995162 7.999020 8.000158 7.995538 7.996391\n#&gt;  [441] 8.003976 7.997306 7.997200 8.009007 7.997799 7.997065 8.001695 7.997703\n#&gt;  [449] 7.994515 8.001980 8.006241 7.993731 7.990839 7.998356 7.998492 7.998819\n#&gt;  [457] 7.997111 7.996764 8.001061 8.004925 7.999888 8.000944 8.003688 7.996438\n#&gt;  [465] 7.996263 8.000027 8.007181 8.002946 8.006305 7.997675 8.002020 8.005247\n#&gt;  [473] 7.998154 7.994800 8.004049 7.998578 7.998986 7.993742 8.003096 8.007116\n#&gt;  [481] 7.997335 7.996996 8.000187 8.000416 7.992161 7.998593 8.004869 7.988739\n#&gt;  [489] 8.001602 7.996814 8.002757 8.005060 8.002415 7.995501 8.003918 7.997018\n#&gt;  [497] 7.998449 8.004234 7.996985 7.998783 7.992476 7.997147 7.996701 8.001824\n#&gt;  [505] 7.998784 8.003676 8.002103 7.999799 7.998836 8.002616 8.003314 7.996674\n#&gt;  [513] 8.002017 7.996884 8.008130 7.998484 8.004259 8.002947 7.999018 8.001131\n#&gt;  [521] 8.000257 7.999753 7.999347 7.999931 7.999212 8.006132 7.998156 8.002949\n#&gt;  [529] 7.999295 7.995753 8.001789 8.000979 7.993904 7.999257 8.004390 8.005518\n#&gt;  [537] 7.995027 8.001200 7.995642 8.006709 7.993524 7.993891 7.993968 7.999810\n#&gt;  [545] 8.002780 8.004695 8.002858 7.994576 8.004947 7.990316 8.001147 7.998640\n#&gt;  [553] 7.999212 7.998676 7.999601 7.996775 8.003244 7.995551 7.995034 8.000704\n#&gt;  [561] 7.998824 7.995677 7.994888 7.995285 7.999855 7.996475 8.003066 7.998882\n#&gt;  [569] 8.005600 7.999249 8.008103 8.006096 7.994987 8.002651 8.001727 8.004421\n#&gt;  [577] 7.994210 8.000068 8.002647 8.000274 7.997617 8.000765 8.000954 8.008061\n#&gt;  [585] 8.007498 7.993286 7.996324 7.997737 7.997714 8.003243 7.993502 8.001868\n#&gt;  [593] 8.002806 7.994663 8.005574 8.002100 8.003949 8.001460 8.007198 7.995998\n#&gt;  [601] 7.992405 7.994832 7.998949 7.994445 7.998540 8.005093 7.998090 8.001495\n#&gt;  [609] 7.994916 7.997280 8.008068 7.997833 7.999429 8.002867 8.000983 8.002765\n#&gt;  [617] 8.003564 7.995602 7.996050 8.003264 8.000703 8.003422 7.999859 8.007116\n#&gt;  [625] 8.001360 7.991332 7.999067 7.994695 7.998513 7.999200 8.004876 8.002811\n#&gt;  [633] 7.998861 7.999865 8.000569 7.992018 8.003328 8.002126 7.996269 7.999086\n#&gt;  [641] 8.004509 7.997078 8.001715 8.002542 7.995526 8.009490 8.001861 8.003486\n#&gt;  [649] 8.005033 7.996039 8.005564 7.995087 7.999994 7.997186 7.993216 7.994357\n#&gt;  [657] 7.999565 8.006838 7.994427 8.004514 7.999053 7.998667 7.998484 7.997295\n#&gt;  [665] 7.996892 7.997404 8.002421 7.991485 8.001872 8.009075 7.996452 8.000912\n#&gt;  [673] 7.998913 7.991160 8.005471 7.997005 8.000536 7.997245 7.994276 7.998258\n#&gt;  [681] 8.001905 8.001060 7.993313 8.000000 7.999826 7.997987 7.998468 8.001216\n#&gt;  [689] 7.998919 8.001435 7.997528 8.006885 8.004376 8.002154 8.006075 7.996624\n#&gt;  [697] 8.002853 8.003318 8.002401 7.999709 8.004756 7.998413 8.002477 7.998666\n#&gt;  [705] 8.001611 8.000429 7.995380 7.996849 7.996167 8.007364 8.002293 8.000955\n#&gt;  [713] 7.996460 7.997889 7.998025 8.004575 8.001768 7.998007 8.002329 7.998035\n#&gt;  [721] 8.002904 7.997964 8.006559 7.995417 7.992893 7.995654 7.998308 8.001941\n#&gt;  [729] 7.997387 8.003324 8.002355 7.995046 7.999879 8.000880 8.008232 7.998773\n#&gt;  [737] 7.996497 8.002220 8.002651 8.010518 8.002033 8.008923 8.003653 8.001004\n#&gt;  [745] 8.005508 8.004182 7.989603 7.998160 8.002482 7.999755 7.996670 8.005916\n#&gt;  [753] 7.996006 7.999972 8.004969 7.999063 7.997276 8.000054 8.003554 7.992355\n#&gt;  [761] 7.995455 7.997624 8.000055 7.998952 7.996352 8.002431 8.001766 8.002276\n#&gt;  [769] 8.008437 8.009375 7.999098 8.000003 7.991890 8.001498 8.002755 7.996282\n#&gt;  [777] 7.996786 7.997485 8.002087 7.998159 7.992391 7.994233 8.004091 7.996386\n#&gt;  [785] 8.003383 7.994153 7.999199 7.995456 7.998597 7.998620 8.001304 8.001493\n#&gt;  [793] 7.997232 7.992850 8.001597 8.001008 8.000705 7.998407 7.992572 8.001354\n#&gt;  [801] 7.998271 8.003242 7.995669 8.001957 8.004254 8.005144 8.001106 8.003070\n#&gt;  [809] 7.997724 8.001577 8.001401 7.993363 7.999876 7.992213 8.002709 7.998177\n#&gt;  [817] 8.003375 7.997533 8.002554 8.002897 7.991561 8.004664 7.997510 7.994253\n#&gt;  [825] 8.005618 7.995426 8.000699 8.000822 7.998052 7.992168 7.998554 8.001620\n#&gt;  [833] 8.002109 7.991539 7.991085 8.000925 7.998480 8.001382 7.999265 8.006425\n#&gt;  [841] 8.001349 8.002999 7.999012 8.011747 7.997604 7.994425 7.999367 8.000275\n#&gt;  [849] 8.001621 8.000965 8.002683 7.993985 8.007190 7.990663 7.998291 7.998634\n#&gt;  [857] 8.005499 7.989444 8.008664 7.994372 7.997085 8.004241 7.993302 7.996634\n#&gt;  [865] 8.004450 7.998853 8.002752 8.000421 7.995854 7.998139 7.999289 8.001447\n#&gt;  [873] 8.004166 8.001665 7.995213 7.991371 8.001408 7.998068 7.997750 8.001111\n#&gt;  [881] 8.010293 8.002383 7.999105 7.998197 8.007901 8.002348 7.999729 7.994392\n#&gt;  [889] 7.996872 8.006121 8.003443 7.997534 7.997188 7.995532 8.000241 7.993679\n#&gt;  [897] 7.997856 7.994096 7.997863 7.994639 7.992302 8.003076 8.003365 8.001554\n#&gt;  [905] 7.993522 7.997914 8.005295 8.002378 8.001682 7.996682 7.997459 7.999326\n#&gt;  [913] 7.999851 8.006115 8.007196 8.001817 8.006217 8.002646 8.001620 8.001490\n#&gt;  [921] 7.999812 7.995839 7.990297 7.999489 7.997431 8.009065 7.990821 7.998080\n#&gt;  [929] 8.005671 8.006470 8.000026 8.001363 8.004385 8.001403 7.998671 7.996004\n#&gt;  [937] 7.998598 8.002540 8.011402 8.002708 8.004125 8.001544 7.999529 7.993893\n#&gt;  [945] 7.996348 8.001709 8.002283 8.001123 8.008125 8.000859 8.001343 7.991236\n#&gt;  [953] 7.990212 7.991359 7.999695 8.000367 8.002975 7.989495 7.993200 8.002122\n#&gt;  [961] 8.002021 8.003123 7.999501 7.994297 7.992449 7.999989 8.004634 7.998962\n#&gt;  [969] 8.008032 8.007042 7.997013 8.002421 8.000847 7.996955 7.995815 7.999883\n#&gt;  [977] 8.006118 8.001707 7.998132 7.997519 8.003568 8.006287 8.001160 8.000173\n#&gt;  [985] 8.002151 7.993940 7.998374 7.993818 7.997584 7.995414 7.999636 7.993034\n#&gt;  [993] 8.004542 8.002560 8.001145 8.005721 8.003467 7.995891 7.999825 7.998180"
  },
  {
    "objectID": "lectures/9.html#distributions-of-hat-beta_1",
    "href": "lectures/9.html#distributions-of-hat-beta_1",
    "title": "Sampling Distribution",
    "section": "Distributions of \\(\\hat \\beta_1\\)",
    "text": "Distributions of \\(\\hat \\beta_1\\)\n\n\nCode\nggplot(data.frame(x = betas), aes(x = x)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/9.html#central-limit-theorem-1",
    "href": "lectures/9.html#central-limit-theorem-1",
    "title": "Sampling Distribution",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\nThe Central Limit Theorem (CLT) is a fundamental concept in probability and statistics. It states that the distribution of the sum (or average) of a large number of independent, identically distributed (i.i.d.) random variables will be approximately normal, regardless of the underlying distribution of those individual variables."
  },
  {
    "objectID": "lectures/9.html#formal-statement-of-the-clt",
    "href": "lectures/9.html#formal-statement-of-the-clt",
    "title": "Sampling Distribution",
    "section": "Formal Statement of the CLT",
    "text": "Formal Statement of the CLT\n\nLet \\(X_1\\), \\(X_2\\), …, \\(X_n\\) be a sequence of i.i.d. random variables with mean \\(\\mu\\) and standard deviation \\(\\sigma\\).\nLet \\(\\bar X\\) be the sample mean of these variables.\nAs n (the sample size) approaches infinity, the distribution of \\(\\bar X\\) approaches a normal distribution with:\n\nMean: \\(\\mu\\)\nStandard Deviation: \\(\\sigma/\\sqrt{n}\\)"
  },
  {
    "objectID": "lectures/9.html#clt-example",
    "href": "lectures/9.html#clt-example",
    "title": "Sampling Distribution",
    "section": "CLT Example",
    "text": "CLT Example\n\nImagine: You’re flipping a fair coin many times.\n\nEach flip is an independent event (heads or tails).\nThe probability of heads/tails is the same for each flip.\n\nNow: Calculate the average number of heads after each set of 10 flips, then each set of 100 flips, and so on.\nObservation: As the number of flips in each set increases, the distribution of these averages will start to resemble a bell-shaped curve (normal distribution), even though the individual coin flips are not normally distributed."
  },
  {
    "objectID": "lectures/9.html#clt-implications",
    "href": "lectures/9.html#clt-implications",
    "title": "Sampling Distribution",
    "section": "CLT Implications",
    "text": "CLT Implications\n\nApproximation: Even if the underlying data is not normally distributed, the distribution of the sample means will be approximately normal for large enough sample sizes.\nPractical Rule: A common rule of thumb is that the sample size (n) should be at least 30 for the CLT to provide a good approximation. However, this is a guideline, and the actual required sample size can vary depending on the shape of the original distribution."
  },
  {
    "objectID": "lectures/9.html#normal-example-n-10",
    "href": "lectures/9.html#normal-example-n-10",
    "title": "Sampling Distribution",
    "section": "Normal Example \\(n = 10\\)",
    "text": "Normal Example \\(n = 10\\)\nSimulating 500 samples of size 10 from a normal distribution with mean 5 and standard deviation of 2.\n\n\nCode\n#rnorm(10, 5, 2)\nsims &lt;- replicate(500, rnorm(10, 5, 2))\nsims_mean &lt;- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(10)),\n                col = \"red\")"
  },
  {
    "objectID": "lectures/9.html#normal-example-n-30",
    "href": "lectures/9.html#normal-example-n-30",
    "title": "Sampling Distribution",
    "section": "Normal Example \\(n = 30\\)",
    "text": "Normal Example \\(n = 30\\)\nSimulating 500 samples of size 30 from a normal distribution with mean 5 and standard deviation of 2.\n\n\nCode\n# rnorm(30, 5, 2)\nsims &lt;- replicate(500, rnorm(30, 5, 2))\nsims_mean &lt;- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(30)),\n                col = \"red\")"
  },
  {
    "objectID": "lectures/9.html#normal-example-n-50",
    "href": "lectures/9.html#normal-example-n-50",
    "title": "Sampling Distribution",
    "section": "Normal Example \\(n = 50\\)",
    "text": "Normal Example \\(n = 50\\)\nSimulating 500 samples of size 50 from a normal distribution with mean 5 and standard deviation of 2.\n\n\nCode\n# rnorm(50, 5, 2)\nsims &lt;- replicate(500, rnorm(50, 5, 2))\nsims_mean &lt;- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(50)),\n                col = \"red\")"
  },
  {
    "objectID": "lectures/9.html#normal-example-n-100",
    "href": "lectures/9.html#normal-example-n-100",
    "title": "Sampling Distribution",
    "section": "Normal Example \\(n = 100\\)",
    "text": "Normal Example \\(n = 100\\)\nSimulating 500 samples of size 100 from a normal distribution with mean 5 and standard deviation of 2.\n\n\nCode\n# rnorm(100, 5, 2)\nsims &lt;- replicate(500, rnorm(100, 5, 2))\nsims_mean &lt;- colMeans(sims)\nggplot(data.frame(x = sims_mean), aes(x)) +\n  geom_density() +\n  stat_function(fun = dnorm, \n                args = list(mean = 5, sd = 2 / sqrt(100)),\n                col = \"red\")"
  },
  {
    "objectID": "lectures/9.html#normal-dgp",
    "href": "lectures/9.html#normal-dgp",
    "title": "Sampling Distribution",
    "section": "Normal DGP",
    "text": "Normal DGP\nWhen the data is said to have a normal distribution (DGP), there are special properties with both the mean and standard deviation, regardless of sample size."
  },
  {
    "objectID": "lectures/9.html#statistics",
    "href": "lectures/9.html#statistics",
    "title": "Sampling Distribution",
    "section": "Statistics",
    "text": "Statistics\n\n\nMean \\[\n\\bar X = \\sum ^n_{i=1} X_i\n\\]\n\nStandard Deviation \\[\ns^2 = \\frac{1}{n}\\sum ^n_{i=1} (X_i - \\bar X)^2\n\\]"
  },
  {
    "objectID": "lectures/9.html#when-the-true-mu-and-sigma-are-known",
    "href": "lectures/9.html#when-the-true-mu-and-sigma-are-known",
    "title": "Sampling Distribution",
    "section": "When the true \\(\\mu\\) and \\(\\sigma\\) are known",
    "text": "When the true \\(\\mu\\) and \\(\\sigma\\) are known\nA data sample of size \\(n\\) is generated from: \\[\nX_i \\sim N(\\mu, \\sigma)\n\\]"
  },
  {
    "objectID": "lectures/9.html#distribution-of-bar-x",
    "href": "lectures/9.html#distribution-of-bar-x",
    "title": "Sampling Distribution",
    "section": "Distribution of \\(\\bar X\\)",
    "text": "Distribution of \\(\\bar X\\)\n\\[\n\\bar X \\sim N(\\mu, \\sigma/\\sqrt{n})\n\\]"
  },
  {
    "objectID": "lectures/9.html#distribution-of-z",
    "href": "lectures/9.html#distribution-of-z",
    "title": "Sampling Distribution",
    "section": "Distribution of Z",
    "text": "Distribution of Z\n\\[\nZ = \\frac{\\bar X - \\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n\\]"
  },
  {
    "objectID": "lectures/9.html#when-the-true-mu-and-sigma-are-unknown",
    "href": "lectures/9.html#when-the-true-mu-and-sigma-are-unknown",
    "title": "Sampling Distribution",
    "section": "When the true \\(\\mu\\) and \\(\\sigma\\) are unknown",
    "text": "When the true \\(\\mu\\) and \\(\\sigma\\) are unknown\nA data sample of size \\(n\\) is generated from: \\[\nX_i \\sim N(\\mu, \\sigma)\n\\]"
  },
  {
    "objectID": "lectures/9.html#distribution-of-s2-unknown-mu",
    "href": "lectures/9.html#distribution-of-s2-unknown-mu",
    "title": "Sampling Distribution",
    "section": "Distribution of \\(s^2\\) (unknown \\(\\mu\\))",
    "text": "Distribution of \\(s^2\\) (unknown \\(\\mu\\))\n\\[\n(n-1)s^2/\\sigma^2 \\sim \\chi^2(n-1)\n\\]"
  },
  {
    "objectID": "lectures/9.html#distribution-of-z-unknown-sigma",
    "href": "lectures/9.html#distribution-of-z-unknown-sigma",
    "title": "Sampling Distribution",
    "section": "Distribution of Z (unknown \\(\\sigma\\))",
    "text": "Distribution of Z (unknown \\(\\sigma\\))\n\\[\nZ = \\frac{\\bar X - \\mu}{\\sigma/\\sqrt{n}} \\rightarrow \\frac{\\bar X - \\mu}{s/\\sqrt{n}} \\sim t(n-1)\n\\]"
  },
  {
    "objectID": "lectures/9.html#regression-coefficients",
    "href": "lectures/9.html#regression-coefficients",
    "title": "Sampling Distribution",
    "section": "Regression Coefficients",
    "text": "Regression Coefficients\nThe estimates of regression coefficients (slopes) have a distribution!\n\nBased on our outcome, we will have 2 different distributions to work with: Normal or t."
  },
  {
    "objectID": "lectures/9.html#linear-regression",
    "href": "lectures/9.html#linear-regression",
    "title": "Sampling Distribution",
    "section": "Linear Regression",
    "text": "Linear Regression\n\\[\n\\frac{\\hat\\beta_j-\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p^\\prime}\n\\]"
  },
  {
    "objectID": "lectures/9.html#beta_j-0",
    "href": "lectures/9.html#beta_j-0",
    "title": "Sampling Distribution",
    "section": "\\(\\beta_j = 0\\)",
    "text": "\\(\\beta_j = 0\\)\n\\[\n\\frac{\\hat\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim t_{n-p^\\prime}\n\\]"
  },
  {
    "objectID": "lectures/9.html#logistic-regression",
    "href": "lectures/9.html#logistic-regression",
    "title": "Sampling Distribution",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\\[\n\\frac{\\hat\\beta_j - \\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1)\n\\]"
  },
  {
    "objectID": "lectures/9.html#beta_j-0-1",
    "href": "lectures/9.html#beta_j-0-1",
    "title": "Sampling Distribution",
    "section": "\\(\\beta_j = 0\\)",
    "text": "\\(\\beta_j = 0\\)\n\\[\n\\frac{\\hat\\beta_j}{\\mathrm{se}(\\hat\\beta_j)} \\sim N(0,1)\n\\]"
  },
  {
    "objectID": "lectures/9.html#scientific-notation-1",
    "href": "lectures/9.html#scientific-notation-1",
    "title": "Sampling Distribution",
    "section": "Scientific Notation",
    "text": "Scientific Notation\nWe often work with very large or very small numbers.\n\nEarth → Sun distance: 150,000,000 km\n\nDiameter of a hydrogen atom: 0.0000000001 m\n\nProblems with standard form:\n\nHard to read\nEasy to copy wrong\nDifficult to compare\n\nScientific notation makes numbers compact and standardized."
  },
  {
    "objectID": "lectures/9.html#the-scientific-notation-form",
    "href": "lectures/9.html#the-scientific-notation-form",
    "title": "Sampling Distribution",
    "section": "The Scientific Notation Form",
    "text": "The Scientific Notation Form\nA number is in scientific notation if:\n\\[\na \\times 10^n\n\\]\nwhere:\n\n\\(a\\) is at least 1 and less than 10\n\\(n\\) is an integer (positive, negative, or zero)\n\\(10^n\\) is a power of ten"
  },
  {
    "objectID": "lectures/9.html#example-large-number",
    "href": "lectures/9.html#example-large-number",
    "title": "Sampling Distribution",
    "section": "Example: Large Number",
    "text": "Example: Large Number\nWrite 45,000 in scientific notation.\nMove decimal:\n\\[\n45000 \\rightarrow 4.5\n\\]\nMoved 4 places left:\n\\[\n4.5 \\times 10^4\n\\]"
  },
  {
    "objectID": "lectures/9.html#example-small-number",
    "href": "lectures/9.html#example-small-number",
    "title": "Sampling Distribution",
    "section": "Example: Small Number",
    "text": "Example: Small Number\nWrite 0.00072 in scientific notation.\nMove decimal:\n\\[\n0.00072 \\rightarrow 7.2\n\\]\nMoved 4 places right:\n\\[\n7.2 \\times 10^{-4}\n\\]"
  },
  {
    "objectID": "lectures/9.html#understanding-positive-exponent",
    "href": "lectures/9.html#understanding-positive-exponent",
    "title": "Sampling Distribution",
    "section": "Understanding Positive Exponent",
    "text": "Understanding Positive Exponent\nPositive exponents → big numbers\n\n\\(10^3 = 1{,}000\\)\n\\(10^6 = 1{,}000{,}000\\)\n\nExample:\n\\[\n2.1 \\times 10^6 = 2{,}100{,}000\n\\]"
  },
  {
    "objectID": "lectures/9.html#understanding-negative-exponent",
    "href": "lectures/9.html#understanding-negative-exponent",
    "title": "Sampling Distribution",
    "section": "Understanding Negative Exponent",
    "text": "Understanding Negative Exponent\nNegative exponents → small numbers\n\n\\(10^{-2} = 0.01\\)\n\\(10^{-5} = 0.00001\\)\n\nExample:\n\\[\n4.3 \\times 10^{-3} = 0.0043\n\\]"
  },
  {
    "objectID": "lectures/9.html#converting-back-to-standard-form",
    "href": "lectures/9.html#converting-back-to-standard-form",
    "title": "Sampling Distribution",
    "section": "Converting Back to Standard Form",
    "text": "Converting Back to Standard Form\nRule:\n\n\\(10^{+n}\\): move decimal right \\(n\\) places\n\\(10^{-n}\\): move decimal left \\(n\\) places"
  },
  {
    "objectID": "lectures/9.html#convert-example-positive-exponent",
    "href": "lectures/9.html#convert-example-positive-exponent",
    "title": "Sampling Distribution",
    "section": "Convert Example (Positive Exponent)",
    "text": "Convert Example (Positive Exponent)\n\\[\n6.2 \\times 10^5\n\\]\nMove decimal 5 places right:\n\\[\n620{,}000\n\\]"
  },
  {
    "objectID": "lectures/9.html#convert-example-negative-exponent",
    "href": "lectures/9.html#convert-example-negative-exponent",
    "title": "Sampling Distribution",
    "section": "Convert Example (Negative Exponent)",
    "text": "Convert Example (Negative Exponent)\n\\[\n9.1 \\times 10^{-4}\n\\]\nMove decimal 4 places left:\n\\[\n0.00091\n\\]"
  },
  {
    "objectID": "lectures/9.html#comparing-numbers-in-scientific-notation",
    "href": "lectures/9.html#comparing-numbers-in-scientific-notation",
    "title": "Sampling Distribution",
    "section": "Comparing Numbers in Scientific Notation",
    "text": "Comparing Numbers in Scientific Notation\nStep 1: Compare exponents\n\nBigger exponent → bigger number\n\nStep 2: If exponents match, compare coefficients \\(a\\)\nExample:\n\n\\(3.2 \\times 10^5\\)\n\\(7.1 \\times 10^4\\)\n\nSince \\(10^5 &gt; 10^4\\), the first number is larger."
  },
  {
    "objectID": "lectures/9.html#scientific-notation-in-r",
    "href": "lectures/9.html#scientific-notation-in-r",
    "title": "Sampling Distribution",
    "section": "Scientific Notation in R",
    "text": "Scientific Notation in R\nR often displays very large/small numbers using e notation.\n\\[\na \\times 10^n \\quad \\text{is shown as} \\quad a\\text{e}n\n\\]\nExamples:\n\n3e+06 means \\(3 \\times 10^6\\)\n4.5e-04 means \\(4.5 \\times 10^{-4}\\)"
  },
  {
    "objectID": "lectures/7.html#r-packages",
    "href": "lectures/7.html#r-packages",
    "title": "Group  Regression",
    "section": "R Packages",
    "text": "R Packages\n\nrcistats\ntidyverse"
  },
  {
    "objectID": "lectures/7.html#palmer-penguins-data",
    "href": "lectures/7.html#palmer-penguins-data",
    "title": "Group  Regression",
    "section": "Palmer Penguins Data",
    "text": "Palmer Penguins Data\n\n\nVariables of Interest\n\nspecies: Penguin species\nbody_mass: Body mass in grams\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lectures/7.html#heart-disease-data",
    "href": "lectures/7.html#heart-disease-data",
    "title": "Group  Regression",
    "section": "Heart Disease Data",
    "text": "Heart Disease Data\n\n\nVariables of Interest\n\nthal: Thallium stress test result\ndisease: Indicating if they have heart disease"
  },
  {
    "objectID": "lectures/7.html#explaining-continuous-variables",
    "href": "lectures/7.html#explaining-continuous-variables",
    "title": "Group  Regression",
    "section": "Explaining Continuous Variables",
    "text": "Explaining Continuous Variables\n\n\nCode\nggplot(penguins, aes(body_mass)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/7.html#linear-categorical-variables",
    "href": "lectures/7.html#linear-categorical-variables",
    "title": "Group  Regression",
    "section": "Linear: Categorical Variables",
    "text": "Linear: Categorical Variables\n\n\nCode\nggplot(penguins, aes(body_mass, fill = species)) +\n  geom_density(alpha = .5)"
  },
  {
    "objectID": "lectures/7.html#explainging-binary-variables",
    "href": "lectures/7.html#explainging-binary-variables",
    "title": "Group  Regression",
    "section": "Explainging Binary Variables",
    "text": "Explainging Binary Variables\n\n\nCode\nheart_disease |&gt; \n  ggplot(aes(disease)) +\n  geom_bar()"
  },
  {
    "objectID": "lectures/7.html#logistic-categorical-variables",
    "href": "lectures/7.html#logistic-categorical-variables",
    "title": "Group  Regression",
    "section": "Logistic: Categorical Variables",
    "text": "Logistic: Categorical Variables\n\n\nCode\nheart_disease |&gt; \n  ggplot(aes(disease, fill = thal)) +\n  geom_bar()"
  },
  {
    "objectID": "lectures/7.html#group-statistics-1",
    "href": "lectures/7.html#group-statistics-1",
    "title": "Group  Regression",
    "section": "Group Statistics",
    "text": "Group Statistics\nWe can use statistics to explain a variable by the categories.\n\nCompute statistics for each group."
  },
  {
    "objectID": "lectures/7.html#continuous-data",
    "href": "lectures/7.html#continuous-data",
    "title": "Group  Regression",
    "section": "Continuous Data",
    "text": "Continuous Data\nnum_by_cat_stats(DATA, NUM, CAT)\n\nNUM: Name of the numerical variable\nCAT: Name of the categorical variable\nDATA: Name of the data frame"
  },
  {
    "objectID": "lectures/7.html#continous-data",
    "href": "lectures/7.html#continous-data",
    "title": "Group  Regression",
    "section": "Continous Data",
    "text": "Continous Data\n\nnum_by_cat_stats(penguins, body_mass, species)\n\n#&gt;   Categories  min    q25     mean median  q75  max      sd      var   iqr\n#&gt; 1     Adelie 2850 3362.5 3706.164   3700 4000 4775 458.620 210332.4 637.5\n#&gt; 2  Chinstrap 2700 3487.5 3733.088   3700 3950 4800 384.335 147713.5 462.5\n#&gt; 3     Gentoo 3950 4700.0 5092.437   5050 5500 6300 501.476 251478.3 800.0\n#&gt;   missing\n#&gt; 1       0\n#&gt; 2       0\n#&gt; 3       0"
  },
  {
    "objectID": "lectures/7.html#continuous-data-1",
    "href": "lectures/7.html#continuous-data-1",
    "title": "Group  Regression",
    "section": "Continuous Data",
    "text": "Continuous Data\ncat_stats(DATA$Y, DATA$X, prop = \"row\")\nOR\ncat_stats(DATA$X, DATA$Y, prop = \"col\")\n\nY: Name of the outcome variable\nX: Name of the categorical variable\nDATA: Name of the data frame"
  },
  {
    "objectID": "lectures/7.html#binary-data",
    "href": "lectures/7.html#binary-data",
    "title": "Group  Regression",
    "section": "Binary Data",
    "text": "Binary Data\n\ncat_stats(heart_disease$disease, heart_disease$thal, prop = \"row\")\n\n#&gt; $frequency\n#&gt;      \n#&gt;       Normal Fixed Defect Reversible Defect\n#&gt;   no     127            6                27\n#&gt;   yes     37           12                88\n#&gt; \n#&gt; $row_prop\n#&gt;      \n#&gt;       Normal Fixed Defect Reversible Defect\n#&gt;   no  0.7938       0.0375            0.1688\n#&gt;   yes 0.2701       0.0876            0.6423"
  },
  {
    "objectID": "lectures/7.html#glm-with-categorical-variables",
    "href": "lectures/7.html#glm-with-categorical-variables",
    "title": "Group  Regression",
    "section": "G/LM with Categorical Variables",
    "text": "G/LM with Categorical Variables\nA line is normally used to model 2 continuous variables.\n\nHowever, the predictor variable \\(X\\) can be restricted to a set a dummy variables that can symbolize categories.\n\n\nA category from \\(X\\) will be used as a reference for a model."
  },
  {
    "objectID": "lectures/7.html#lm-example",
    "href": "lectures/7.html#lm-example",
    "title": "Group  Regression",
    "section": "LM Example",
    "text": "LM Example\n\\[\nbody\\_mass = \\beta_0 + \\boldsymbol \\beta (species)\n\\]\n\n\\[\nbody\\_mass = \\beta_0 + \\beta_1 (Chinstrap) + \\beta_2 (Gentoo)\n\\]\n\n\n\\(Chinstrap\\) and \\(Gentoo\\) are both dummy variables that will reference Adelie"
  },
  {
    "objectID": "lectures/7.html#glm-example",
    "href": "lectures/7.html#glm-example",
    "title": "Group  Regression",
    "section": "GLM Example",
    "text": "GLM Example\n\\[\nlo(disease) = \\beta_0 + \\boldsymbol \\beta (thal)\n\\]\n\n\\[\nlo(disease) = \\beta_0 + \\beta_1 (Fixed) + \\beta_2 (Reversible)\n\\]\n\n\n\\(Fixed\\) and \\(Reversible\\) defects are both dummy variables that will reference Normal"
  },
  {
    "objectID": "lectures/7.html#dummy-variables",
    "href": "lectures/7.html#dummy-variables",
    "title": "Group  Regression",
    "section": "Dummy Variables",
    "text": "Dummy Variables\nTo fit a model with categorical variables, we must utilize dummy (binary) variables that indicate which category is being referenced. We use \\(C-1\\) dummy variables where \\(C\\) indicates the number of categories. When coded correctly, each category will be represented by a combination of dummy variables."
  },
  {
    "objectID": "lectures/7.html#dummy-variables-1",
    "href": "lectures/7.html#dummy-variables-1",
    "title": "Group  Regression",
    "section": "Dummy Variables",
    "text": "Dummy Variables\nBinary variables are variable that can only take on the value 0 or 1.\n\\[\nD_i = \\left\\{\n\\begin{array}{cc}\n1 & Category\\\\\n0 & Other\n\\end{array}\n\\right.\n\\]"
  },
  {
    "objectID": "lectures/7.html#example",
    "href": "lectures/7.html#example",
    "title": "Group  Regression",
    "section": "Example",
    "text": "Example\nIf we have 4 categories, we will need 3 dummy variables:\n\n\n\n\nCat 1\nCat 2\nCat 3\nCat 4\n\n\n\n\nDummy 1\n1\n0\n0\n0\n\n\nDummy 2\n0\n1\n0\n0\n\n\nDummy 2\n0\n0\n1\n0"
  },
  {
    "objectID": "lectures/7.html#species-dummy-variables",
    "href": "lectures/7.html#species-dummy-variables",
    "title": "Group  Regression",
    "section": "Species Dummy Variables",
    "text": "Species Dummy Variables\n\n\n\nDUMMY\nChinstrap\nGentoo\nAdelie (Reference)\n\n\n\n\n\\(Chinstrap\\)\n1\n0\n0\n\n\n\\(Gentoo\\)\n0\n1\n0"
  },
  {
    "objectID": "lectures/7.html#thal-dummy-variables",
    "href": "lectures/7.html#thal-dummy-variables",
    "title": "Group  Regression",
    "section": "Thal Dummy Variables",
    "text": "Thal Dummy Variables\n\n\n\nDUMMY\nFixed Defect\nReversible Defect\nNormal (Reference)\n\n\n\n\n\\(Fixed\\)\n1\n0\n0\n\n\n\\(Reversible\\)\n0\n1\n0"
  },
  {
    "objectID": "lectures/7.html#lm-penguins",
    "href": "lectures/7.html#lm-penguins",
    "title": "Group  Regression",
    "section": "LM: Penguins",
    "text": "LM: Penguins\n\\[\nbody\\_mass = \\hat \\beta_0 + \\hat\\beta_1 (Chinstrap) + \\hat\\beta_2 (Gentoo)\n\\]\n\n\\(\\hat \\beta_1\\) indicates how body mass changes from Adelie to Chinstrap.\n\n\n\\(\\hat \\beta_2\\) indicates how body mass changes from Adelie to Gentoo.\n\n\n\\(\\hat \\beta_0\\) represents the baseline level, in this case the body mass of Adelie."
  },
  {
    "objectID": "lectures/7.html#glm-penguins",
    "href": "lectures/7.html#glm-penguins",
    "title": "Group  Regression",
    "section": "GLM: Penguins",
    "text": "GLM: Penguins\n\\[\nlo(disease) = \\hat \\beta_0 + \\hat\\beta_1 (Fixed) + \\hat\\beta_2 (Reversible)\n\\]\n\n\\(\\hat \\beta_1\\) indicates how \\(lo(disease)\\) changes from Normal to Fixed.\n\n\n\\(\\hat \\beta_2\\) indicates how \\(lo(disease)\\) changes from Normal to Reversible.\n\n\n\\(\\hat \\beta_0\\) represents the baseline level, in this case the \\(lo(disease)\\) of Normal."
  },
  {
    "objectID": "lectures/7.html#interepreting-beta",
    "href": "lectures/7.html#interepreting-beta",
    "title": "Group  Regression",
    "section": "Interepreting \\(\\beta\\)",
    "text": "Interepreting \\(\\beta\\)\nInterpreting \\(\\beta\\) for categorical variables are different from continuous (numeric) variables. Interpreting \\(\\beta\\)s only allow us to make comparisons between the dummy indicator category and the reference category"
  },
  {
    "objectID": "lectures/7.html#lm-interpreting-beta",
    "href": "lectures/7.html#lm-interpreting-beta",
    "title": "Group  Regression",
    "section": "LM: Interpreting \\(\\beta\\)",
    "text": "LM: Interpreting \\(\\beta\\)\n\n\n\\[\n\\hat Y = \\hat \\beta_0 + \\hat\\beta_1 D\n\\]\n\n\\[\nD = \\left\\{\n\\begin{array}{cc}\n1 & CAT\\\\\n0 & REF\n\\end{array}\n\\right.\n\\]\n\nOn average, CAT1 has a larger/smaller Y than REF by about \\(\\beta_1\\)."
  },
  {
    "objectID": "lectures/7.html#glm-interpreting-beta",
    "href": "lectures/7.html#glm-interpreting-beta",
    "title": "Group  Regression",
    "section": "GLM: Interpreting \\(\\beta\\)",
    "text": "GLM: Interpreting \\(\\beta\\)\n\n\n\\[\nlo(Y) = \\hat \\beta_0 + \\hat\\beta_1 D\n\\]\n\n\\[\nD = \\left\\{\n\\begin{array}{cc}\n1 & CAT\\\\\n0 & REF\n\\end{array}\n\\right.\n\\]\n\nThe odds of having Y is \\(e^{\\beta_1}\\) times higher/lower for CAT than Ref."
  },
  {
    "objectID": "lectures/7.html#fitting-an-lm-in-r",
    "href": "lectures/7.html#fitting-an-lm-in-r",
    "title": "Group  Regression",
    "section": "Fitting an LM in R",
    "text": "Fitting an LM in R\nxlm &lt;- lm(Y ~ X, data = DATA)\nxlm\n\nX: Name Predictor Variable of Interest in data frame DATA, must be a factor variable\nY: Name Outcome Variable of Interest in data frame DATA\nDATA: Name of the data frame"
  },
  {
    "objectID": "lectures/7.html#fitting-an-glm-in-r",
    "href": "lectures/7.html#fitting-an-glm-in-r",
    "title": "Group  Regression",
    "section": "Fitting an GLM in R",
    "text": "Fitting an GLM in R\nxglm &lt;- glm(Y ~ X, data = DATA, family = binomial())\nxglm\n\nX: Name Predictor Variable of Interest in data frame DATA, must be a factor variable\nY: Name Outcome Variable of Interest in data frame DATA\nDATA: Name of the data frame"
  },
  {
    "objectID": "lectures/7.html#x-not-a-factor",
    "href": "lectures/7.html#x-not-a-factor",
    "title": "Group  Regression",
    "section": "X not a Factor",
    "text": "X not a Factor\nxlm &lt;- lm(Y ~ factor(X), data = DATA)\nOR\nxglm &lt;- glm(Y ~ factor(X), data = DATA, family = binomial())\n\nX: Name Predictor Variable of Interest in data frame DATA, not a factor variable\nY: Name Outcome Variable of Interest in data frame DATA\nDATA: Name of the data frame"
  },
  {
    "objectID": "lectures/7.html#example-1",
    "href": "lectures/7.html#example-1",
    "title": "Group  Regression",
    "section": "Example",
    "text": "Example\n\nxlm &lt;- lm(body_mass ~ species, penguins)\nxlm\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ species, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt;      (Intercept)  speciesChinstrap     speciesGentoo  \n#&gt;          3706.16             26.92           1386.27\n\n\n\\[\n\\hat Y_i = 3706 + 26.92 (Chinstrap) + 1386.27 (Gentoo)\n\\]"
  },
  {
    "objectID": "lectures/7.html#intepreting-hat-beta_1",
    "href": "lectures/7.html#intepreting-hat-beta_1",
    "title": "Group  Regression",
    "section": "Intepreting \\(\\hat \\beta_1\\)",
    "text": "Intepreting \\(\\hat \\beta_1\\)\nOn average, Chinstrap has a larger mass than Adelie by about 26.92 grams."
  },
  {
    "objectID": "lectures/7.html#intepreting-hat-beta_2",
    "href": "lectures/7.html#intepreting-hat-beta_2",
    "title": "Group  Regression",
    "section": "Intepreting \\(\\hat \\beta_2\\)",
    "text": "Intepreting \\(\\hat \\beta_2\\)\nOn average, Gentoo has a larger mass than Adelie by about 1386.27 grams."
  },
  {
    "objectID": "lectures/7.html#finding-the-adelie-mass",
    "href": "lectures/7.html#finding-the-adelie-mass",
    "title": "Group  Regression",
    "section": "Finding the Adelie MASS",
    "text": "Finding the Adelie MASS\n\\[\n\\hat Y_i = 3706 + 26.92 (0) + 1386.27 (0)\n\\]"
  },
  {
    "objectID": "lectures/7.html#finding-the-chinstrap-mass",
    "href": "lectures/7.html#finding-the-chinstrap-mass",
    "title": "Group  Regression",
    "section": "Finding the Chinstrap MASS",
    "text": "Finding the Chinstrap MASS\n\\[\n\\hat Y_i = 3706 + 26.92 (1) + 1386.27 (0)\n\\]"
  },
  {
    "objectID": "lectures/7.html#finding-the-gentoo-mass",
    "href": "lectures/7.html#finding-the-gentoo-mass",
    "title": "Group  Regression",
    "section": "Finding the Gentoo MASS",
    "text": "Finding the Gentoo MASS\n\\[\n\\hat Y_i = 3706 + 26.92 (0) + 1386.27 (1)\n\\]"
  },
  {
    "objectID": "lectures/7.html#prediction-in-r",
    "href": "lectures/7.html#prediction-in-r",
    "title": "Group  Regression",
    "section": "Prediction in R",
    "text": "Prediction in R\n\nGentooChinstrapAdelie\n\n\n\nxlm &lt;- lm(body_mass ~ species,\n            data = penguins)\npredict_df &lt;- data.frame(species = \"Gentoo\")\npredict(xlm,\n        predict_df)\n\n#&gt;        1 \n#&gt; 5092.437\n\n\n\n\n\nxlm &lt;- lm(body_mass ~ species,\n            data = penguins)\npredict_df &lt;- data.frame(species = \"Chinstrap\")\npredict(xlm,\n        predict_df)\n\n#&gt;        1 \n#&gt; 3733.088\n\n\n\n\n\nxlm &lt;- lm(body_mass ~ species,\n            data = penguins)\npredict_df &lt;- data.frame(species = \"Adelie\")\npredict(xlm,\n        predict_df)\n\n#&gt;        1 \n#&gt; 3706.164"
  },
  {
    "objectID": "lectures/7.html#example-2",
    "href": "lectures/7.html#example-2",
    "title": "Group  Regression",
    "section": "Example",
    "text": "Example\n\nxglm &lt;- glm(disease ~ thal, \n            data = heart_disease, \n            family = binomial())\nxglm\n\n#&gt; \n#&gt; Call:  glm(formula = disease ~ thal, family = binomial(), data = heart_disease)\n#&gt; \n#&gt; Coefficients:\n#&gt;           (Intercept)       thalFixed Defect  thalReversible Defect  \n#&gt;                -1.233                  1.926                  2.415  \n#&gt; \n#&gt; Degrees of Freedom: 296 Total (i.e. Null);  294 Residual\n#&gt; Null Deviance:       409.9 \n#&gt; Residual Deviance: 323.4     AIC: 329.4\n\n\n\\[\nlo(disease) = -1.233 + 1.926 (Fixed) + 2.415 (Reversible)\n\\]"
  },
  {
    "objectID": "lectures/7.html#intepreting-hat-beta_1-1",
    "href": "lectures/7.html#intepreting-hat-beta_1-1",
    "title": "Group  Regression",
    "section": "Intepreting \\(\\hat \\beta_1\\)",
    "text": "Intepreting \\(\\hat \\beta_1\\)\n\n\nCode\nexp(1.926)\n\n\n#&gt; [1] 6.862007\n\n\nThe odds of having heart disease is 6.86 times higher for a patient who has a fixed defect than a patient who is normal."
  },
  {
    "objectID": "lectures/7.html#intepreting-hat-beta_2-1",
    "href": "lectures/7.html#intepreting-hat-beta_2-1",
    "title": "Group  Regression",
    "section": "Intepreting \\(\\hat \\beta_2\\)",
    "text": "Intepreting \\(\\hat \\beta_2\\)\n\n\nCode\nexp(2.415)\n\n\n#&gt; [1] 11.18977\n\n\nThe odds of having heart disease is 11.19 times higher for a patient who has a reversible defect than a patient who is normal."
  },
  {
    "objectID": "lectures/7.html#prediction-in-r-1",
    "href": "lectures/7.html#prediction-in-r-1",
    "title": "Group  Regression",
    "section": "Prediction in R",
    "text": "Prediction in R\n\nFixed DefectReversible DefectNormal\n\n\n\nxglm &lt;- glm(disease ~ thal, data = heart_disease,\n            family = binomial())\npdf &lt;- data.frame(thal = \"Fixed Defect\")\npredict(xglm, pdf, type = \"response\")\n\n#&gt;         1 \n#&gt; 0.6666667\n\n\n\n\n\nxglm &lt;- glm(disease ~ thal, data = heart_disease,\n            family = binomial())\npdf &lt;- data.frame(thal = \"Reversible Defect\")\npredict(xglm, pdf, type = \"response\")\n\n#&gt;         1 \n#&gt; 0.7652174\n\n\n\n\n\nxglm &lt;- glm(disease ~ thal, data = heart_disease,\n            family = binomial())\npdf &lt;- data.frame(thal = \"Normal\")\npredict(xglm, pdf, type = \"response\")\n\n#&gt;         1 \n#&gt; 0.2256098"
  },
  {
    "objectID": "lectures/5.html#r-packages",
    "href": "lectures/5.html#r-packages",
    "title": "Simple  Linear Regression",
    "section": "R Packages",
    "text": "R Packages\n\nrcistats\ntidyverse"
  },
  {
    "objectID": "lectures/5.html#palmer-penguins-data",
    "href": "lectures/5.html#palmer-penguins-data",
    "title": "Simple  Linear Regression",
    "section": "Palmer Penguins Data",
    "text": "Palmer Penguins Data\n\n\nVariables of Interest\n\nflipper_len: Flipper Length in millimeters\nbody_mass: Body mass in grams\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lectures/5.html#variables-of-interest-1",
    "href": "lectures/5.html#variables-of-interest-1",
    "title": "Simple  Linear Regression",
    "section": "Variables of Interest",
    "text": "Variables of Interest"
  },
  {
    "objectID": "lectures/5.html#explaining-variation",
    "href": "lectures/5.html#explaining-variation",
    "title": "Simple  Linear Regression",
    "section": "Explaining Variation",
    "text": "Explaining Variation\n\nThis is the process where we try to reduce the variation with the use of other variables.\n\n\nCan be thought of as getting it less wrong when taking an educated guess."
  },
  {
    "objectID": "lectures/5.html#modeling-variation",
    "href": "lectures/5.html#modeling-variation",
    "title": "Simple  Linear Regression",
    "section": "Modeling Variation",
    "text": "Modeling Variation\n\n\nCode\nggplot(penguins, aes(body_mass)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/5.html#modeling-variation-with-bar-x",
    "href": "lectures/5.html#modeling-variation-with-bar-x",
    "title": "Simple  Linear Regression",
    "section": "Modeling Variation with \\(\\bar X\\)",
    "text": "Modeling Variation with \\(\\bar X\\)\n\n\nCode\nggplot(penguins, aes(body_mass)) +\n  geom_density() +\n  geom_vline(xintercept = mean(penguins$body_mass))"
  },
  {
    "objectID": "lectures/5.html#modeling-with-a-numerical-variable",
    "href": "lectures/5.html#modeling-with-a-numerical-variable",
    "title": "Simple  Linear Regression",
    "section": "Modeling with a Numerical Variable",
    "text": "Modeling with a Numerical Variable\n\n\nCode\nggplot(penguins, aes(x = flipper_len, y = body_mass)) +\n  geom_point() +\n  stat_density_2d(aes(fill = after_stat(level))) +\n  xlim(c(170, 236)) +\n  ylim(c(2500, 6250))"
  },
  {
    "objectID": "lectures/5.html#modeling-with-a-numerical-variable-1",
    "href": "lectures/5.html#modeling-with-a-numerical-variable-1",
    "title": "Simple  Linear Regression",
    "section": "Modeling with a Numerical Variable",
    "text": "Modeling with a Numerical Variable\n\n\nCode\nggplot(penguins, aes(x = flipper_len, y = body_mass)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F, col = \"red\") +\n  stat_density_2d(aes(fill = after_stat(level))) +\n  xlim(c(170, 236)) +\n  ylim(c(2500, 6250))"
  },
  {
    "objectID": "lectures/5.html#generated-model",
    "href": "lectures/5.html#generated-model",
    "title": "Simple  Linear Regression",
    "section": "Generated Model",
    "text": "Generated Model\n\\[\nY \\sim DGP_1\n\\]"
  },
  {
    "objectID": "lectures/5.html#a-simple-model-1",
    "href": "lectures/5.html#a-simple-model-1",
    "title": "Simple  Linear Regression",
    "section": "A Simple Model",
    "text": "A Simple Model\n\n\nCode\nggplot(penguins, aes(body_mass)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/5.html#a-simple-model-2",
    "href": "lectures/5.html#a-simple-model-2",
    "title": "Simple  Linear Regression",
    "section": "A Simple Model",
    "text": "A Simple Model\n\\[\nY = \\_\\_\\_ + error\n\\]"
  },
  {
    "objectID": "lectures/5.html#notation",
    "href": "lectures/5.html#notation",
    "title": "Simple  Linear Regression",
    "section": "Notation",
    "text": "Notation\n\\[\nY = \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\varepsilon\n\\]"
  },
  {
    "objectID": "lectures/5.html#the-simple-generated-model",
    "href": "lectures/5.html#the-simple-generated-model",
    "title": "Simple  Linear Regression",
    "section": "The Simple Generated Model",
    "text": "The Simple Generated Model\n\\[\nY \\sim \\beta_0 + \\varepsilon\n\\]\n\\[\n\\varepsilon \\sim DGP_2\n\\]\n\n\\(DGP_2\\) is not the same as the \\(DGP_1\\), it is transformed due \\(\\beta_0\\). Consider this the NULL \\(DGP\\)."
  },
  {
    "objectID": "lectures/5.html#observing-data",
    "href": "lectures/5.html#observing-data",
    "title": "Simple  Linear Regression",
    "section": "Observing Data",
    "text": "Observing Data\n\\[\nY = \\beta_0 + \\varepsilon\n\\]"
  },
  {
    "objectID": "lectures/5.html#estimated-line",
    "href": "lectures/5.html#estimated-line",
    "title": "Simple  Linear Regression",
    "section": "Estimated Line",
    "text": "Estimated Line\n\\[\n\\hat Y=\\hat\\beta_0\n\\]"
  },
  {
    "objectID": "lectures/5.html#notation-1",
    "href": "lectures/5.html#notation-1",
    "title": "Simple  Linear Regression",
    "section": "Notation",
    "text": "Notation\n\n\nObserved\n\\[\nY = \\beta_0 + \\varepsilon\n\\]\n\nEstimated\n\\[\n\\hat Y = \\hat \\beta_0\n\\]"
  },
  {
    "objectID": "lectures/5.html#indexing-data",
    "href": "lectures/5.html#indexing-data",
    "title": "Simple  Linear Regression",
    "section": "Indexing Data",
    "text": "Indexing Data\nThe data in a data set can be indexed by a number.\n\n\nCode\npenguins[1,-c(1:2)]\n\n\n#&gt;   bill_len bill_dep flipper_len body_mass  sex year\n#&gt; 1     39.1     18.7         181      3750 male 2007\n\n\n\nMaking the variable body_mass be represented by \\(Y\\) and flipper_len as \\(X\\):\n\\[\nY_1 = 3750 \\ \\ X_1=181\n\\]"
  },
  {
    "objectID": "lectures/5.html#indexing-data-1",
    "href": "lectures/5.html#indexing-data-1",
    "title": "Simple  Linear Regression",
    "section": "Indexing Data",
    "text": "Indexing Data\n\\[\nY_i, X_i\n\\]"
  },
  {
    "objectID": "lectures/5.html#data",
    "href": "lectures/5.html#data",
    "title": "Simple  Linear Regression",
    "section": "Data",
    "text": "Data\nWith the data that we collect from a sample, we hypothesize how the data was generated.\n\nUsing a simple model:\n\\[\nY_i = \\beta_0 + \\varepsilon_i\n\\]"
  },
  {
    "objectID": "lectures/5.html#estimated-value",
    "href": "lectures/5.html#estimated-value",
    "title": "Simple  Linear Regression",
    "section": "Estimated Value",
    "text": "Estimated Value\n\\[\n\\hat Y_i = \\hat \\beta_0\n\\]"
  },
  {
    "objectID": "lectures/5.html#estimation",
    "href": "lectures/5.html#estimation",
    "title": "Simple  Linear Regression",
    "section": "Estimation",
    "text": "Estimation\nTo estimate \\(\\hat \\beta_0\\), we minimize the follow function:\n\\[\n\\sum^n_{i=1} (Y_i-\\hat Y_i)^2\n\\]\n\nThis is known as the sum squared errors, SSE"
  },
  {
    "objectID": "lectures/5.html#residuals",
    "href": "lectures/5.html#residuals",
    "title": "Simple  Linear Regression",
    "section": "Residuals",
    "text": "Residuals\nThe residuals are known as the observed errors from the data in the model:\n\\[\nr_i = Y_i - \\hat Y_i\n\\]"
  },
  {
    "objectID": "lectures/5.html#estimation-in-r",
    "href": "lectures/5.html#estimation-in-r",
    "title": "Simple  Linear Regression",
    "section": "Estimation in R",
    "text": "Estimation in R\n\n\nCode\nlm(Y ~ 1, data = DATA)\n\n\n\nY: Name Outcome Variable of Interest in data frame DATA\nDATA: Name of the data frame"
  },
  {
    "objectID": "lectures/5.html#modeling-body-mass-in-penguins",
    "href": "lectures/5.html#modeling-body-mass-in-penguins",
    "title": "Simple  Linear Regression",
    "section": "Modeling Body Mass in Penguins",
    "text": "Modeling Body Mass in Penguins\n\n\nCode\nxlm &lt;- lm(body_mass ~ 1, data = penguins)\nxlm\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ 1, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)  \n#&gt;        4207\n\n\n\n\\[\n\\hat Y = 4207\n\\]"
  },
  {
    "objectID": "lectures/5.html#visualize",
    "href": "lectures/5.html#visualize",
    "title": "Simple  Linear Regression",
    "section": "Visualize",
    "text": "Visualize\n\n\nCode\nggplot(penguins, aes(body_mass)) +\n  geom_density() +\n  geom_vline(xintercept = 4207)"
  },
  {
    "objectID": "lectures/5.html#linear-model-1",
    "href": "lectures/5.html#linear-model-1",
    "title": "Simple  Linear Regression",
    "section": "Linear Model",
    "text": "Linear Model\nThe goal of Statistics is to develop models the have a better explanation of the outcome \\(Y\\).\n\nIn particularly, reduce the sum of squared errors.\n\n\nBy utilizing a bit more of information, \\(X\\), we can increase the predicting capabilities of the model.\n\n\nThus, the linear model is born."
  },
  {
    "objectID": "lectures/5.html#visualization",
    "href": "lectures/5.html#visualization",
    "title": "Simple  Linear Regression",
    "section": "Visualization",
    "text": "Visualization\n\n1-Dimensional2-Dimensional\n\n\n\n\nCode\nggplot(penguins, aes(body_mass)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(penguins, aes(x = flipper_len, y = body_mass)) +\n  geom_point() +\n  stat_density_2d(aes(fill = after_stat(level))) +\n  xlim(c(170, 236)) +\n  ylim(c(2500, 6250))"
  },
  {
    "objectID": "lectures/5.html#linear-model-2",
    "href": "lectures/5.html#linear-model-2",
    "title": "Simple  Linear Regression",
    "section": "Linear Model",
    "text": "Linear Model\n\\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon\n\\]\n\\[\n\\varepsilon \\sim DGP_3\n\\]"
  },
  {
    "objectID": "lectures/5.html#scatter-plot",
    "href": "lectures/5.html#scatter-plot",
    "title": "Simple  Linear Regression",
    "section": "Scatter Plot",
    "text": "Scatter Plot\n\n\nCode\nggplot(penguins, aes(flipper_len, body_mass)) + \n  geom_point()"
  },
  {
    "objectID": "lectures/5.html#imposing-a-line",
    "href": "lectures/5.html#imposing-a-line",
    "title": "Simple  Linear Regression",
    "section": "Imposing a Line",
    "text": "Imposing a Line\n\n\nCode\nggplot(penguins, aes(flipper_len, body_mass)) + \n  geom_point() +\n  stat_smooth(method = \"lm\", se = F)"
  },
  {
    "objectID": "lectures/5.html#modelling-the-data",
    "href": "lectures/5.html#modelling-the-data",
    "title": "Simple  Linear Regression",
    "section": "Modelling the Data",
    "text": "Modelling the Data\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n\\]"
  },
  {
    "objectID": "lectures/5.html#linear-model-3",
    "href": "lectures/5.html#linear-model-3",
    "title": "Simple  Linear Regression",
    "section": "Linear Model",
    "text": "Linear Model\n\\[\n\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\n\\]\n\nGoal is to obtain numerical values for \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\) that will minimize the SSE."
  },
  {
    "objectID": "lectures/5.html#sse",
    "href": "lectures/5.html#sse",
    "title": "Simple  Linear Regression",
    "section": "SSE",
    "text": "SSE\n\\[\n\\sum^n_{i=1} (Y_i-\\hat Y_i)^2\n\\]\n\\[\n\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\n\\]"
  },
  {
    "objectID": "lectures/5.html#fitting-a-model-in-r",
    "href": "lectures/5.html#fitting-a-model-in-r",
    "title": "Simple  Linear Regression",
    "section": "Fitting a Model in R",
    "text": "Fitting a Model in R\n\n\nCode\nxlm &lt;- lm(Y ~ X, data = DATA)\nxlm\n\n\n\nX: Name Predictor Variable of Interest in data frame DATA\nY: Name Outcome Variable of Interest in data frame DATA\nDATA: Name of the data frame"
  },
  {
    "objectID": "lectures/5.html#example",
    "href": "lectures/5.html#example",
    "title": "Simple  Linear Regression",
    "section": "Example",
    "text": "Example\nY: body_mass; X: flipper_len\n\n\nCode\nxlm &lt;- lm(body_mass ~ flipper_len, data = penguins)\nxlm\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ flipper_len, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)  flipper_len  \n#&gt;    -5872.09        50.15\n\n\n\\[\n\\hat Y_i = -5872.09 + 50.15 X_i\n\\]"
  },
  {
    "objectID": "lectures/5.html#interpretation-of-hatbeta_0",
    "href": "lectures/5.html#interpretation-of-hatbeta_0",
    "title": "Simple  Linear Regression",
    "section": "Interpretation of \\(\\hat\\beta_0\\)",
    "text": "Interpretation of \\(\\hat\\beta_0\\)\nThe intercept \\(\\hat \\beta_0\\) can be interpreted as the base value when \\(X\\) is set to 0.\n\nSome times the intercept can be interpretable to real world scenarios.\n\n\nOther times it cannot."
  },
  {
    "objectID": "lectures/5.html#interpreting-example",
    "href": "lectures/5.html#interpreting-example",
    "title": "Simple  Linear Regression",
    "section": "Interpreting Example",
    "text": "Interpreting Example\n\\[\n\\hat Y_i = -5872.09 + 50.15 X_i\n\\]\nWhen flipper length is 0 mm, the body mass is -5872 grams."
  },
  {
    "objectID": "lectures/5.html#interpretation-of-hat-beta_1",
    "href": "lectures/5.html#interpretation-of-hat-beta_1",
    "title": "Simple  Linear Regression",
    "section": "Interpretation of \\(\\hat \\beta_1\\)",
    "text": "Interpretation of \\(\\hat \\beta_1\\)\nThe slope \\(\\hat \\beta_1\\) indicates how will y change when x increases by 1 unit.\n\nIt will demonstrate if there is, on average, a positive or negative relationship based on the sign provided."
  },
  {
    "objectID": "lectures/5.html#interpreting-example-1",
    "href": "lectures/5.html#interpreting-example-1",
    "title": "Simple  Linear Regression",
    "section": "Interpreting Example",
    "text": "Interpreting Example\n\\[\n\\hat Y_i = -5872.09 + 50.15 X_i\n\\]\nWhen flipper length increases by 1 mm, the body mass will increase by 50.15 grams."
  },
  {
    "objectID": "lectures/5.html#statistical-model",
    "href": "lectures/5.html#statistical-model",
    "title": "Simple  Linear Regression",
    "section": "Statistical Model",
    "text": "Statistical Model\n\\[\n\\hat Y = \\hat \\beta_0 + \\hat \\beta_1 X\n\\]\n\n\\(X\\): Input\n\\(\\hat Y\\): Output"
  },
  {
    "objectID": "lectures/5.html#prediction-1",
    "href": "lectures/5.html#prediction-1",
    "title": "Simple  Linear Regression",
    "section": "Prediction",
    "text": "Prediction\nUsing the equation \\(\\hat Y\\), we can give it a value of \\(X\\) and then, in return, a value of \\(\\hat Y\\) that predicts the true value \\(Y\\)."
  },
  {
    "objectID": "lectures/5.html#prediction-in-r",
    "href": "lectures/5.html#prediction-in-r",
    "title": "Simple  Linear Regression",
    "section": "Prediction in R",
    "text": "Prediction in R\n\n\nCode\nxlm &lt;- lm(Y ~ X,\n            data = DATA)\n\npredict_df &lt;- data.frame(X = VAL)\n\npredict(xlm,\n        predict_df)\n\n\n\nX: Name Predictor Variable of Interest in data frame DATA\nY: Name Outcome Variable of Interest in data frame DATA\nDATA: Name of the data frame\nVAL: Value for the Predictor Variable"
  },
  {
    "objectID": "lectures/5.html#example-1",
    "href": "lectures/5.html#example-1",
    "title": "Simple  Linear Regression",
    "section": "Example 1",
    "text": "Example 1\n\nExampleCode\n\n\nPredict the body mass for a penguin with a flipper length of 185.\n\n\n\n\nCode\nxlm &lt;- lm(body_mass ~ flipper_len,\n            data = penguins)\n\nxlm\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ flipper_len, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)  flipper_len  \n#&gt;    -5872.09        50.15\n\n\nCode\npredict_df &lt;- data.frame(flipper_len = 185)\n\npredict(xlm,\n        predict_df)\n\n\n#&gt;        1 \n#&gt; 3406.262"
  },
  {
    "objectID": "lectures/5.html#example-2-1",
    "href": "lectures/5.html#example-2-1",
    "title": "Simple  Linear Regression",
    "section": "Example 2",
    "text": "Example 2\n\nExampleCode\n\n\nPredict the body mass for a penguin with a flipper length of 205.\n\n\n\n\nCode\nxlm &lt;- lm(body_mass ~ flipper_len,\n            data = penguins)\n\n\nxlm\n\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ flipper_len, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)  flipper_len  \n#&gt;    -5872.09        50.15\n\n\nCode\npredict_df &lt;- data.frame(flipper_len = 190)\n\npredict(xlm,\n        predict_df)\n\n\n#&gt;        1 \n#&gt; 3657.028"
  },
  {
    "objectID": "lectures/5.html#interpolation",
    "href": "lectures/5.html#interpolation",
    "title": "Simple  Linear Regression",
    "section": "Interpolation",
    "text": "Interpolation\nInterpolation is the process of estimating a value within the range of the observed input data \\(X\\)."
  },
  {
    "objectID": "lectures/5.html#extrapolation",
    "href": "lectures/5.html#extrapolation",
    "title": "Simple  Linear Regression",
    "section": "Extrapolation",
    "text": "Extrapolation\nExtrapolation is the process of estimating a value beyond the range of observed input data \\(X\\). It’s about venturing into the unknown, using what we know as a guide."
  },
  {
    "objectID": "lectures/5.html#extrapolation-1",
    "href": "lectures/5.html#extrapolation-1",
    "title": "Simple  Linear Regression",
    "section": "Extrapolation",
    "text": "Extrapolation\n\n\nCode\nggplot(penguins, aes(flipper_len, body_mass)) + \n  xlim(160, 250) +\n  ylim(2600, 7000) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F)"
  },
  {
    "objectID": "lectures/3.html#r-packages",
    "href": "lectures/3.html#r-packages",
    "title": "Numerical Data",
    "section": "R Packages",
    "text": "R Packages\n\nrcistats\ntidyverse"
  },
  {
    "objectID": "lectures/3.html#palmer-penguins-1",
    "href": "lectures/3.html#palmer-penguins-1",
    "title": "Numerical Data",
    "section": "Palmer Penguins",
    "text": "Palmer Penguins\n\n\nThe penguins data set was contains information on penguins from the Palmer Station located in . You can learn more about the data set here.\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lectures/3.html#variables-of-interest",
    "href": "lectures/3.html#variables-of-interest",
    "title": "Numerical Data",
    "section": "Variables of Interest",
    "text": "Variables of Interest\n\nflipper_len: Flipper Length in millimeters\nbody_mass: Body mass in grams"
  },
  {
    "objectID": "lectures/3.html#what-is-numerical-data",
    "href": "lectures/3.html#what-is-numerical-data",
    "title": "Numerical Data",
    "section": "What is numerical data?",
    "text": "What is numerical data?\n\n\nCode\npenguins |&gt; \n  slice(1:7) |&gt; \n  pull(flipper_len)\n\n\n#&gt; [1] 181 186 195 193 190 181 195"
  },
  {
    "objectID": "lectures/3.html#central-tendency",
    "href": "lectures/3.html#central-tendency",
    "title": "Numerical Data",
    "section": "Central Tendency",
    "text": "Central Tendency\n\n\nCode\npenguins |&gt; \n  slice(1:7) |&gt; \n  pull(flipper_len)\n\n\n#&gt; [1] 181 186 195 193 190 181 195"
  },
  {
    "objectID": "lectures/3.html#variation",
    "href": "lectures/3.html#variation",
    "title": "Numerical Data",
    "section": "Variation",
    "text": "Variation\n\n\nCode\npenguins |&gt; \n  slice(1:7) |&gt; \n  pull(flipper_len)\n\n\n#&gt; [1] 181 186 195 193 190 181 195"
  },
  {
    "objectID": "lectures/3.html#summary-statistics-1",
    "href": "lectures/3.html#summary-statistics-1",
    "title": "Numerical Data",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nSummary statistics are used to describe the distribution of data."
  },
  {
    "objectID": "lectures/3.html#central-tendency-1",
    "href": "lectures/3.html#central-tendency-1",
    "title": "Numerical Data",
    "section": "Central Tendency",
    "text": "Central Tendency\nCentral tendency is a statistical concept that refers to the central or typical value around which a set of data points tends to cluster. It is used to summarize and describe a data set by identifying a single representative value that provides insights into the data’s overall characteristics."
  },
  {
    "objectID": "lectures/3.html#variation-1",
    "href": "lectures/3.html#variation-1",
    "title": "Numerical Data",
    "section": "Variation",
    "text": "Variation\nVariation in statistics refers to the extent to which data points in a dataset deviate or differ from a central tendency measure. Understanding variation is crucial for making informed decisions, drawing meaningful conclusions, and assessing the reliability of statistical analyses."
  },
  {
    "objectID": "lectures/3.html#minimum",
    "href": "lectures/3.html#minimum",
    "title": "Numerical Data",
    "section": "Minimum",
    "text": "Minimum\nThe minimum (min) is the smallest value in the data."
  },
  {
    "objectID": "lectures/3.html#maximum",
    "href": "lectures/3.html#maximum",
    "title": "Numerical Data",
    "section": "Maximum",
    "text": "Maximum\nThe maximum (max) is the largest value in the data."
  },
  {
    "objectID": "lectures/3.html#quartiles",
    "href": "lectures/3.html#quartiles",
    "title": "Numerical Data",
    "section": "Quartiles",
    "text": "Quartiles\nQuartiles are three values (Q1, Q2, Q3) that divides the data into four subsets."
  },
  {
    "objectID": "lectures/3.html#q1",
    "href": "lectures/3.html#q1",
    "title": "Numerical Data",
    "section": "Q1",
    "text": "Q1\nQ1 is the value signifying that a quarter of the data (25%) is lower than it."
  },
  {
    "objectID": "lectures/3.html#q2---median-tildex",
    "href": "lectures/3.html#q2---median-tildex",
    "title": "Numerical Data",
    "section": "Q2 - Median (\\(\\tilde{x}\\))",
    "text": "Q2 - Median (\\(\\tilde{x}\\))\nQ2 is the value signifying that half of the data (50%) is below it.\n\nThe median also represents the central tendency of the data."
  },
  {
    "objectID": "lectures/3.html#q3",
    "href": "lectures/3.html#q3",
    "title": "Numerical Data",
    "section": "Q3",
    "text": "Q3\nQ3 is the value signifying that 3 quarters (75%) of the data is below it."
  },
  {
    "objectID": "lectures/3.html#interquartile-range",
    "href": "lectures/3.html#interquartile-range",
    "title": "Numerical Data",
    "section": "Interquartile Range",
    "text": "Interquartile Range\n\\[\nIQR = Q_3 - Q_1\n\\]"
  },
  {
    "objectID": "lectures/3.html#range",
    "href": "lectures/3.html#range",
    "title": "Numerical Data",
    "section": "Range",
    "text": "Range\n\n\\[\nR = \\mathrm{max} - \\mathrm{min}\n\\]"
  },
  {
    "objectID": "lectures/3.html#how-to-identify-the-quartiles",
    "href": "lectures/3.html#how-to-identify-the-quartiles",
    "title": "Numerical Data",
    "section": "How to identify the quartiles?",
    "text": "How to identify the quartiles?\n\nSort the data\nID Max and Min\nFind the amount of data the makes a quarter:\n\n\\(K=N/4\\)\n\nCreate 4 groups using the sorted data\n\ngroup by data size\nIf \\(K\\) has a decimal, the \\(Kth\\) value is quartile of each group."
  },
  {
    "objectID": "lectures/3.html#mean-barx",
    "href": "lectures/3.html#mean-barx",
    "title": "Numerical Data",
    "section": "Mean (\\(\\bar{x}\\))",
    "text": "Mean (\\(\\bar{x}\\))\nDescribe how you will find the mean of these numbers:\n\n\n#&gt; [1] 18 18 12 18 13"
  },
  {
    "objectID": "lectures/3.html#mean-barx-1",
    "href": "lectures/3.html#mean-barx-1",
    "title": "Numerical Data",
    "section": "Mean (\\(\\bar{x}\\))",
    "text": "Mean (\\(\\bar{x}\\))\nThe mean is another measurement for central tendency.\n\\[\n\\bar X = \\frac{1}{n}\\sum^n_{i=1}X_i\n\\]\n\n\\(n\\): total data points\n\\(X_i\\): data points\n\\(i\\): indexing data\n\\(\\sum\\): add all from first (bottom) to last (up)"
  },
  {
    "objectID": "lectures/3.html#variance",
    "href": "lectures/3.html#variance",
    "title": "Numerical Data",
    "section": "Variance",
    "text": "Variance\nThe variance is a measurement on the average squared distance the data points are from the central tendency.\n\\[\ns^2 = \\frac{1}{n-1}\\sum^n_{i=1}(X_i-\\bar X)^2\n\\]"
  },
  {
    "objectID": "lectures/3.html#standard-deviation",
    "href": "lectures/3.html#standard-deviation",
    "title": "Numerical Data",
    "section": "Standard Deviation",
    "text": "Standard Deviation\nThe standard deviation is a measurement on the average distance the data points are from the central tendency.\n\\[\ns=\\sqrt{s^2}\n\\]"
  },
  {
    "objectID": "lectures/3.html#mean-vs-median",
    "href": "lectures/3.html#mean-vs-median",
    "title": "Numerical Data",
    "section": "Mean vs Median",
    "text": "Mean vs Median\n\n\nMean\n\\[\n\\bar X = \\frac{1}{n}\\sum^n_{i=1}x_i\n\\]\n\nMedian\n\\[\nP(X \\leq \\tilde{X}) = 0.5\n\\]"
  },
  {
    "objectID": "lectures/3.html#mean-vs-median-1",
    "href": "lectures/3.html#mean-vs-median-1",
    "title": "Numerical Data",
    "section": "Mean vs Median",
    "text": "Mean vs Median\nMean (blue line) vs Median (red line)"
  },
  {
    "objectID": "lectures/3.html#outliers",
    "href": "lectures/3.html#outliers",
    "title": "Numerical Data",
    "section": "Outliers",
    "text": "Outliers\nThese are data points that seem to be highly distant from all other variables."
  },
  {
    "objectID": "lectures/3.html#numerical-statistics-in-r-1",
    "href": "lectures/3.html#numerical-statistics-in-r-1",
    "title": "Numerical Data",
    "section": "Numerical Statistics in R",
    "text": "Numerical Statistics in R\nR has several built in functions to compute statistics."
  },
  {
    "objectID": "lectures/3.html#mean-1",
    "href": "lectures/3.html#mean-1",
    "title": "Numerical Data",
    "section": "Mean",
    "text": "Mean\nmean(DATA$VAR)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#median-1",
    "href": "lectures/3.html#median-1",
    "title": "Numerical Data",
    "section": "Median",
    "text": "Median\nmedian(DATA$VAR)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#standard-deviation-1",
    "href": "lectures/3.html#standard-deviation-1",
    "title": "Numerical Data",
    "section": "Standard Deviation",
    "text": "Standard Deviation\nsd(DATA$VAR)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#variance-1",
    "href": "lectures/3.html#variance-1",
    "title": "Numerical Data",
    "section": "Variance",
    "text": "Variance\nvar(DATA$VAR)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#quartiles-1",
    "href": "lectures/3.html#quartiles-1",
    "title": "Numerical Data",
    "section": "Quartiles",
    "text": "Quartiles\nquantile(DATA$VAR, probs = c(0.25, 0.5, 0.75))\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#max-and-min",
    "href": "lectures/3.html#max-and-min",
    "title": "Numerical Data",
    "section": "Max and Min",
    "text": "Max and Min\nmax(DATA$VAR)\nmin(DATA$VAR)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#summary-statistics-2",
    "href": "lectures/3.html#summary-statistics-2",
    "title": "Numerical Data",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nrnum_stats(DATA$VAR)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#penguins",
    "href": "lectures/3.html#penguins",
    "title": "Numerical Data",
    "section": "Penguins",
    "text": "Penguins\n\n\nCode\nnum_stats(penguins$flipper_len)\n\n\n#&gt;   min q25    mean median q75 max     sd     var iqr missing\n#&gt; 1 172 190 200.967    197 213 231 14.016 196.442  23       0"
  },
  {
    "objectID": "lectures/3.html#histogram",
    "href": "lectures/3.html#histogram",
    "title": "Numerical Data",
    "section": "Histogram",
    "text": "Histogram\nA histogram is a graphical representation of the distribution or frequency of data points in a dataset. It provides a visual way to understand the shape, central tendency, and spread of a dataset by dividing the data into intervals or bins and showing how many data points fall into each bin as a bar."
  },
  {
    "objectID": "lectures/3.html#histogram-r-code",
    "href": "lectures/3.html#histogram-r-code",
    "title": "Numerical Data",
    "section": "Histogram R Code",
    "text": "Histogram R Code\nggplot(DATA, aes(VAR)) +\n  geom_histogram()\nTo change bins:\nggplot(DATA, aes(VAR)) +\n  geom_histogram(bins = VAL)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)\nVAL: Numerical value to change the bin width."
  },
  {
    "objectID": "lectures/3.html#histogram-1",
    "href": "lectures/3.html#histogram-1",
    "title": "Numerical Data",
    "section": "Histogram",
    "text": "Histogram\n\n\nCode\ny &lt;- rnorm(1000)\nggplot(tibble(y), aes(y)) +\n  geom_histogram(bins = 15)"
  },
  {
    "objectID": "lectures/3.html#histogram-2",
    "href": "lectures/3.html#histogram-2",
    "title": "Numerical Data",
    "section": "Histogram",
    "text": "Histogram\n\n\nCode\ny &lt;- rgamma(1000, 2)\nggplot(tibble(y), aes(y)) +\n  geom_histogram(bins = 15)"
  },
  {
    "objectID": "lectures/3.html#histograms",
    "href": "lectures/3.html#histograms",
    "title": "Numerical Data",
    "section": "Histograms",
    "text": "Histograms\n\n\nCode\ny &lt;- rbeta(1000, 5, 1)\nggplot(tibble(y), aes(y)) +\n  geom_histogram(bins = 15)"
  },
  {
    "objectID": "lectures/3.html#histograms-1",
    "href": "lectures/3.html#histograms-1",
    "title": "Numerical Data",
    "section": "Histograms",
    "text": "Histograms\n\n\nCode\ny &lt;- rbinom(1000, 1, 0.4)\nz &lt;- (y == 0) * rnorm(1000, 23) + (y == 1) * rnorm(1000, 27)\nggplot(tibble(z), aes(z)) +\n  geom_histogram(bins = 15)"
  },
  {
    "objectID": "lectures/3.html#penguins-1",
    "href": "lectures/3.html#penguins-1",
    "title": "Numerical Data",
    "section": "Penguins",
    "text": "Penguins\n\nggplot(penguins, aes(flipper_len)) +\n  geom_histogram()"
  },
  {
    "objectID": "lectures/3.html#box-plot",
    "href": "lectures/3.html#box-plot",
    "title": "Numerical Data",
    "section": "Box Plot",
    "text": "Box Plot\nA box plot, also known as a box-and-whisker plot, is a graphical representation of the distribution and key statistical characteristics of a dataset. It provides a visual summary of the data’s central tendency, spread, and potential outliers."
  },
  {
    "objectID": "lectures/3.html#box-plot-1",
    "href": "lectures/3.html#box-plot-1",
    "title": "Numerical Data",
    "section": "Box Plot",
    "text": "Box Plot"
  },
  {
    "objectID": "lectures/3.html#box-plot-r-code",
    "href": "lectures/3.html#box-plot-r-code",
    "title": "Numerical Data",
    "section": "Box Plot R Code",
    "text": "Box Plot R Code\nggplot(DATA, aes(VAR)) +\n  geom_boxplot()\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#box-plot-2",
    "href": "lectures/3.html#box-plot-2",
    "title": "Numerical Data",
    "section": "Box Plot",
    "text": "Box Plot\n\nggplot(penguins, aes(flipper_len)) +\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/3.html#box-plot-3",
    "href": "lectures/3.html#box-plot-3",
    "title": "Numerical Data",
    "section": "Box Plot",
    "text": "Box Plot\n\nggplot(penguins, aes(y = flipper_len)) +\n  geom_boxplot()"
  },
  {
    "objectID": "lectures/3.html#dot-plots",
    "href": "lectures/3.html#dot-plots",
    "title": "Numerical Data",
    "section": "Dot Plots",
    "text": "Dot Plots\nDot Plots are similar to histograms, but they incorporate dots to count how many data points fall within bins."
  },
  {
    "objectID": "lectures/3.html#dot-plots-in-r",
    "href": "lectures/3.html#dot-plots-in-r",
    "title": "Numerical Data",
    "section": "Dot Plots in R",
    "text": "Dot Plots in R\nggplot(DATA, aes(VAR)) +\n  geom_dotplot()\nTo change binwidth\nggplot(DATA, aes(VAR)) +\n  geom_dotplot(binwidth = VAL)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)\nVAL: Numerical value to change the bin width."
  },
  {
    "objectID": "lectures/3.html#dot-plots-1",
    "href": "lectures/3.html#dot-plots-1",
    "title": "Numerical Data",
    "section": "Dot Plots",
    "text": "Dot Plots\n\nggplot(penguins, aes(flipper_len)) +\n  geom_dotplot(binwidth = 1)"
  },
  {
    "objectID": "lectures/3.html#density-plot",
    "href": "lectures/3.html#density-plot",
    "title": "Numerical Data",
    "section": "Density Plot",
    "text": "Density Plot"
  },
  {
    "objectID": "lectures/3.html#density-plot-1",
    "href": "lectures/3.html#density-plot-1",
    "title": "Numerical Data",
    "section": "Density Plot",
    "text": "Density Plot\nA density plot is a way to visualize the distribution of a continuous variable — it shows where data values are concentrated (dense) and where they are sparse via the height of the graph."
  },
  {
    "objectID": "lectures/3.html#density-plot-in-r",
    "href": "lectures/3.html#density-plot-in-r",
    "title": "Numerical Data",
    "section": "Density Plot in R",
    "text": "Density Plot in R\nggplot(DATA, aes(VAR)) +\n  geom_density()\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)"
  },
  {
    "objectID": "lectures/3.html#density-plot-2",
    "href": "lectures/3.html#density-plot-2",
    "title": "Numerical Data",
    "section": "Density Plot",
    "text": "Density Plot\n\nggplot(penguins, aes(flipper_len)) +\n  geom_density()"
  },
  {
    "objectID": "lectures/3.html#adding-vertical-lines",
    "href": "lectures/3.html#adding-vertical-lines",
    "title": "Numerical Data",
    "section": "Adding Vertical Lines",
    "text": "Adding Vertical Lines\nggplot(DATA, aes(VAR)) +\n  geom_density() +\n  geom_vline(xintercept = XVAL)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)\nXVAL: Number to place the vertical line (eg: 5)"
  },
  {
    "objectID": "lectures/3.html#vertical-lines",
    "href": "lectures/3.html#vertical-lines",
    "title": "Numerical Data",
    "section": "Vertical Lines",
    "text": "Vertical Lines\n\nggplot(penguins, aes(flipper_len)) +\n  geom_density() +\n  geom_vline(xintercept = mean(penguins$flipper_len), col  = \"blue\") +\n  geom_vline(xintercept = median(penguins$flipper_len), col = \"red\")"
  },
  {
    "objectID": "lectures/3.html#adding-horizontal-lines",
    "href": "lectures/3.html#adding-horizontal-lines",
    "title": "Numerical Data",
    "section": "Adding Horizontal Lines",
    "text": "Adding Horizontal Lines\nggplot(DATA, aes(VAR)) +\n  geom_density() +\n  geom_hline(yintercept = YVAL)\n\nDATA: Name of the data frame (eg: penguins)\nVAR: Name of the variable to create a plot (eg: flipper_len)\nYVAL: Number to place the horizontal line (eg: 2)"
  },
  {
    "objectID": "lectures/3.html#horizontal-lines",
    "href": "lectures/3.html#horizontal-lines",
    "title": "Numerical Data",
    "section": "Horizontal Lines",
    "text": "Horizontal Lines\n\nggplot(penguins, aes(flipper_len)) +\n  geom_density() +\n  geom_hline(yintercept = 0.01, col  = \"blue\") +\n  geom_hline(yintercept = 0.02, col = \"red\")"
  },
  {
    "objectID": "lectures/3.html#skeweness-1",
    "href": "lectures/3.html#skeweness-1",
    "title": "Numerical Data",
    "section": "Skeweness",
    "text": "Skeweness\nSkewness is a statistical measure to determine if unimodal data follows a symmetric distribution, skewed to the left, or skewed to the right."
  },
  {
    "objectID": "lectures/3.html#symmetric-distribution",
    "href": "lectures/3.html#symmetric-distribution",
    "title": "Numerical Data",
    "section": "Symmetric Distribution",
    "text": "Symmetric Distribution\nA symmetric distribution will look bell shaped and the mean (red line) and median (dashed blue line) will overlap each other.\n\n\nCode\ny &lt;- rnorm(100000)\nggplot(tibble(y), aes(y)) +\n  geom_density() +\n  geom_vline(xintercept = mean(y), col = \"red\") +\n  geom_vline(xintercept = median(y), col = \"blue\", lty = 2)"
  },
  {
    "objectID": "lectures/3.html#right-skewed-distribution",
    "href": "lectures/3.html#right-skewed-distribution",
    "title": "Numerical Data",
    "section": "Right Skewed Distribution",
    "text": "Right Skewed Distribution\nA right skewed distribution looks asymetric and the mean (red line) is to the right of the median (dashed blue line).\n\n\nCode\ny &lt;- rgamma(100000, shape = 4)\nggplot(tibble(y), aes(y)) +\n  geom_density() +\n  geom_vline(xintercept = mean(y), col = \"red\") +\n  geom_vline(xintercept = median(y), col = \"blue\", lty = 2)"
  },
  {
    "objectID": "lectures/3.html#left-skewed-distribution",
    "href": "lectures/3.html#left-skewed-distribution",
    "title": "Numerical Data",
    "section": "left Skewed Distribution",
    "text": "left Skewed Distribution\nA left skewed distribution looks asymetric and the mean (red line) is to the left of the median (dashed blue line).\n\n\nCode\ny &lt;- rbeta(100000, shape1 = 5, shape2 = 1.25)\nggplot(tibble(y), aes(y)) +\n  geom_density() +\n  geom_vline(xintercept = mean(y), col = \"red\") +\n  geom_vline(xintercept = median(y), col = \"blue\", lty = 2)"
  },
  {
    "objectID": "lectures/3.html#scatter-plots-1",
    "href": "lectures/3.html#scatter-plots-1",
    "title": "Numerical Data",
    "section": "Scatter Plots",
    "text": "Scatter Plots\nScatter plots demonstrate how two variables behave with each other. They can tell you any postive or negative trends, if they exist, with the combination of the plots."
  },
  {
    "objectID": "lectures/3.html#positive-relationship",
    "href": "lectures/3.html#positive-relationship",
    "title": "Numerical Data",
    "section": "Positive Relationship",
    "text": "Positive Relationship"
  },
  {
    "objectID": "lectures/3.html#negative-relationship",
    "href": "lectures/3.html#negative-relationship",
    "title": "Numerical Data",
    "section": "Negative Relationship",
    "text": "Negative Relationship"
  },
  {
    "objectID": "lectures/3.html#no-relationship",
    "href": "lectures/3.html#no-relationship",
    "title": "Numerical Data",
    "section": "No Relationship",
    "text": "No Relationship"
  },
  {
    "objectID": "lectures/3.html#weak-relationship",
    "href": "lectures/3.html#weak-relationship",
    "title": "Numerical Data",
    "section": "Weak Relationship",
    "text": "Weak Relationship"
  },
  {
    "objectID": "lectures/3.html#scatter-plots-in-r",
    "href": "lectures/3.html#scatter-plots-in-r",
    "title": "Numerical Data",
    "section": "Scatter Plots in R",
    "text": "Scatter Plots in R\nggplot(DATA, aes(x = VAR1, y = VAR2)) +\n  geom_point()\n\nDATA: Name of the data frame (eg: penguins)\nVAR1: Name of the X variable to create a plot (eg: flipper_len)\nVAR2: Name of the Y variable to create a plot (eg: body_mass)"
  },
  {
    "objectID": "lectures/3.html#penguins-2",
    "href": "lectures/3.html#penguins-2",
    "title": "Numerical Data",
    "section": "Penguins",
    "text": "Penguins\n\n\nCode\nggplot(penguins, aes(flipper_len, body_mass)) +\n  geom_point()"
  },
  {
    "objectID": "lectures/1a.html#statistical-warning",
    "href": "lectures/1a.html#statistical-warning",
    "title": "Statistics",
    "section": "Statistical Warning",
    "text": "Statistical Warning"
  },
  {
    "objectID": "lectures/1a.html#statistics-1",
    "href": "lectures/1a.html#statistics-1",
    "title": "Statistics",
    "section": "Statistics",
    "text": "Statistics\n\n\n\n\n\n\n\n\n\nWith an increasing use of data to make decisions, Statistics has been essential for processing large amounts of data to byte-size information\nStatistics is also known as\n\nData Science\nMachine Learning\nArtificial Intelligence\n\nSo for today, we’re asking: what is Statistics?"
  },
  {
    "objectID": "lectures/1a.html#what-does-google-say",
    "href": "lectures/1a.html#what-does-google-say",
    "title": "Statistics",
    "section": "What does Google say?",
    "text": "What does Google say?\n\n\nUC Irvine\nStatistics is the science concerned with developing and studying methods for collecting, analyzing, interpreting and presenting empirical data.\n\nWikipedia\nStatistics is a mathematical body of science that pertains to the collection, analysis, interpretation or explanation, and presentation of data, or as a branch of mathematics."
  },
  {
    "objectID": "lectures/1a.html#what-does-ai-say",
    "href": "lectures/1a.html#what-does-ai-say",
    "title": "Statistics",
    "section": "What does AI say?",
    "text": "What does AI say?\n\n\nChatGPT\nStatistics is a branch of mathematics and a field of study that deals with the collection, analysis, interpretation, presentation, and organization of data.\n\nGoogle Gemini\nStatistics is the science of collecting, analyzing, interpreting, and presenting data."
  },
  {
    "objectID": "lectures/1a.html#what-do-researchers-say",
    "href": "lectures/1a.html#what-do-researchers-say",
    "title": "Statistics",
    "section": "What do researchers say?",
    "text": "What do researchers say?\n\nAnthropologistMicrobiologistSociologistPolitical ScientistEcologistMathematician\n\n\nObjectively interpreting data to make meaningful inferences about our predictions.\n\n\nWhatever the statistician says.\n\n\nGathering the narratives of individuals, groups, or society and telling a story about their past, present, or future. The numbers paint a picture worth many words.\n\n\nUsing numbers to try to explain behaviors and/or patterns in our world.\n\n\nStatistics is the way to make sense of the natural world by taking data we collect to identify patterns between variables, and applying statistical theory to make sure we are taking the right approach to data collection and analysis. Also, assess patterns to see if they are reproducible and provide a logical explanation that makes biological sense.\n\n\nStatistics is the study of data, patterns, and trends."
  },
  {
    "objectID": "lectures/1a.html#what-is-it",
    "href": "lectures/1a.html#what-is-it",
    "title": "Statistics",
    "section": "What is it?",
    "text": "What is it?\n\n\nMath\n\n\n\n\n\n\nScience"
  },
  {
    "objectID": "lectures/1a.html#what-does-a-statistician-say",
    "href": "lectures/1a.html#what-does-a-statistician-say",
    "title": "Statistics",
    "section": "What does a Statistician say?",
    "text": "What does a Statistician say?\nIt is the study of variation and randomness!\n\nUsing mathematics, we model randomness to characterizes commonality and variation!\n\n\nUsing science, we systematically refine models to better fit randomness in data!\n\n\nUsing art, when it all eventually fails!"
  },
  {
    "objectID": "lectures/1a.html#when-it-fails",
    "href": "lectures/1a.html#when-it-fails",
    "title": "Statistics",
    "section": "When it fails?!?!",
    "text": "When it fails?!?!"
  },
  {
    "objectID": "lectures/1a.html#statistics-mantra---george-box",
    "href": "lectures/1a.html#statistics-mantra---george-box",
    "title": "Statistics",
    "section": "Statistics Mantra - George Box",
    "text": "Statistics Mantra - George Box\n\n\n\n\n\n\n\n\nAll models are wrong,\nsome are useful!"
  },
  {
    "objectID": "lectures/1a.html#what-is-the-formal-definition-of-statistics",
    "href": "lectures/1a.html#what-is-the-formal-definition-of-statistics",
    "title": "Statistics",
    "section": "What is the formal definition of Statistics?",
    "text": "What is the formal definition of Statistics?\nStatistics is both the development of mathematical models to be used in real-world data and the analysis of data using existing models."
  },
  {
    "objectID": "lectures/1a.html#probability-models",
    "href": "lectures/1a.html#probability-models",
    "title": "Statistics",
    "section": "Probability Models",
    "text": "Probability Models\n\n\n\n\n\n\n\n\n\nModel observations that follow a new data generating process\nUnderstand its properties\nDevelop new probability distributions\nKnown as Probability Theory\nResearcher is a Probabilist or Mathematical Statistician"
  },
  {
    "objectID": "lectures/1a.html#data-analysis",
    "href": "lectures/1a.html#data-analysis",
    "title": "Statistics",
    "section": "Data Analysis",
    "text": "Data Analysis\n\n\n\nModel data with a known probability model\nAccount for sources of variation and bias\nAccount for violations of independence and randomness\nKnown as Statistician or Data Scientist"
  },
  {
    "objectID": "lectures/1a.html#whats-the-goal-of-a-statistician",
    "href": "lectures/1a.html#whats-the-goal-of-a-statistician",
    "title": "Statistics",
    "section": "What’s the goal of a Statistician?",
    "text": "What’s the goal of a Statistician?\n\nINFERENCE\n\n\nUse our sample data to understand the larger population.\n\n\nThe data will tell us how the population generally behaves.\n\n\nThe data will guide us in the differences in units.\n\n\nData will tell us if there is a signal or just noise."
  },
  {
    "objectID": "lectures/1a.html#word-cloud",
    "href": "lectures/1a.html#word-cloud",
    "title": "Statistics",
    "section": "Word Cloud",
    "text": "Word Cloud"
  },
  {
    "objectID": "lectures/1a.html#conducting-inference",
    "href": "lectures/1a.html#conducting-inference",
    "title": "Statistics",
    "section": "Conducting Inference",
    "text": "Conducting Inference"
  },
  {
    "objectID": "lectures/1a.html#are-we-seeing-something-or-is-it-just-noise",
    "href": "lectures/1a.html#are-we-seeing-something-or-is-it-just-noise",
    "title": "Statistics",
    "section": "Are we seeing something or is it just noise???",
    "text": "Are we seeing something or is it just noise???\nAre we seeing something different from what was expected? Or is it due to random chance?"
  },
  {
    "objectID": "lectures/1a.html#hypothesis-testing",
    "href": "lectures/1a.html#hypothesis-testing",
    "title": "Statistics",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nSet up the Null and Alternative Hypothesis\nConstruct a test statistic based on the null hypothesis\nConstruct a distribution of the test statistic based on probability theory\nCompute the probability of observing the test statistic\nMake a decision based on the probability"
  },
  {
    "objectID": "lectures/1a.html#what-if-we-cannot-construct-the-distribution",
    "href": "lectures/1a.html#what-if-we-cannot-construct-the-distribution",
    "title": "Statistics",
    "section": "What if we cannot construct the distribution?!?!",
    "text": "What if we cannot construct the distribution?!?!\n\n\n\n\n\n\n\n\n\n\n\nWe bring out the Monte Carlo methods!"
  },
  {
    "objectID": "lectures/1a.html#monte-carlo-methods",
    "href": "lectures/1a.html#monte-carlo-methods",
    "title": "Statistics",
    "section": "Monte Carlo Methods",
    "text": "Monte Carlo Methods\n\nMonte Carlo Methods are used to construct a distribution function of an obscure test statistic\nWe simulate a large number of data sets based on the null hypothesis\nWe construct a test statistic for each fake data set and the real one\nWe count how many data sets produce a test statistic that is more extreme than the real test statistic\n\\(p=\\#\\ of\\ extreme\\ data\\ sets\\ /\\ all\\ data\\ sets\\)"
  },
  {
    "objectID": "lectures/1a.html#overview-of-research",
    "href": "lectures/1a.html#overview-of-research",
    "title": "Statistics",
    "section": "Overview of Research",
    "text": "Overview of Research\n\nAsk a question about a population\nCollect data from a sample\nConstruct and test a hypothesis\nDraw conclusion about the population\nRefine your question and methodology"
  },
  {
    "objectID": "lectures/1a.html#so-what-is-statistics",
    "href": "lectures/1a.html#so-what-is-statistics",
    "title": "Statistics",
    "section": "So, what is Statistics?",
    "text": "So, what is Statistics?\n\n\n\n\n\n\nFor you, I’ll be anything"
  },
  {
    "objectID": "lectures/1a.html#whats-statistics-without-a-little",
    "href": "lectures/1a.html#whats-statistics-without-a-little",
    "title": "Statistics",
    "section": "What’s Statistics without a little …",
    "text": "What’s Statistics without a little …"
  },
  {
    "objectID": "lectures/1a.html#train-of-thoughts",
    "href": "lectures/1a.html#train-of-thoughts",
    "title": "Statistics",
    "section": "Train of Thoughts",
    "text": "Train of Thoughts\n\nThere are two train of thoughts on how to interpret estimates and probability.\n\n\nOne approach is the Frequentist approach.\n\n\nThe other approach is the Bayesian approach.\n\n\nBoth sides hate each other."
  },
  {
    "objectID": "lectures/1a.html#frequentists",
    "href": "lectures/1a.html#frequentists",
    "title": "Statistics",
    "section": "Frequentists",
    "text": "Frequentists"
  },
  {
    "objectID": "lectures/1a.html#frequentists-1",
    "href": "lectures/1a.html#frequentists-1",
    "title": "Statistics",
    "section": "Frequentists",
    "text": "Frequentists\nA frequentist, in the context of statistics, is an individual who adheres to the frequentist interpretation of probability and statistical inference.\n\nMeaning probability is obtained by the repetition of multiple experiments."
  },
  {
    "objectID": "lectures/1a.html#bayesians",
    "href": "lectures/1a.html#bayesians",
    "title": "Statistics",
    "section": "Bayesians",
    "text": "Bayesians"
  },
  {
    "objectID": "lectures/1a.html#bayesians-1",
    "href": "lectures/1a.html#bayesians-1",
    "title": "Statistics",
    "section": "Bayesians",
    "text": "Bayesians\nA Bayesians, in the context of statistics, is an individual who adheres to the Bayesian interpretation of probability and statistical inference.\n\nProbability is obtained by likelihood of an event to occur, given data and prior knowledge."
  },
  {
    "objectID": "lectures/1a.html#what-am-i-and-people-that-have-lives",
    "href": "lectures/1a.html#what-am-i-and-people-that-have-lives",
    "title": "Statistics",
    "section": "What am I (and people that have lives)?",
    "text": "What am I (and people that have lives)?\n\n\nWhatever gets the job done!"
  },
  {
    "objectID": "lectures/1a.html#there-is-more-much-more-but-i-will-say-this-in-my-statistical-journey",
    "href": "lectures/1a.html#there-is-more-much-more-but-i-will-say-this-in-my-statistical-journey",
    "title": "Statistics",
    "section": "There is more, much more, but I will say this, in my statistical journey",
    "text": "There is more, much more, but I will say this, in my statistical journey"
  },
  {
    "objectID": "lectures/12.html#hypothesis-tests",
    "href": "lectures/12.html#hypothesis-tests",
    "title": "Statistical  Modeling",
    "section": "Hypothesis Tests",
    "text": "Hypothesis Tests\nConducting a hypothesis test for coefficients in regression models with more than one predictor is the same as the standard simple approaches.\n\nYou will just need to specify the hypothesis tests are adjusted for the other covariates."
  },
  {
    "objectID": "lectures/12.html#hypothesis-testing-steps",
    "href": "lectures/12.html#hypothesis-testing-steps",
    "title": "Statistical  Modeling",
    "section": "Hypothesis Testing Steps",
    "text": "Hypothesis Testing Steps\n\nState \\(H_0\\) and \\(H_1\\)\nChoose \\(\\alpha\\)\nCompute confidence interval/p-value\nMake a decision"
  },
  {
    "objectID": "lectures/12.html#null-hypothesis-h_0",
    "href": "lectures/12.html#null-hypothesis-h_0",
    "title": "Statistical  Modeling",
    "section": "Null Hypothesis \\(H_0\\)",
    "text": "Null Hypothesis \\(H_0\\)\nThe null hypothesis is the claim that is initially believed to be true. For the most part, it is always equal to the hypothesized value."
  },
  {
    "objectID": "lectures/12.html#alternative-hypothesis-h_1",
    "href": "lectures/12.html#alternative-hypothesis-h_1",
    "title": "Statistical  Modeling",
    "section": "Alternative Hypothesis \\(H_1\\)",
    "text": "Alternative Hypothesis \\(H_1\\)\nThe alternative hypothesis contradicts the null hypothesis."
  },
  {
    "objectID": "lectures/12.html#significance-level",
    "href": "lectures/12.html#significance-level",
    "title": "Statistical  Modeling",
    "section": "Significance Level",
    "text": "Significance Level\nChoose a value that represents the probability of being wrong if you decide to reject the \\(H_0\\).\n\n\\[\n\\alpha = 0.05\n\\]\n\n\nWalk through the steps slowly with an example in mind. Emphasize that \\(\\alpha\\) is a threshold, not the actual probability of error."
  },
  {
    "objectID": "lectures/12.html#conducting-ht-of-beta_j-linear-r",
    "href": "lectures/12.html#conducting-ht-of-beta_j-linear-r",
    "title": "Statistical  Modeling",
    "section": "Conducting HT of \\(\\beta_j\\) Linear R",
    "text": "Conducting HT of \\(\\beta_j\\) Linear R\nXLM &lt;- lm(Y ~ X1 + X2 + ... + Xp, data = DATA)\ntidy(XLM)\n\nXLM: Object where the model is stored\nY: Name of the outcome variable in DATA\nX1, X2, …, Xp: predictor variables in DATA\nDATA: Name of the data set"
  },
  {
    "objectID": "lectures/12.html#conducting-ht-of-beta_j",
    "href": "lectures/12.html#conducting-ht-of-beta_j",
    "title": "Statistical  Modeling",
    "section": "Conducting HT of \\(\\beta_j\\)",
    "text": "Conducting HT of \\(\\beta_j\\)\nXLM &lt;- glm(Y ~ X1 + X2 + ... + Xp, data = DATA, family = binomial())\ntidy(XLM)\n\nXLM: Object where the model is stored\nY: Name of the outcome variable in DATA\nX1, X2, …, Xp: predictor variables in DATA\nDATA: Name of the data set"
  },
  {
    "objectID": "lectures/12.html#penguins-example",
    "href": "lectures/12.html#penguins-example",
    "title": "Statistical  Modeling",
    "section": "Penguins Example",
    "text": "Penguins Example\nIs there a significant relationship between penguin body mass (outcome; body_mass) and flipper length (predictor; flipper_len), adjusting for species? Use the penguins data set to determine a significant association."
  },
  {
    "objectID": "lectures/12.html#penguins-hypothesis",
    "href": "lectures/12.html#penguins-hypothesis",
    "title": "Statistical  Modeling",
    "section": "Penguins: Hypothesis",
    "text": "Penguins: Hypothesis\n\\(H_0\\): There is no relationship between penguin body mass and flipper length, adjusting for penguin species (\\(\\beta_{flipper\\_len} = 0\\))\n\\(H_1\\): There is a relationship between penguin body mass and flipper length, adjusting for penguin species (\\(\\beta_{flipper\\_len} \\ne 0\\))"
  },
  {
    "objectID": "lectures/12.html#penguins-alpha-level",
    "href": "lectures/12.html#penguins-alpha-level",
    "title": "Statistical  Modeling",
    "section": "Penguins: \\(\\alpha\\)-level",
    "text": "Penguins: \\(\\alpha\\)-level\n\\[\n\\alpha = 0.05 = 5.0*10^{-2} = 5.0e-2\n\\]"
  },
  {
    "objectID": "lectures/12.html#penguins-code",
    "href": "lectures/12.html#penguins-code",
    "title": "Statistical  Modeling",
    "section": "Penguins: Code",
    "text": "Penguins: Code\n\n\nCode\nm1 &lt;- lm(body_mass ~ flipper_len + species, penguins)\ntidy(m1)\n\n\n#&gt; # A tibble: 4 × 5\n#&gt;   term             estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       -4031.     584.       -6.90 2.55e-11\n#&gt; 2 flipper_len          40.7      3.07     13.3  1.40e-32\n#&gt; 3 speciesChinstrap   -207.      57.7      -3.58 3.98e- 4\n#&gt; 4 speciesGentoo       267.      95.3       2.80 5.39e- 3"
  },
  {
    "objectID": "lectures/12.html#penguins-decision-making",
    "href": "lectures/12.html#penguins-decision-making",
    "title": "Statistical  Modeling",
    "section": "Penguins: Decision Making",
    "text": "Penguins: Decision Making\n\\[\np = 1.4e-32 &lt; 5e-2 = 0.05 = \\alpha\n\\]\nReject \\(H_0\\)"
  },
  {
    "objectID": "lectures/12.html#penguins-interpretation",
    "href": "lectures/12.html#penguins-interpretation",
    "title": "Statistical  Modeling",
    "section": "Penguins: Interpretation",
    "text": "Penguins: Interpretation\nThere is a significant association between penguins flipper length and body mass, after adjusting for species (p &lt; 0.0001; \\(\\beta = 40.7\\)). As flipper length increases by 1 unit, body mass increases by 40.7 units, adjusting for penguin species."
  },
  {
    "objectID": "lectures/12.html#heart-disease-example",
    "href": "lectures/12.html#heart-disease-example",
    "title": "Statistical  Modeling",
    "section": "Heart Disease Example",
    "text": "Heart Disease Example\nIs there a significant association between heart disease (outcome; disease) and resting blood pressure (predictor; trestbps), adjusting for chest pain (cp). Use the heart_disease data set to determine a significant association."
  },
  {
    "objectID": "lectures/12.html#heart-hypothesis",
    "href": "lectures/12.html#heart-hypothesis",
    "title": "Statistical  Modeling",
    "section": "Heart: Hypothesis",
    "text": "Heart: Hypothesis\n\\(H_0\\): There is no relationship between heart disease probability and resting blood pressure, adjusting for chest pain (\\(\\beta_{bp} = 0\\))\n\\(H_1\\): There is no relationship between heart disease probability and resting blood pressure, adjusting for chest pain (\\(\\beta_{bp} \\ne 0\\))"
  },
  {
    "objectID": "lectures/12.html#heart-alpha-level",
    "href": "lectures/12.html#heart-alpha-level",
    "title": "Statistical  Modeling",
    "section": "Heart: \\(\\alpha\\)-level",
    "text": "Heart: \\(\\alpha\\)-level\n\\[\n\\alpha = 0.05 = 5.0*10^{-2} = 5.0e-2\n\\]"
  },
  {
    "objectID": "lectures/12.html#heart-code",
    "href": "lectures/12.html#heart-code",
    "title": "Statistical  Modeling",
    "section": "Heart: Code",
    "text": "Heart: Code\n\n\nCode\nm2 &lt;- glm(disease ~ trestbps + cp, heart_disease, family = binomial())\ntidy(m2)\n\n\n#&gt; # A tibble: 5 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)  -3.80     1.25       -3.04  0.00234  \n#&gt; 2 trestbps      0.0209   0.00807     2.59  0.00967  \n#&gt; 3 cp2          -0.409    0.601      -0.681 0.496    \n#&gt; 4 cp3          -0.236    0.540      -0.437 0.662    \n#&gt; 5 cp4           2.04     0.512       3.99  0.0000674"
  },
  {
    "objectID": "lectures/12.html#heart-decision-making",
    "href": "lectures/12.html#heart-decision-making",
    "title": "Statistical  Modeling",
    "section": "Heart: Decision Making",
    "text": "Heart: Decision Making\n\\[\np = 0.00967 &lt; 0.05 = \\alpha\n\\]\nReject \\(H_0\\)"
  },
  {
    "objectID": "lectures/12.html#heart-interpretation",
    "href": "lectures/12.html#heart-interpretation",
    "title": "Statistical  Modeling",
    "section": "Heart: Interpretation",
    "text": "Heart: Interpretation\nThere is a significant association between heart disease and resting blood pressure, after adjusting for chest pain (p &lt; 0.00967; \\(\\beta = 0.0209\\)). As resting blood pressure increases by 1 unit, the odds of having heart disease increases by a factor of 1.02, adjusting for chest pain."
  },
  {
    "objectID": "lectures/12.html#model-inference-1",
    "href": "lectures/12.html#model-inference-1",
    "title": "Statistical  Modeling",
    "section": "Model Inference",
    "text": "Model Inference"
  },
  {
    "objectID": "lectures/12.html#what-is-statistical-power",
    "href": "lectures/12.html#what-is-statistical-power",
    "title": "Statistical  Modeling",
    "section": "What is Statistical Power",
    "text": "What is Statistical Power\n\nStatistical Power is the probability of correctly rejecting a false null hypothesis.\nIn other words, it’s the chance of detecting a real effect when it exists."
  },
  {
    "objectID": "lectures/12.html#why-power-matters",
    "href": "lectures/12.html#why-power-matters",
    "title": "Statistical  Modeling",
    "section": "Why Power Matters",
    "text": "Why Power Matters\n\nLow power → high risk of Type II Error (false negatives)\nHigh power → better chance of finding true effects\nCommon threshold: 80% power"
  },
  {
    "objectID": "lectures/12.html#errors-in-inference",
    "href": "lectures/12.html#errors-in-inference",
    "title": "Statistical  Modeling",
    "section": "Errors in Inference",
    "text": "Errors in Inference\n\n\n\nType I\nReject \\(H_0\\) when true\nFalse positive\n\n\nType II\nDon’t reject \\(H_0\\) when false\nFalse negative\n\n\nPower\n\\(1 - P(\\text{Type II})\\)\nDetecting a true effect\n\n\n\n\nPower is often overlooked. It’s about how sensitive the test is to real effects. Larger samples increase power."
  },
  {
    "objectID": "lectures/12.html#type-i-error-false-positive",
    "href": "lectures/12.html#type-i-error-false-positive",
    "title": "Statistical  Modeling",
    "section": "Type I Error (False Positive)",
    "text": "Type I Error (False Positive)\n\nRejecting \\(H_0\\) when it is actually true\nProbability = \\(\\alpha\\) (significance level)\n\n\nType I errors happen when we detect an effect that doesn’t really exist. This is controlled by our chosen alpha level."
  },
  {
    "objectID": "lectures/12.html#type-ii-error-false-negative",
    "href": "lectures/12.html#type-ii-error-false-negative",
    "title": "Statistical  Modeling",
    "section": "Type II Error (False Negative)",
    "text": "Type II Error (False Negative)\n\nFailing to reject \\(H_0\\) when it is actually false\nProbability = \\(\\beta\\)\nPower = \\(1 - \\beta\\)\n\n\nType II errors are often due to small sample sizes or high variability. Power analysis helps us plan to avoid these."
  },
  {
    "objectID": "lectures/12.html#balancing-errors",
    "href": "lectures/12.html#balancing-errors",
    "title": "Statistical  Modeling",
    "section": "Balancing Errors",
    "text": "Balancing Errors\n\nLowering \\(\\alpha\\) reduces Type I errors, but increases risk of Type II errors.\nTo reduce both:\n\nIncrease sample size\nUse more appropriate statistical tests\n\n\n\nThere’s a trade-off between these errors. We can’t eliminate both, but we can manage the risk based on the consequences of each type."
  },
  {
    "objectID": "lectures/12.html#what-affects-power",
    "href": "lectures/12.html#what-affects-power",
    "title": "Statistical  Modeling",
    "section": "What Affects Power?",
    "text": "What Affects Power?\n\nEffect Size\n\nBigger effects are easier to detect\n\nSample Size (\\(n\\))\n\nLarger samples reduce standard error\n\nSignificance Level (\\(\\alpha\\))\n\nHigher \\(\\alpha\\) increases power (but riskier!)\n\nVariability\n\nLess noise in data = better power"
  },
  {
    "objectID": "lectures/12.html#boosting-power",
    "href": "lectures/12.html#boosting-power",
    "title": "Statistical  Modeling",
    "section": "Boosting Power",
    "text": "Boosting Power\n\nPower = Probability of rejecting \\(H_0\\) when it’s false\nHelps avoid Type II Errors\nDriven by:\n\nSample size\nEffect size\n\\(\\alpha\\)\nVariability\n\nAim for 80% or higher"
  },
  {
    "objectID": "lectures/12.html#simpsons-paradox-1",
    "href": "lectures/12.html#simpsons-paradox-1",
    "title": "Statistical  Modeling",
    "section": "Simpson’s Paradox",
    "text": "Simpson’s Paradox"
  },
  {
    "objectID": "lectures/12.html#model-conditions-1",
    "href": "lectures/12.html#model-conditions-1",
    "title": "Statistical  Modeling",
    "section": "Model Conditions",
    "text": "Model Conditions\nWhen we are conducting inference with regression models, we will have to check the following conditions:\n\nLinearity\nIndependence\nProbability Assumption\nEqual Variances\nMulticollinearity (for Multi-Regression)"
  },
  {
    "objectID": "lectures/12.html#linearity",
    "href": "lectures/12.html#linearity",
    "title": "Statistical  Modeling",
    "section": "Linearity",
    "text": "Linearity\nThere must be a linear relationship between both the outcome variable (y) and a set of predictors (\\(x_1\\), \\(x_2\\), …)."
  },
  {
    "objectID": "lectures/12.html#independence",
    "href": "lectures/12.html#independence",
    "title": "Statistical  Modeling",
    "section": "Independence",
    "text": "Independence\nThe data points must not influence each other."
  },
  {
    "objectID": "lectures/12.html#probability-assumption",
    "href": "lectures/12.html#probability-assumption",
    "title": "Statistical  Modeling",
    "section": "Probability Assumption",
    "text": "Probability Assumption\nThe model errors (also known as residuals) must follow a specified distribution.\n\nLinear Regression: Normal Distribution\nLogistic Regression: Binomial Distribution"
  },
  {
    "objectID": "lectures/12.html#equal-variances",
    "href": "lectures/12.html#equal-variances",
    "title": "Statistical  Modeling",
    "section": "Equal Variances",
    "text": "Equal Variances\nThe variability of the data points must be the same for all predictor values."
  },
  {
    "objectID": "lectures/12.html#residuals",
    "href": "lectures/12.html#residuals",
    "title": "Statistical  Modeling",
    "section": "Residuals",
    "text": "Residuals\nResiduals are the errors between the observed value and the estimated model. Common residuals include\n\nRaw Residual\nStandardized Residuals\nJackknife (studentized) Residuals\nDeviance Residuals\nQuantized Residuals"
  },
  {
    "objectID": "lectures/12.html#influential-measurements",
    "href": "lectures/12.html#influential-measurements",
    "title": "Statistical  Modeling",
    "section": "Influential Measurements",
    "text": "Influential Measurements\nInfluential measures are statistics that determine how much a data point affects the model. Common influential measures are\n\nLeverages\nCook’s Distance"
  },
  {
    "objectID": "lectures/12.html#raw-residuals",
    "href": "lectures/12.html#raw-residuals",
    "title": "Statistical  Modeling",
    "section": "Raw Residuals",
    "text": "Raw Residuals\n\\[\n\\hat r_i = y_i - \\hat y_i\n\\]"
  },
  {
    "objectID": "lectures/12.html#residual-analysis",
    "href": "lectures/12.html#residual-analysis",
    "title": "Statistical  Modeling",
    "section": "Residual Analysis",
    "text": "Residual Analysis\nA residual analysis is used to test the assumptions of linear regression."
  },
  {
    "objectID": "lectures/12.html#qq-plot",
    "href": "lectures/12.html#qq-plot",
    "title": "Statistical  Modeling",
    "section": "QQ Plot",
    "text": "QQ Plot\nA qq (quantile-quantile) plot will plot the estimated quantiles of the residuals against the theoretical quantiles from a normal distribution function. If the points from the qq-plot lie on the \\(y=x\\) line, it is said that the residuals follow a normal distribution."
  },
  {
    "objectID": "lectures/12.html#residual-vs-fitted-plot",
    "href": "lectures/12.html#residual-vs-fitted-plot",
    "title": "Statistical  Modeling",
    "section": "Residual vs Fitted Plot",
    "text": "Residual vs Fitted Plot\nThis plot allows you to assess the linearity, constant variance, and identify potential outliers. Create a scatter plot between the fitted values (x-axis) and the raw/standardized residuals (y-axis)."
  },
  {
    "objectID": "lectures/12.html#residual-analysis-in-r",
    "href": "lectures/12.html#residual-analysis-in-r",
    "title": "Statistical  Modeling",
    "section": "Residual Analysis in R",
    "text": "Residual Analysis in R\nUse the resid_df function to obtain the residuals of a model.\n\n\nCode\nrdf &lt;- resid_df(OBJECT)"
  },
  {
    "objectID": "lectures/12.html#residual-vs-fitted-plot-1",
    "href": "lectures/12.html#residual-vs-fitted-plot-1",
    "title": "Statistical  Modeling",
    "section": "Residual vs Fitted Plot",
    "text": "Residual vs Fitted Plot\n\n\nLinear\nggplot(RDF, aes(fitted, resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = \"red\")\n\nLogistic\nggplot(RDF, aes(fitted, quantile_resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = \"red\")\n\n\nRDF: Name of object from resid_df()"
  },
  {
    "objectID": "lectures/12.html#qq-plot-1",
    "href": "lectures/12.html#qq-plot-1",
    "title": "Statistical  Modeling",
    "section": "QQ Plot",
    "text": "QQ Plot\n\n\nLinear\nggplot(RDF, aes(sample = resid)) + \n  stat_qq() +\n  stat_qq_line() \n\nLogistic\nggplot(RDF, aes(sample = quantile_resid)) + \n  stat_qq() +\n  stat_qq_line() \n\n\nRDF: Name of object from resid_df()"
  },
  {
    "objectID": "lectures/12.html#penguins-example-1",
    "href": "lectures/12.html#penguins-example-1",
    "title": "Statistical  Modeling",
    "section": "Penguins: Example",
    "text": "Penguins: Example\n\n\nCode\nm3 &lt;- lm(body_mass ~   island + species + flipper_len,\n          penguins)\ntidy(m3)\n\n\n#&gt; # A tibble: 6 × 5\n#&gt;   term             estimate std.error statistic  p.value\n#&gt;   &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n#&gt; 1 (Intercept)       -4048.     586.      -6.91  2.40e-11\n#&gt; 2 islandDream         -59.8     75.7     -0.789 4.31e- 1\n#&gt; 3 islandTorgersen    -102.      77.7     -1.31  1.90e- 1\n#&gt; 4 speciesChinstrap   -206.      70.4     -2.92  3.71e- 3\n#&gt; 5 speciesGentoo       200.     110.       1.82  6.94e- 2\n#&gt; 6 flipper_len          41.1      3.09    13.3   9.26e-33\n\n\nCode\ndfm3 &lt;- resid_df(m3)\nhead(dfm3)\n\n\n#&gt;   obs body_mass    island species flipper_len     resid   fitted      sresid\n#&gt; 1   1      3750 Torgersen  Adelie         181  462.5612 3287.439  1.24797225\n#&gt; 2   2      3800 Torgersen  Adelie         186  307.1225 3492.877  0.82640213\n#&gt; 3   3      3250 Torgersen  Adelie         195 -612.6671 3862.667 -1.64784619\n#&gt; 5   4      3450 Torgersen  Adelie         193 -330.4916 3780.492 -0.88855590\n#&gt; 6   5      3650 Torgersen  Adelie         190   -7.2284 3657.228 -0.01943297\n#&gt; 7   6      3625 Torgersen  Adelie         181  337.5612 3287.439  0.91072706\n#&gt;      hatvals   jackknife        cooks\n#&gt; 1 0.02662612  1.24901185 7.100464e-03\n#&gt; 2 0.02143054  0.82601134 2.492718e-03\n#&gt; 3 0.02058469 -1.65208143 9.511731e-03\n#&gt; 5 0.01982753 -0.88827691 2.661855e-03\n#&gt; 6 0.01970442 -0.01940404 1.265126e-06\n#&gt; 7 0.02662612  0.91049529 3.781407e-03\n\n\n\n\nCode\nggplot(dfm3, aes(fitted, resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = \"red\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(dfm3, aes(sample = resid)) + \n  stat_qq() +\n  stat_qq_line()"
  },
  {
    "objectID": "lectures/12.html#heart-example",
    "href": "lectures/12.html#heart-example",
    "title": "Statistical  Modeling",
    "section": "Heart: Example",
    "text": "Heart: Example\n\n\nCode\nm4 &lt;- glm(disease ~ trestbps + cp, heart_disease, family = binomial())\ntidy(m4)\n\n\n#&gt; # A tibble: 5 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)  -3.80     1.25       -3.04  0.00234  \n#&gt; 2 trestbps      0.0209   0.00807     2.59  0.00967  \n#&gt; 3 cp2          -0.409    0.601      -0.681 0.496    \n#&gt; 4 cp3          -0.236    0.540      -0.437 0.662    \n#&gt; 5 cp4           2.04     0.512       3.99  0.0000674\n\n\nCode\ndfm4 &lt;- resid_df(m4)\nhead(dfm4)\n\n\n#&gt;   obs disease trestbps cp    fitted        eta  raw_resid pearson_resid\n#&gt; 1   1      no      145  1 0.3162617 -0.7710053 -0.3162617    -0.6801087\n#&gt; 2   2     yes      160  4 0.8296967  1.5834796  0.1703033     0.4530559\n#&gt; 3   3     yes      120  4 0.6787886  0.7482102  0.3212114     0.6879046\n#&gt; 4   4      no      130  3 0.2107532 -1.3203915 -0.2107532    -0.5167502\n#&gt; 5   5      no      130  2 0.1834250 -1.4933128 -0.1834250    -0.4739486\n#&gt; 6   6      no      120  2 0.1541873 -1.7021301 -0.1541873    -0.4269600\n#&gt;   deviance_resid working_resid partial_resid.trestbps partial_resid.cp\n#&gt; 1     -0.8719863     -2.233553              -1.184687        -2.305014\n#&gt; 2      0.6110565      2.788739               1.796346         2.404052\n#&gt; 3      0.8802790      2.221423               1.229030         2.672005\n#&gt; 4     -0.6880061     -2.587422              -1.302396        -2.345657\n#&gt; 5     -0.6366106     -2.717940              -1.259993        -2.476175\n#&gt; 6     -0.5787181     -2.884425              -1.426478        -2.433842\n#&gt;   std_pear_resid std_dev_resid stud_dev_resid quantile_resid   leverages\n#&gt; 1     -0.6962858    -0.8927274     -0.8846616     -0.9513868 0.045927133\n#&gt; 2      0.4562301     0.6153377      0.6134136     -0.2358693 0.013866647\n#&gt; 3      0.6910541     0.8843093      0.8827424     -0.2235802 0.009094376\n#&gt; 4     -0.5199246    -0.6922325     -0.6903935     -0.1632137 0.012173676\n#&gt; 5     -0.4789686    -0.6433536     -0.6403567     -0.1649384 0.020852010\n#&gt; 6     -0.4311339    -0.5843756     -0.5818043     -0.3419256 0.019268922\n#&gt;          cooks\n#&gt; 1 0.0046675922\n#&gt; 2 0.0005853744\n#&gt; 3 0.0008765864\n#&gt; 4 0.0006662724\n#&gt; 5 0.0009771107\n#&gt; 6 0.0007304018\n\n\n\n\nCode\nggplot(dfm4, aes(fitted, quantile_resid)) +\n  geom_point() +\n  geom_hline(yintercept = 0, col = \"red\")\n\n\n\n\n\n\n\n\n\nCode\nggplot(dfm4, aes(sample = quantile_resid)) + \n  stat_qq() +\n  stat_qq_line()"
  },
  {
    "objectID": "lectures/10.html#what-is-statistical-inference",
    "href": "lectures/10.html#what-is-statistical-inference",
    "title": "Statistical Inference",
    "section": "What is Statistical Inference?",
    "text": "What is Statistical Inference?\n\nDrawing conclusions about a population based on a sample\nPopulation = entire group\nSample = subset\n\n\nIntroduce the big idea: We want to make st"
  },
  {
    "objectID": "lectures/10.html#two-main-types-of-inference",
    "href": "lectures/10.html#two-main-types-of-inference",
    "title": "Statistical Inference",
    "section": "Two Main Types of Inference",
    "text": "Two Main Types of Inference\n\nEstimation\nHypothesis Testing\n\n\nWe’ll be focusing on two fundamental techniques in inference. First, estimating population values (like the mean), and second, testing claims about the population."
  },
  {
    "objectID": "lectures/10.html#estimation",
    "href": "lectures/10.html#estimation",
    "title": "Statistical Inference",
    "section": "Estimation",
    "text": "Estimation\n\nPoint Estimate: Single best guess (e.g., \\(\\hat \\beta_1\\))\nInterval Estimate: Range likely to contain the true value\n\n\nPoint estimates are easy but not very informative. Intervals give us a sense of uncertainty, which is critical in inference."
  },
  {
    "objectID": "lectures/10.html#hypothesis-testing",
    "href": "lectures/10.html#hypothesis-testing",
    "title": "Statistical Inference",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\n\\(H_0\\): No effect or difference\n\n\\(H_1\\): Some effect or difference\n\nWe use sample data to support or reject \\(H_0\\)\n\n\nMention that \\(H_0\\) is the default assumption. We only reject it if the data give us strong enough evidence."
  },
  {
    "objectID": "lectures/10.html#key-concepts-and-tools",
    "href": "lectures/10.html#key-concepts-and-tools",
    "title": "Statistical Inference",
    "section": "Key Concepts and Tools",
    "text": "Key Concepts and Tools\n\nSampling Distribution\nCentral Limit Theorem\nStandard Error\n\n\nThese three concepts are foundational. Understanding them helps us assess how reliable our estimates are."
  },
  {
    "objectID": "lectures/10.html#p-values",
    "href": "lectures/10.html#p-values",
    "title": "Statistical Inference",
    "section": "p-values",
    "text": "p-values\n\nProbability of observing data as extreme as this if \\(H_0\\) is true\nMisinterpretation of p-values is common.\nEmphasize: low p-value means data is unusual under \\(H_0\\)."
  },
  {
    "objectID": "lectures/10.html#confidence-intervals",
    "href": "lectures/10.html#confidence-intervals",
    "title": "Statistical Inference",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA range where we expect the true value to fall\n\n\nClarify interpretation: it’s not about the probability the parameter is inside the interval, but about the method producing accurate intervals in the long run."
  },
  {
    "objectID": "lectures/10.html#hypothesis-tests",
    "href": "lectures/10.html#hypothesis-tests",
    "title": "Statistical Inference",
    "section": "Hypothesis Tests",
    "text": "Hypothesis Tests\nHypothesis tests are used to test whether claims are valid or not. This is conducted by collecting data, setting the Null and Alternative Hypothesis."
  },
  {
    "objectID": "lectures/10.html#null-hypothesis-h_0",
    "href": "lectures/10.html#null-hypothesis-h_0",
    "title": "Statistical Inference",
    "section": "Null Hypothesis \\(H_0\\)",
    "text": "Null Hypothesis \\(H_0\\)\nThe null hypothesis is the claim that is initially believed to be true. For the most part, it is always equal to the hypothesized value."
  },
  {
    "objectID": "lectures/10.html#alternative-hypothesis-h_1",
    "href": "lectures/10.html#alternative-hypothesis-h_1",
    "title": "Statistical Inference",
    "section": "Alternative Hypothesis \\(H_1\\)",
    "text": "Alternative Hypothesis \\(H_1\\)\nThe alternative hypothesis contradicts the null hypothesis."
  },
  {
    "objectID": "lectures/10.html#example-of-null-and-alternative-hypothesis",
    "href": "lectures/10.html#example-of-null-and-alternative-hypothesis",
    "title": "Statistical Inference",
    "section": "Example of Null and Alternative Hypothesis",
    "text": "Example of Null and Alternative Hypothesis\nWe want to see if \\(\\beta\\) is different from \\(\\beta^*\\)\n\n\n\nNull Hypothesis\nAlternative Hypothesis\n\n\n\n\n\\(H_0: \\beta=\\beta^*\\)\n\\(H_1: \\beta\\ne\\beta^*\\)\n\n\n\\(H_0: \\beta\\le\\beta^*\\)\n\\(H_1: \\beta&gt;\\beta^*\\)\n\n\n\\(H_0: \\beta\\ge\\beta^*\\)\n\\(H_1: \\beta&lt;\\beta^*\\)"
  },
  {
    "objectID": "lectures/10.html#one-side-vs-two-side-hypothesis-tests",
    "href": "lectures/10.html#one-side-vs-two-side-hypothesis-tests",
    "title": "Statistical Inference",
    "section": "One-Side vs Two-Side Hypothesis Tests",
    "text": "One-Side vs Two-Side Hypothesis Tests\nNotice how there are 3 types of null and alternative hypothesis, The first type of hypothesis (\\(H_1:\\beta\\ne\\beta^*\\)) is considered a 2-sided hypothesis because the rejection region is located in 2 regions. The remaining two hypotheses are considered 1-sided because the rejection region is located on one side of the distribution.\n\n\n\nNull Hypothesis\nAlternative Hypothesis\nSide\n\n\n\n\n\\(H_0: \\beta=\\beta^*\\)\n\\(H_1: \\beta\\ne\\beta^*\\)\n2-Sided\n\n\n\\(H_0: \\beta\\le\\beta^*\\)\n\\(H_1: \\beta&gt;\\beta^*\\)\n1-Sided\n\n\n\\(H_0: \\beta\\ge\\beta^*\\)\n\\(H_1: \\beta&lt;\\beta^*\\)\n1-Sided"
  },
  {
    "objectID": "lectures/10.html#hypothesis-testing-steps",
    "href": "lectures/10.html#hypothesis-testing-steps",
    "title": "Statistical Inference",
    "section": "Hypothesis Testing Steps",
    "text": "Hypothesis Testing Steps\n\nState \\(H_0\\) and \\(H_1\\)\nChoose \\(\\alpha\\)\nCompute confidence interval/p-value\nMake a decision\n\n\nWalk through the steps slowly with an example in mind. Emphasize that \\(\\alpha\\) is a threshold, not the actual probability of error."
  },
  {
    "objectID": "lectures/10.html#rejection-region",
    "href": "lectures/10.html#rejection-region",
    "title": "Statistical Inference",
    "section": "Rejection Region",
    "text": "Rejection Region\n\nThe rejection region is the set of all test statistic values that lead to rejecting \\(H_0\\).\nIt’s defined by a significance level (\\(\\alpha\\)) — the probability of rejecting \\(H_0\\), when it’s actually true."
  },
  {
    "objectID": "lectures/10.html#rejection-region-1",
    "href": "lectures/10.html#rejection-region-1",
    "title": "Statistical Inference",
    "section": "Rejection Region",
    "text": "Rejection Region\n\n\nCode\nalpha &lt;- 0.05\n\n# Critical values for two-tailed test\nz_critical &lt;- qnorm(1 - alpha / 2)\n\n# Create data for the normal curve\nx &lt;- seq(-4, 4, length = 1000)\ny &lt;- dnorm(x)\n\ndf &lt;- data.frame(x = x, y = y)\n\nggplot(df, aes(x = x, y = y)) +\n  geom_line(color = \"deepskyblue\", linewidth = 1) +\n  geom_area(data = subset(df, x &lt;= -z_critical), aes(y = y), fill = \"firebrick\", alpha = 0.5) +\n  geom_area(data = subset(df, x &gt;= z_critical), aes(y = y), fill = \"firebrick\", alpha = 0.5) +\n  geom_vline(xintercept = c(-z_critical, z_critical), linetype = \"dashed\", color = \"black\") +\n  theme_bw()"
  },
  {
    "objectID": "lectures/10.html#decision-making-1",
    "href": "lectures/10.html#decision-making-1",
    "title": "Statistical Inference",
    "section": "Decision Making",
    "text": "Decision Making\nHypothesis Testing will force you to make a decision: Reject \\(H_0\\) OR Fail to Reject \\(H_0\\)\n\nReject \\(H_0\\): The effect seen is not due to random chance, there is a process contributing to the effect.\n\n\nFail to Reject \\(H_0\\): The effect seen is due to random chance. Random sampling is the reason why an effect is displayed, not an underlying process."
  },
  {
    "objectID": "lectures/10.html#decision-making-p-value",
    "href": "lectures/10.html#decision-making-p-value",
    "title": "Statistical Inference",
    "section": "Decision Making: P-Value",
    "text": "Decision Making: P-Value\nThe p-value approach is one of the most common methods to report significant results. It is easier to interpret the p-value because it provides the probability of observing our test statistics, or something more extreme, given that the null hypothesis is true.\n\nIf \\(p &lt; \\alpha\\), then you reject \\(H_0\\); otherwise, you will fail to reject \\(H_0\\)."
  },
  {
    "objectID": "lectures/10.html#significance-level-alpha",
    "href": "lectures/10.html#significance-level-alpha",
    "title": "Statistical Inference",
    "section": "Significance Level \\(\\alpha\\)",
    "text": "Significance Level \\(\\alpha\\)\nThe significance level \\(\\alpha\\) is the probability you will reject the null hypothesis given that it was true.\n\nIn other words, \\(\\alpha\\) is the error rate that a researcher controls.\n\n\nTypically, we want this error rate to be small (\\(\\alpha = 0.05\\))."
  },
  {
    "objectID": "lectures/10.html#confidence-intervals-2",
    "href": "lectures/10.html#confidence-intervals-2",
    "title": "Statistical Inference",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval gives a range of plausible values for a population parameter.\nIt reflects uncertainty in point estimates from sample data.\n\n\nIntroduce confidence intervals as the natural next step after understanding sampling variability and standard error. Emphasize that point estimates are useful, but intervals give a more complete picture."
  },
  {
    "objectID": "lectures/10.html#interpretation",
    "href": "lectures/10.html#interpretation",
    "title": "Statistical Inference",
    "section": "Interpretation",
    "text": "Interpretation\n\n“We are 95% confident that the true mean lies between A and B.”\n\n\nThis does not mean there’s a 95% chance the mean is in that interval.\nIt means: if we repeated the sampling process many times, 95% of the intervals would contain the true value.\n\n\nThis is one of the most common misconceptions. Clarify that the confidence is in the method, not any one interval."
  },
  {
    "objectID": "lectures/10.html#factors-affecting-ci-width",
    "href": "lectures/10.html#factors-affecting-ci-width",
    "title": "Statistical Inference",
    "section": "Factors Affecting CI Width",
    "text": "Factors Affecting CI Width\n\nSample size (\\(n\\)): larger \\(n\\) → narrower CI\n\nStandard deviation (\\(s\\) or \\(\\sigma\\)): more variability → wider CI\n\nConfidence level: higher confidence → wider CI\n\n\nUse this to summarize what controls how “precise” our confidence interval is. Give examples of each."
  },
  {
    "objectID": "lectures/10.html#decision-making-confidence-interval-approach",
    "href": "lectures/10.html#decision-making-confidence-interval-approach",
    "title": "Statistical Inference",
    "section": "Decision Making: Confidence Interval Approach",
    "text": "Decision Making: Confidence Interval Approach\nThe confidence interval approach can evaluate a hypothesis test where the alternative hypothesis is \\(\\beta\\ne\\beta^*\\). The confidence interval approach will result in a lower and upper bound denoted as: \\((LB, UB)\\).\n\nIf \\(\\beta^*\\) is in \\((LB, UB)\\), then you fail to reject \\(H_0\\). If \\(\\beta^*\\) is not in \\((LB,UB)\\), then you reject \\(H_0\\)."
  },
  {
    "objectID": "lectures/10.html#conducting-ht-of-beta_j",
    "href": "lectures/10.html#conducting-ht-of-beta_j",
    "title": "Statistical Inference",
    "section": "Conducting HT of \\(\\beta_j\\)",
    "text": "Conducting HT of \\(\\beta_j\\)\nXLM &lt;- lm(Y ~ X, data = DATA)\ntidy(XLM)\n\nXLM: Object where the model is stored\nY: Name of the outcome variable in DATA\nX: Name of the Predictor Variable(s) in DATA\nDATA: Name of the data set"
  },
  {
    "objectID": "lectures/10.html#example",
    "href": "lectures/10.html#example",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\nIs there a significant relationship between penguin body mass (outcome; body_mass) and flipper length (predictor; flipper_len)? Use the penguins data set to determine a significant association."
  },
  {
    "objectID": "lectures/10.html#example-1",
    "href": "lectures/10.html#example-1",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\n\n\nCode\nm1 &lt;- lm(body_mass ~ flipper_len, penguins)\ntidy(m1)\n\n\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic   p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)  -5781.     306.       -18.9 5.59e- 55\n#&gt; 2 flipper_len     49.7      1.52      32.7 4.37e-107"
  },
  {
    "objectID": "lectures/10.html#confidence-interval",
    "href": "lectures/10.html#confidence-interval",
    "title": "Statistical Inference",
    "section": "Confidence Interval",
    "text": "Confidence Interval\ntidy(XLM, conf.int = TRUE)\n\nXLM: Object where the model is stored"
  },
  {
    "objectID": "lectures/10.html#x-confidence-interval",
    "href": "lectures/10.html#x-confidence-interval",
    "title": "Statistical Inference",
    "section": "X% Confidence Interval",
    "text": "X% Confidence Interval\ntidy(XLM, conf.int = TRUE, conf.level = X)\n\nXLM: Object where the model is stored\nX: A number between 0 and 1 to specify confidence level"
  },
  {
    "objectID": "lectures/10.html#example-2",
    "href": "lectures/10.html#example-2",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\n\n\nCode\ntidy(m1, conf.int = TRUE, conf.level = 0.9)\n\n\n#&gt; # A tibble: 2 × 7\n#&gt;   term        estimate std.error statistic   p.value conf.low conf.high\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)  -5781.     306.       -18.9 5.59e- 55  -6285.    -5276. \n#&gt; 2 flipper_len     49.7      1.52      32.7 4.37e-107     47.2      52.2"
  },
  {
    "objectID": "lectures/10.html#mammals-sleep-data-set",
    "href": "lectures/10.html#mammals-sleep-data-set",
    "title": "Statistical Inference",
    "section": "Mammals Sleep Data Set",
    "text": "Mammals Sleep Data Set\nThe msleep data set contains information on sleeping patterns for mammals. We are interested in understanding the relationship of the length of sleep cycle (sleep_cycle; in hours) and rem sleep (sleep_rem; rapid eye movement; in hours)."
  },
  {
    "objectID": "lectures/10.html#red-wine-data",
    "href": "lectures/10.html#red-wine-data",
    "title": "Statistical Inference",
    "section": "Red Wine Data",
    "text": "Red Wine Data\nThe Wine Quality data set contains data on information on both red and white wine from North Portugal. We are interested in seeing if pH of the red wine (predictor variable) affects the quality (outcome variable).\n\n\nCode\nurl &lt;- \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\nwine &lt;- read_delim(url, delim = \";\")"
  },
  {
    "objectID": "lectures/10.html#conducting-ht-of-beta_j-1",
    "href": "lectures/10.html#conducting-ht-of-beta_j-1",
    "title": "Statistical Inference",
    "section": "Conducting HT of \\(\\beta_j\\)",
    "text": "Conducting HT of \\(\\beta_j\\)\nXLM &lt;- glm(Y ~ X, data = DATA, family = binomial())\ntidy(XLM)\n\nXLM: Object where the model is stored\nY: Name of the outcome variable in DATA\nX: Name of the Predictor Variable(s) in DATA\nDATA: Name of the data set"
  },
  {
    "objectID": "lectures/10.html#example-3",
    "href": "lectures/10.html#example-3",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\nIs there a significant association between heart disease (outcome; disease) and resting blood pressure (predictor; trestbps). Use the heart_disease data set to determine a significant association."
  },
  {
    "objectID": "lectures/10.html#example-4",
    "href": "lectures/10.html#example-4",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\n\n\nCode\nm1 &lt;- glm(disease ~ trestbps, heart_disease, family = binomial())\ntidy(m1)\n\n\n#&gt; # A tibble: 2 × 5\n#&gt;   term        estimate std.error statistic p.value\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 (Intercept)  -2.49     0.905       -2.76 0.00586\n#&gt; 2 trestbps      0.0177   0.00681      2.61 0.00914"
  },
  {
    "objectID": "lectures/10.html#confidence-interval-1",
    "href": "lectures/10.html#confidence-interval-1",
    "title": "Statistical Inference",
    "section": "Confidence Interval",
    "text": "Confidence Interval\ntidy(XLM, conf.int = TRUE, conf.level = LEVEL)\n\nXLM: Object where the model is stored\nLEVEL: A number between 0 and 1 to specify confidence level\ndefaults to 0.95"
  },
  {
    "objectID": "lectures/10.html#example-5",
    "href": "lectures/10.html#example-5",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\n\n\nCode\ntidy(m1, conf.int = TRUE)\n\n\n#&gt; # A tibble: 2 × 7\n#&gt;   term        estimate std.error statistic p.value conf.low conf.high\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)  -2.49     0.905       -2.76 0.00586 -4.31      -0.747 \n#&gt; 2 trestbps      0.0177   0.00681      2.61 0.00914  0.00461    0.0314"
  },
  {
    "objectID": "lectures/10.html#odds-ratio-confidence-intervat",
    "href": "lectures/10.html#odds-ratio-confidence-intervat",
    "title": "Statistical Inference",
    "section": "Odds Ratio & Confidence Intervat",
    "text": "Odds Ratio & Confidence Intervat\ntidy(XLM, exponentiate = TRUE, conf.int = TRUE)\n\nXLM: Object where the model is stored"
  },
  {
    "objectID": "lectures/10.html#example-6",
    "href": "lectures/10.html#example-6",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\n\n\nCode\ntidy(m1, exponentiate = TRUE, conf.int = TRUE)\n\n\n#&gt; # A tibble: 2 × 7\n#&gt;   term        estimate std.error statistic p.value conf.low conf.high\n#&gt;   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1 (Intercept)   0.0826   0.905       -2.76 0.00586   0.0135     0.474\n#&gt; 2 trestbps      1.02     0.00681      2.61 0.00914   1.00       1.03"
  },
  {
    "objectID": "lectures/10.html#breast-cancer-data",
    "href": "lectures/10.html#breast-cancer-data",
    "title": "Statistical Inference",
    "section": "Breast Cancer Data",
    "text": "Breast Cancer Data\nThe Breast Cancer data set contains information about image diagnosis of individuals from Wisconsin. We are interested if breast cancer diagnosis (outcome variable; Benign or Malignant), is affected by tumor radius.\n\n\nCode\nurl &lt;- \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\nbc &lt;- read.csv(url, header = FALSE)\n\n# Add column names\ncolnames(bc) &lt;- c(\"id\", \"diagnosis\", \"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\",\n                  \"compactness\", \"concavity\", paste0(\"V\", 10:32))\n\n# Convert diagnosis to factor\nbc$diagnosis &lt;- factor(bc$diagnosis, levels = c(\"B\", \"M\"), labels = c(\"Benign\", \"Malignant\"))"
  },
  {
    "objectID": "lectures/10.html#bank-note-classification",
    "href": "lectures/10.html#bank-note-classification",
    "title": "Statistical Inference",
    "section": "Bank Note Classification",
    "text": "Bank Note Classification\nThe Bank Note data set contains information about bank note authentication based on images. We are interested in seeing if class (outcome variable; real or fake) is associated by image entropy (predictor).\n\n\nCode\nurl &lt;- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\"\nbank &lt;- read.csv(url, header = FALSE)\n\ncolnames(bank) &lt;- c(\"variance\", \"skewness\", \"curtosis\", \"entropy\", \"class\")\nbank$class &lt;- factor(bank$class, levels = c(0, 1), labels = c(\"Genuine\", \"Forged\"))"
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "Categorical Data\n\n\n\n\n\nProvides an overview descriptive statistics and data visualization techniques for categorical data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Generating Process\n\n\n\n\n\nProvides a brief introduction of data, study design, and the data generating process.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistribution Functions\n\n\n\n\n\nProvides an overview distribution function (mathematical models).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup  Regression\n\n\n\n\n\nDiscuss using categorical predictor variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstalling R and Positron\n\n\nClass Lecture\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariable  Regression\n\n\n\n\n\nDiscuss how to model multivariable predictors to a single outcome.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumerical Data\n\n\n\n\n\nProvides an overview descriptive statistics and data visualization techniques for numerical data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSampling Distribution\n\n\n\n\n\nDiscuss for sampling distributions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple  Linear Regression\n\n\n\n\n\nBegins the discussion for linear regression.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple  Logistic Regression\n\n\n\n\n\nBegins the discussion for logistic regression.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical  Modeling\n\n\n\n\n\nFinish the discussion on model inference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Inference\n\n\n\n\n\nBegin the discussion of statistical inference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical Inference\n\n\nGroup Model Inference\n\n\nTesting the difference in groups.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStatistics\n\n\nA Math? A Science? An Art? Or Something Else?\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ec/ec_3.html",
    "href": "ec/ec_3.html",
    "title": "Extra Credit 3",
    "section": "",
    "text": "After reading one book below, create a video essay that summarizes the book, provide a brief analysis in supporting or opposing the book, and connect key elements of the book to your every day life. The video essay should be 10 minutes being narrated by your own voice. Use visual aids, such as a powerpoint presentation, to highlight your main findings, and how it relates to your own life. All books should be available through the Broome Library.\nBooks:\n\nEmpire of AI\n\nKaren Hao\n\nThe Last Human Job\n\nAllison Pugh\n\nThe Book of Why\n\nJudea Pearl\n\nAlgorithms of Oppression\n\nSafiya Umoja Noble\n\nData Feminism\n\nCatherine D’Ignazio and Lauren Klein\n\nWeapons of Math Destruction\n\nCathy O’Niel\n\nInvisible Women : data bias in a world designed for men\n\nCaroline Criado Perez\n\nFactfulness: Ten Reasons We’re Wrong About the World… and Why Things are Better Than You Think\n\nHans Rosling\n\nArtificial Unintelligence: How Computers Misunderstand the World\n\nMerideth Broussard\n\nTechnically Wrong: Sexist Apps, Biased Algorithms, and Other Threats of Toxic Tech\n\nSara Wachter-Boettcher\n\nOR ANY Book Approved By Me (Deadline for Approval by April 17, 2026)\n\nVideo Essay Guidelines:\n\n10 Minutes Long\nUse of visual aids\nNarrated by your own voice\nDue 5/17/2026\n\nWorth 2 final grade percentage points."
  },
  {
    "objectID": "ec/ec_1.html",
    "href": "ec/ec_1.html",
    "title": "Extra Credit 1",
    "section": "",
    "text": "Due 2/13/2025\nWorth 1 final grade percentage points.\n\nWrite a Wellness Plan\nWrite a welness plan to ensure you will maintain your overall well being.\nReport guidelines\n\n2-3 Pages\nDouble Spaced\n12 point font"
  },
  {
    "objectID": "ec.html",
    "href": "ec.html",
    "title": "Extra Credit",
    "section": "",
    "text": "Extra Credit is designed to expand on different topics that related to Probability and Statistics, but are not necessarily required for the course. Additionally, these opportunities provide students relief when unexpected situations occur during the semester. While it is not required, I encourage everyone to attempt each opportunity.\nBelow is more information on each assignment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Credit 1\n\n\nInstructions for extra credit one.\n\n\n\n\n\nJan 2, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Credit 2\n\n\nInstructions for extra credit two.\n\n\n\n\n\nJan 3, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Credit 3\n\n\nInstructions for extra credit three.\n\n\n\n\n\nJan 4, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "ec/ec_2.html",
    "href": "ec/ec_2.html",
    "title": "Extra Credit 2",
    "section": "",
    "text": "After reading one book below, create a video essay that summarizes the book, provide a brief analysis in supporting or opposing the book, and connect key elements of the book to your every day life. The video essay should be 10 minutes being narrated by your own voice. Use visual aids, such as a powerpoint presentation, to highlight your main findings, and how it relates to your own life. All books should be available through the Broome Library.\nBooks:\n\nMake it Stick: The Science of Successful Learning\n\nPeter Brown\n\nTeach Yourself How to Learn: Strategies you can use to ace any course\n\nSaundra McGuire\n\nLimitless Mind\n\nJo Boaler\n\n\nVideo Essay Guidelines:\n\n10 Minutes Long\nUse of visual aids\nNarrated by your own voice\nDue 5/17/2025\n\nWorth 2 final grade percentage points."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Elementary Statistics!",
    "section": "",
    "text": "NoteBrief Introduction\n\n\n\n\n\nWelcome to the course! This is the home page of the course where I will provide a recap on what was covered in the week. Here I will post any documents or videos for your reference. If you have any questions, please email me at isaac.qs@csuci.edu."
  },
  {
    "objectID": "lectures/1.html#observations",
    "href": "lectures/1.html#observations",
    "title": "Data Generating Process",
    "section": "Observations",
    "text": "Observations\nAn observation is the unit which contains information to be obtained.\n\nAlso known as experimental unit."
  },
  {
    "objectID": "lectures/1.html#data-1",
    "href": "lectures/1.html#data-1",
    "title": "Data Generating Process",
    "section": "Data",
    "text": "Data\nData is information from a particular experimental unit. There can be more that one piece of information per experimental unit."
  },
  {
    "objectID": "lectures/1.html#data-structure",
    "href": "lectures/1.html#data-structure",
    "title": "Data Generating Process",
    "section": "Data Structure",
    "text": "Data Structure\nThe structure of the data can be represented in various forms:\n\nA list of long numbers\nTable"
  },
  {
    "objectID": "lectures/1.html#tabular-form",
    "href": "lectures/1.html#tabular-form",
    "title": "Data Generating Process",
    "section": "Tabular Form",
    "text": "Tabular Form"
  },
  {
    "objectID": "lectures/1.html#measurements-1",
    "href": "lectures/1.html#measurements-1",
    "title": "Data Generating Process",
    "section": "Measurements",
    "text": "Measurements\nMeasurements are the processes where we represent an attribute of an experimental unit as either a number or category."
  },
  {
    "objectID": "lectures/1.html#quantitative-measurements",
    "href": "lectures/1.html#quantitative-measurements",
    "title": "Data Generating Process",
    "section": "Quantitative Measurements",
    "text": "Quantitative Measurements\nQuantitative measurements are data measurements that take a numeric form."
  },
  {
    "objectID": "lectures/1.html#qualitative-measurements",
    "href": "lectures/1.html#qualitative-measurements",
    "title": "Data Generating Process",
    "section": "Qualitative Measurements",
    "text": "Qualitative Measurements\nQualitative measurements are data measurements that take a certain category."
  },
  {
    "objectID": "lectures/1.html#value",
    "href": "lectures/1.html#value",
    "title": "Data Generating Process",
    "section": "Value",
    "text": "Value\nA value is a description (number or category) of a specific attribute of an experimental unit."
  },
  {
    "objectID": "lectures/1.html#variable",
    "href": "lectures/1.html#variable",
    "title": "Data Generating Process",
    "section": "Variable",
    "text": "Variable\nA variable is the descriptive attribute that we want to obtain from an experimental unit. In terms of a data set, the variable contains all the values of specific attribute in a sample."
  },
  {
    "objectID": "lectures/1.html#research-question",
    "href": "lectures/1.html#research-question",
    "title": "Data Generating Process",
    "section": "Research Question",
    "text": "Research Question\n\nA research question is designed to create new knowledge of certain phenomenons observed in the world.\nThis is designed by conducting a research project that systematically answers the question.\nThe study design is the procedure in which data is collected to answer the question, while reducing any potential bias while conducting the study."
  },
  {
    "objectID": "lectures/1.html#study-design-1",
    "href": "lectures/1.html#study-design-1",
    "title": "Data Generating Process",
    "section": "Study Design",
    "text": "Study Design\n\nThis is the procedure designed to answer a research question.\nEntails procedures to collect data that answers a research question.\nDictates how the data will be analyzed.\nDetermines how the data is quantified and what is the experimental unit."
  },
  {
    "objectID": "lectures/1.html#sampling-1",
    "href": "lectures/1.html#sampling-1",
    "title": "Data Generating Process",
    "section": "Sampling",
    "text": "Sampling\nThe process of a selecting a small subset from a large population.\n\n\n\n\n\n\n\nImage Provided by Simply Psychology."
  },
  {
    "objectID": "lectures/1.html#sampling-2",
    "href": "lectures/1.html#sampling-2",
    "title": "Data Generating Process",
    "section": "Sampling",
    "text": "Sampling\nWhen Sampling you want to maintain these properties:\n\nRepresentative sample\nLarge enough sample size"
  },
  {
    "objectID": "lectures/1.html#sampling-example",
    "href": "lectures/1.html#sampling-example",
    "title": "Data Generating Process",
    "section": "Sampling Example",
    "text": "Sampling Example\nWe want to answer the question, are people happy?"
  },
  {
    "objectID": "lectures/1.html#random-sampling",
    "href": "lectures/1.html#random-sampling",
    "title": "Data Generating Process",
    "section": "Random Sampling",
    "text": "Random Sampling\nWhen sampling, we strive for random sampling\n\nEach unit in the population of interest must have an equal probability of being selected for the study.\nThis ensures a representative population"
  },
  {
    "objectID": "lectures/1.html#independent-sampling",
    "href": "lectures/1.html#independent-sampling",
    "title": "Data Generating Process",
    "section": "Independent Sampling",
    "text": "Independent Sampling\nIn addition to random sampling, we strive to make sure each unit is independent from each other.\n\nThe probability of UNIT A being sampled will not affect the probability of UNIT B to be sampled."
  },
  {
    "objectID": "lectures/1.html#sampling-variation",
    "href": "lectures/1.html#sampling-variation",
    "title": "Data Generating Process",
    "section": "Sampling Variation",
    "text": "Sampling Variation\n\nRandom samples may vary from the population of interest.\nDue to randomness, samples many not look the same or biased.\nHowever, this is to be expected as the sample will not be biased in one way or another.\nSamples are then considered unbiased as long as experimental units were collected randomly."
  },
  {
    "objectID": "lectures/1.html#data-2",
    "href": "lectures/1.html#data-2",
    "title": "Data Generating Process",
    "section": "Data",
    "text": "Data\nThe measurement collected from an experimental unit."
  },
  {
    "objectID": "lectures/1.html#data-distribution",
    "href": "lectures/1.html#data-distribution",
    "title": "Data Generating Process",
    "section": "Data Distribution",
    "text": "Data Distribution\nWhen thinking about data, we know an attribute is allowed to vary. With this variation, some numbers are more likely to be observed than others."
  },
  {
    "objectID": "lectures/1.html#forest-from-the-trees",
    "href": "lectures/1.html#forest-from-the-trees",
    "title": "Data Generating Process",
    "section": "Forest from the trees",
    "text": "Forest from the trees\n\n\n\n\n\n\n\nImage Provided by Pexels"
  },
  {
    "objectID": "lectures/1.html#sample",
    "href": "lectures/1.html#sample",
    "title": "Data Generating Process",
    "section": "Sample",
    "text": "Sample\nWhen inspecting data:\n\nDo not focus on one individual data point.\nSee how data points is in relation to other data points.\nSee what is common\nSee what is rare"
  },
  {
    "objectID": "lectures/1.html#data-generation-process-dgp",
    "href": "lectures/1.html#data-generation-process-dgp",
    "title": "Data Generating Process",
    "section": "Data Generation Process (DGP)",
    "text": "Data Generation Process (DGP)\nThe data generation process is understanding how variation from the population is transferred to the data collected.\n\nA population has a mechanism to produce data, understanding this mechanism is essential understanding the data."
  },
  {
    "objectID": "lectures/1.html#dgp",
    "href": "lectures/1.html#dgp",
    "title": "Data Generating Process",
    "section": "DGP",
    "text": "DGP\nA populations DGP can be defined with the following characteristics:\n\nThe potential outcomes that can be observed when measuring\nEach potential outcome will have a probability of being observed\n\nThe probability must be between 0 and 1\n\nSum of all the probabilities of each outcome will add up to 1"
  },
  {
    "objectID": "lectures/1.html#flipping-a-coin",
    "href": "lectures/1.html#flipping-a-coin",
    "title": "Data Generating Process",
    "section": "Flipping a Coin",
    "text": "Flipping a Coin\n\nFlipping a coin results in either heads or tail.\nThe probability for heads is 50%\nThe DGP of flipping a coin is the process of selecting an outcome, given the probability of both options are 50%."
  },
  {
    "objectID": "lectures/1.html#rolling-a-die",
    "href": "lectures/1.html#rolling-a-die",
    "title": "Data Generating Process",
    "section": "Rolling a die",
    "text": "Rolling a die\n\n\n\n\n\nImage Provided by Pexels"
  },
  {
    "objectID": "lectures/1.html#measuring-body-temperature",
    "href": "lectures/1.html#measuring-body-temperature",
    "title": "Data Generating Process",
    "section": "Measuring Body Temperature",
    "text": "Measuring Body Temperature\n\n\n\n\n\nImage Provided by Pexels"
  },
  {
    "objectID": "lectures/1.html#inference",
    "href": "lectures/1.html#inference",
    "title": "Data Generating Process",
    "section": "Inference",
    "text": "Inference\n\nHow do we use DGP and sampling to understand the world?\nWe can use a sample to understand the DGP.\nWe can use the DGP to understand the sample."
  },
  {
    "objectID": "lectures/1.html#visualizing-a-dgp",
    "href": "lectures/1.html#visualizing-a-dgp",
    "title": "Data Generating Process",
    "section": "Visualizing a DGP",
    "text": "Visualizing a DGP"
  },
  {
    "objectID": "lectures/1.html#visualizing-dgp",
    "href": "lectures/1.html#visualizing-dgp",
    "title": "Data Generating Process",
    "section": "Visualizing DGP",
    "text": "Visualizing DGP"
  },
  {
    "objectID": "lectures/1.html#example",
    "href": "lectures/1.html#example",
    "title": "Data Generating Process",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "lectures/1.html#statistical-model-1",
    "href": "lectures/1.html#statistical-model-1",
    "title": "Data Generating Process",
    "section": "Statistical Model",
    "text": "Statistical Model\n\\[\nY \\sim F(\\theta)\n\\]\n\n\\(Y\\): A data value generated for DGP\n\\(F\\): A generic mathematical model that describes the DGP\n\\(\\theta\\): Parameter controlling the shape and form of the DGP"
  },
  {
    "objectID": "lectures/1.html#statistical-model-2",
    "href": "lectures/1.html#statistical-model-2",
    "title": "Data Generating Process",
    "section": "Statistical Model",
    "text": "Statistical Model\n\\[\nY = \\beta + \\varepsilon\n\\]\n\n\\(\\beta\\): The average value we expect to see\n\\(\\varepsilon \\sim F(\\cdot)\\): Error Term"
  },
  {
    "objectID": "lectures/1.html#statistical-model-3",
    "href": "lectures/1.html#statistical-model-3",
    "title": "Data Generating Process",
    "section": "Statistical Model",
    "text": "Statistical Model\n\\[\nY = \\beta + \\varepsilon\n\\]\n\n\n\\(\\beta\\): Explained Part\n\nThis is what we expect to see if we took an educated guess\nThe educated guess can incorporate information that is related to \\(Y\\)\n\n\n\\(\\varepsilon\\): Unexplained Part\n\nRandomness\nIncorporates several types of variation\n\nMeasurement Error\nBiological Error\nEnvironmental Error"
  },
  {
    "objectID": "lectures/11.html#species-and-body-mass",
    "href": "lectures/11.html#species-and-body-mass",
    "title": "Statistical Inference",
    "section": "Species and Body Mass",
    "text": "Species and Body Mass\n\n\n\nIs there a difference in body mass between the penguins species?\nIs the difference due to a natural phenomenon or randomness?\n\n\n\n\nCode\npenguins |&gt; ggplot(aes(x=species, y = body_mass)) +\n  geom_jitter() + \n  geom_boxplot() + \n  labs(x = \"Species\", y = \"Body Mass\")"
  },
  {
    "objectID": "lectures/11.html#chest-pain-and-heart-disease",
    "href": "lectures/11.html#chest-pain-and-heart-disease",
    "title": "Statistical Inference",
    "section": "Chest Pain and Heart Disease",
    "text": "Chest Pain and Heart Disease\n\n\n\nIs there a difference in proportions between the different chest pains?\nIs the difference due to a natural phenomenon or randomness?\n\n\n\n\nCode\nheart_disease |&gt; ggplot(aes(x=cp, fill = disease)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Chest Pain\") + \n  theme(axis.text.x = element_text(size = 14))"
  },
  {
    "objectID": "lectures/11.html#group-model-inference-1",
    "href": "lectures/11.html#group-model-inference-1",
    "title": "Statistical Inference",
    "section": "Group Model Inference",
    "text": "Group Model Inference"
  },
  {
    "objectID": "lectures/11.html#group-model-inference-2",
    "href": "lectures/11.html#group-model-inference-2",
    "title": "Statistical Inference",
    "section": "Group Model Inference",
    "text": "Group Model Inference\nGroup Model Inference is the act of conducting a hypothesis test on the entire group model. We do this to determine if the group model is significantly different from just using the sample mean or proportion.\n\nGroup model inference determines if more variation is explained by including categorical variables."
  },
  {
    "objectID": "lectures/11.html#group-model-inference-3",
    "href": "lectures/11.html#group-model-inference-3",
    "title": "Statistical Inference",
    "section": "Group Model Inference",
    "text": "Group Model Inference\n\nWe will conduct group model inference to determine if a group model explains more variation . Both Linear and Logistic Regression have techniques to test different models.\nFor Linear Regression, we determine the significance of the variation explained using an Analysis of Variance (ANOVA) table and F test.\nFor Logistic Regression, we determine the significance of the variation explained using a Likelihood Ratio test.\nConducting Model Inference first ensures that the Family-wise Error Rate is controlled."
  },
  {
    "objectID": "lectures/11.html#group-model-inference-4",
    "href": "lectures/11.html#group-model-inference-4",
    "title": "Statistical Inference",
    "section": "Group Model Inference",
    "text": "Group Model Inference\n\nGroup model inference compares a Full and Reduced model to determine if they are different.\nFull: The group model containing the categorical variable.\nReduced: Either the sample mean or proportion."
  },
  {
    "objectID": "lectures/11.html#linear-models",
    "href": "lectures/11.html#linear-models",
    "title": "Statistical Inference",
    "section": "Linear Models",
    "text": "Linear Models\n\n\nFull Model\n\\[\nY =  \\beta_0 + \\beta_1 D_1 + \\cdots + \\beta_p D_p\n\\]\n\n\\(D_1, \\cdots, D_p\\): Dummy variables for categorical variables\n\\(\\beta_0, \\beta_1, \\cdots, \\beta_p\\): Regression coefficients\n\n\nReduced Model\n\\[\nY =  \\bar y\n\\]\n\n\\(\\bar y\\): Average of the outcome"
  },
  {
    "objectID": "lectures/11.html#generalized-linear-models",
    "href": "lectures/11.html#generalized-linear-models",
    "title": "Statistical Inference",
    "section": "Generalized Linear Models",
    "text": "Generalized Linear Models\n\n\nFull Model\n\\[\nY =  \\beta_0 + \\beta_1 D_1 + \\cdots + \\beta_p D_p\n\\]\n\n\\(D_1, \\cdots, D_p\\): Dummy variables for categorical variables\n\\(\\beta_0, \\beta_1, \\cdots, \\beta_p\\): Regression coefficients\n\n\nReduced Model\n\\[\nlo(Y) =  \\hat p\n\\]\n\n\\(\\hat p\\): Sample proportion of the outcome"
  },
  {
    "objectID": "lectures/11.html#null-and-alt-hypothesis",
    "href": "lectures/11.html#null-and-alt-hypothesis",
    "title": "Statistical Inference",
    "section": "Null and Alt Hypothesis",
    "text": "Null and Alt Hypothesis\n\\(H_0\\): The different categories do not have significantly different means/proportions from each other.\n\\(H_a\\): At least two categories have significantly different means/proportions from each other."
  },
  {
    "objectID": "lectures/11.html#motivation",
    "href": "lectures/11.html#motivation",
    "title": "Statistical Inference",
    "section": "Motivation",
    "text": "Motivation\n\nIn multiple hypothesis testing, we test several hypotheses simultaneously.\nThe probability of making at least one Type I error increases with the number of tests.\nHence, we need error control methods."
  },
  {
    "objectID": "lectures/11.html#type-i-error-and-its-rate",
    "href": "lectures/11.html#type-i-error-and-its-rate",
    "title": "Statistical Inference",
    "section": "Type I Error and Its Rate",
    "text": "Type I Error and Its Rate\nType I Error (False Positive): Rejecting a null hypothesis (\\(H_0\\)), when it is true.\nType I Error Rate (\\(\\alpha\\)): The probability of making a Type I error in a single hypothesis test.\n\\[\n\\alpha = P(\\text{Reject } H_0 \\mid H_0 \\text{ is true})\n\\]\nTypically, \\(\\alpha = 0.05\\), meaning a 5% chance of incorrectly rejecting a true null hypothesis."
  },
  {
    "objectID": "lectures/11.html#definition-of-fwer",
    "href": "lectures/11.html#definition-of-fwer",
    "title": "Statistical Inference",
    "section": "Definition of FWER",
    "text": "Definition of FWER\nFamily-Wise Error Rate (FWER): The probability of making one or more Type I errors among all hypotheses tested.\n\\[\n\\text{FWER} = P(\\text{At least one false rejection}) = P(V \\ge 1)\n\\]\nwhere:\n\n\\(V\\) = number of false positives (incorrect rejections)"
  },
  {
    "objectID": "lectures/11.html#why-control-fwer",
    "href": "lectures/11.html#why-control-fwer",
    "title": "Statistical Inference",
    "section": "Why Control FWER?",
    "text": "Why Control FWER?\n\nMaintains overall confidence in conclusions.\nAvoids claiming false discoveries when many tests are run.\nTrade-off: Strong control of FWER reduces power (increases Type II error)."
  },
  {
    "objectID": "lectures/11.html#methods-to-control-fwer",
    "href": "lectures/11.html#methods-to-control-fwer",
    "title": "Statistical Inference",
    "section": "Methods to Control FWER",
    "text": "Methods to Control FWER\n\nBonferroni Correction\nHolm-Bonferroni Procedure (Step-down)\nTukey’s Honest Significant Difference (HSD)"
  },
  {
    "objectID": "lectures/11.html#linear-model-inference-1",
    "href": "lectures/11.html#linear-model-inference-1",
    "title": "Statistical Inference",
    "section": "Linear Model Inference",
    "text": "Linear Model Inference\nGiven 2 models:\n\\[\n\\hat Y = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_2 + \\cdots + \\hat\\beta_p X_p\n\\]\nor\n\\[\n\\hat Y = \\bar y\n\\]\n\nIs the model with predictors do a better job than using the average?"
  },
  {
    "objectID": "lectures/11.html#linear-models-difference-groups",
    "href": "lectures/11.html#linear-models-difference-groups",
    "title": "Statistical Inference",
    "section": "Linear Models: Difference Groups",
    "text": "Linear Models: Difference Groups\nGiven a categorical variable with 4 categories, which model is better:\n\\[\n\\hat Y = \\hat\\beta_0 + \\hat\\beta_1 C_1 + \\hat\\beta_2 C_2 + \\hat\\beta_3 C_3  \n\\]\nor\n\\[\n\\hat Y = \\bar y\n\\]\n\nAre the 2 models different from each other?"
  },
  {
    "objectID": "lectures/11.html#anova-table",
    "href": "lectures/11.html#anova-table",
    "title": "Statistical Inference",
    "section": "ANOVA Table",
    "text": "ANOVA Table\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSS\nMS\nF\n\n\n\n\nModel\n\\(DFR=k-1\\)\n\\(SSR\\)\n\\(MSR=\\frac{SSM}{DFR}\\)\n\\(\\hat F=\\frac{MSR}{MSE}\\)\n\n\nError\n\\(DFE=n-k\\)\n\\(SSE\\)\n\\(MSE=\\frac{SSE}{DFE}\\)\n\n\n\nTotal\n\\(TDF=n-1\\)\n\\(TSS=SSR+SSE\\)\n\n\n\n\n\n\\[\n\\hat F \\sim F(DFR, DFE)\n\\]"
  },
  {
    "objectID": "lectures/11.html#conducting-an-anova-in-r",
    "href": "lectures/11.html#conducting-an-anova-in-r",
    "title": "Statistical Inference",
    "section": "Conducting an ANOVA in R",
    "text": "Conducting an ANOVA in R\nxlm &lt;- lm(Y ~ X, data = DATA)\nanova(xlm)\n\nY: Outcome variable in DATA\nX: Categorical variable in DATA\nDATA: Name of the data (frame) set"
  },
  {
    "objectID": "lectures/11.html#species-and-body-mass-1",
    "href": "lectures/11.html#species-and-body-mass-1",
    "title": "Statistical Inference",
    "section": "Species and Body Mass",
    "text": "Species and Body Mass\n\n\n\nIs there a difference in body mass between the penguins species?\nIs the difference due to a natural phenomenon or randomness?\n\n\n\n\nCode\npenguins |&gt; ggplot(aes(x=species, y = body_mass)) +\n  geom_jitter() + \n  geom_boxplot() + \n  labs(x = \"Species\", y = \"Body Mass\")"
  },
  {
    "objectID": "lectures/11.html#example-hypothesis",
    "href": "lectures/11.html#example-hypothesis",
    "title": "Statistical Inference",
    "section": "Example: Hypothesis",
    "text": "Example: Hypothesis\n\n\\(H_0\\): The mean body mass are the same between the 3 penguin species.\n\\(H_1\\): At least one species pairing have different mean body mass."
  },
  {
    "objectID": "lectures/11.html#example-anova",
    "href": "lectures/11.html#example-anova",
    "title": "Statistical Inference",
    "section": "Example: ANOVA",
    "text": "Example: ANOVA\n\n\nCode\nxlm &lt;- lm(body_mass ~ species, data = penguins)\nanova(xlm)\n\n\n#&gt; Analysis of Variance Table\n#&gt; \n#&gt; Response: body_mass\n#&gt;            Df    Sum Sq  Mean Sq F value    Pr(&gt;F)    \n#&gt; species     2 145190219 72595110  341.89 &lt; 2.2e-16 ***\n#&gt; Residuals 330  70069447   212332                      \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/11.html#logistic-model-inference-1",
    "href": "lectures/11.html#logistic-model-inference-1",
    "title": "Statistical Inference",
    "section": "Logistic Model Inference",
    "text": "Logistic Model Inference\nGiven 2 models:\n\\[\ng(\\hat Y) = \\hat\\beta_0 + \\hat\\beta_1 X_1 + \\hat\\beta_2 X_2 + \\cdots + \\hat\\beta_p X_p\n\\]\nor\n\\[\ng(\\hat Y) = \\bar y\n\\]\n\nIs the model with predictors do a better job than using the average?"
  },
  {
    "objectID": "lectures/11.html#logistic-model-inference-2",
    "href": "lectures/11.html#logistic-model-inference-2",
    "title": "Statistical Inference",
    "section": "Logistic Model Inference",
    "text": "Logistic Model Inference\nGiven a categorical variable with 4 categories, which model is better:\n\\[\ng(\\hat Y) = \\hat\\beta_0 + \\hat\\beta_1 C_1 + \\hat\\beta_2 C_2 + \\hat\\beta_3 C_3  \n\\]\nor\n\\[\ng(\\hat Y) = \\bar y\n\\]\n\nAre the 2 models different from each other?"
  },
  {
    "objectID": "lectures/11.html#likelihood-ratio-test-logistic",
    "href": "lectures/11.html#likelihood-ratio-test-logistic",
    "title": "Statistical Inference",
    "section": "Likelihood Ratio Test (Logistic)",
    "text": "Likelihood Ratio Test (Logistic)\nThe Likelihood Ratio Test is a test to determine whether the likelihood of observing the outcome is significantly bigger in a larger, more complicated model, than a simpler model.\nIt conducts a hypothesis tests to see if models are significantly different from each other."
  },
  {
    "objectID": "lectures/11.html#conducting-an-lrt-in-r",
    "href": "lectures/11.html#conducting-an-lrt-in-r",
    "title": "Statistical Inference",
    "section": "Conducting an LRT in R",
    "text": "Conducting an LRT in R\nxlm &lt;- glm(Y ~ X, data = DATA, family = binomial)\nanova(xlm)\n\nY: Outcome variable in DATA\nX: Categorical variable in DATA\nDATA: Name of the data (frame) set"
  },
  {
    "objectID": "lectures/11.html#chest-pain-and-heart-disease-1",
    "href": "lectures/11.html#chest-pain-and-heart-disease-1",
    "title": "Statistical Inference",
    "section": "Chest Pain and Heart Disease",
    "text": "Chest Pain and Heart Disease\n\n\n\nIs there a difference in proportions between the different chest pains?\nIs the difference due to a natural phenomenon or randomness?\n\n\n\n\nCode\nheart_disease |&gt; ggplot(aes(x=cp, fill = disease)) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Chest Pain\") + \n  theme(axis.text.x = element_text(size = 14))"
  },
  {
    "objectID": "lectures/11.html#example-hypothesis-1",
    "href": "lectures/11.html#example-hypothesis-1",
    "title": "Statistical Inference",
    "section": "Example: Hypothesis",
    "text": "Example: Hypothesis\n\n\\(H_0\\): The proportion of having heart disease are the same between the 4 chest pain types.\n\\(H_1\\): At least one chest pain pairing have different proportions of having heart disease."
  },
  {
    "objectID": "lectures/11.html#example-lrt",
    "href": "lectures/11.html#example-lrt",
    "title": "Statistical Inference",
    "section": "Example: LRT",
    "text": "Example: LRT\n\n\nCode\nxglm &lt;- glm(disease ~ cp, data = heart_disease,\n            family = binomial)\nanova(xglm)\n\n\n#&gt; Analysis of Deviance Table\n#&gt; \n#&gt; Model: binomial, link: logit\n#&gt; \n#&gt; Response: disease\n#&gt; \n#&gt; Terms added sequentially (first to last)\n#&gt; \n#&gt; \n#&gt;      Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \n#&gt; NULL                   296     409.95              \n#&gt; cp    3   81.195       293     328.75 &lt; 2.2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "lectures/11.html#post-hoc-analysis-1",
    "href": "lectures/11.html#post-hoc-analysis-1",
    "title": "Statistical Inference",
    "section": "Post-Hoc Analysis",
    "text": "Post-Hoc Analysis\n\nIf we found to reject the null hypothesis from our model inference, we conduct a post-hoc analysis to determine which groups are significantly different from each other.\nWe will conduct multiple comparisons test, while maintaining the family-wise error rate, to determine which groups are different from each other."
  },
  {
    "objectID": "lectures/11.html#group-proportions-or-means",
    "href": "lectures/11.html#group-proportions-or-means",
    "title": "Statistical Inference",
    "section": "Group Proportions Or Means",
    "text": "Group Proportions Or Means\nWe will use the emmeans function from the emmeans R package to obtain the group proportions or means."
  },
  {
    "objectID": "lectures/11.html#group-means",
    "href": "lectures/11.html#group-means",
    "title": "Statistical Inference",
    "section": "Group Means",
    "text": "Group Means\nm &lt;- lm(Y ~ X, data = DATA)\nemmeans(m, ~X)\n\nY: Outcome variable in DATA\nX: Categorical variable in DATA\nDATA: Name of the data (frame) set"
  },
  {
    "objectID": "lectures/11.html#group-proportions",
    "href": "lectures/11.html#group-proportions",
    "title": "Statistical Inference",
    "section": "Group Proportions",
    "text": "Group Proportions\nm &lt;- glm(Y ~ X, data = DATA, family = binomial)\nemmeans(m, ~X, type = \"response\")\n\nY: Outcome variable in DATA\nX: Categorical variable in DATA\nDATA: Name of the data (frame) set"
  },
  {
    "objectID": "lectures/11.html#body-mass-by-species",
    "href": "lectures/11.html#body-mass-by-species",
    "title": "Statistical Inference",
    "section": "Body Mass by Species",
    "text": "Body Mass by Species\n\n\nCode\nm1 &lt;- lm(body_mass ~ species, data = penguins)\nemmeans(m1, ~species)\n\n\n#&gt;  species   emmean   SE  df lower.CL upper.CL\n#&gt;  Adelie      3706 38.1 330     3631     3781\n#&gt;  Chinstrap   3733 55.9 330     3623     3843\n#&gt;  Gentoo      5092 42.2 330     5009     5176\n#&gt; \n#&gt; Confidence level used: 0.95"
  },
  {
    "objectID": "lectures/11.html#heart-disease-by-chest-pain",
    "href": "lectures/11.html#heart-disease-by-chest-pain",
    "title": "Statistical Inference",
    "section": "Heart Disease by Chest Pain",
    "text": "Heart Disease by Chest Pain\n\n\nCode\nm2 &lt;- glm(disease ~ cp, data = heart_disease, family = binomial)\nemmeans(m2, ~ cp, type = \"response\")\n\n\n#&gt;  cp                prob     SE  df asymp.LCL asymp.UCL\n#&gt;  Asymptomatic     0.725 0.0375 Inf    0.6463     0.792\n#&gt;  Non-anginal Pain 0.217 0.0452 Inf    0.1411     0.318\n#&gt;  Atypical Angina  0.184 0.0553 Inf    0.0984     0.317\n#&gt;  Typical Angina   0.304 0.0959 Inf    0.1525     0.515\n#&gt; \n#&gt; Confidence level used: 0.95 \n#&gt; Intervals are back-transformed from the logit scale"
  },
  {
    "objectID": "lectures/11.html#multiple-comparisons-test",
    "href": "lectures/11.html#multiple-comparisons-test",
    "title": "Statistical Inference",
    "section": "Multiple Comparisons Test",
    "text": "Multiple Comparisons Test\n\nA multi-comparison test can be achieved by using the pairs function from the output of the emmeans function.\nThis function will automatically adjust the p-values using Tukey’s method to fix the family-wise error rate."
  },
  {
    "objectID": "lectures/11.html#multi-comparison-test-means",
    "href": "lectures/11.html#multi-comparison-test-means",
    "title": "Statistical Inference",
    "section": "Multi-Comparison Test: Means",
    "text": "Multi-Comparison Test: Means\nm &lt;- lm(Y ~ X, data = DATA)\ne &lt;- emmeans(m, ~X)\npairs(e)\n\nY: Outcome variable in DATA\nX: Categorical variable in DATA\nDATA: Name of the data (frame) set"
  },
  {
    "objectID": "lectures/11.html#multi-comparison-test-proportions",
    "href": "lectures/11.html#multi-comparison-test-proportions",
    "title": "Statistical Inference",
    "section": "Multi-Comparison Test: Proportions",
    "text": "Multi-Comparison Test: Proportions\nm &lt;- glm(Y ~ X, data = DATA, family = binomial)\ne &lt;- emmeans(m, ~X, type = \"response\")\npairs(e)\n\nY: Outcome variable in DATA\nX: Categorical variable in DATA\nDATA: Name of the data (frame) set"
  },
  {
    "objectID": "lectures/11.html#body-mass-by-species-1",
    "href": "lectures/11.html#body-mass-by-species-1",
    "title": "Statistical Inference",
    "section": "Body Mass by Species",
    "text": "Body Mass by Species\n\n\nCode\nm1 &lt;- lm(body_mass ~ species, data = penguins)\ne1 &lt;- emmeans(m1, ~species)\npairs(e1)\n\n\n#&gt;  contrast           estimate   SE  df t.ratio p.value\n#&gt;  Adelie - Chinstrap    -26.9 67.7 330  -0.398  0.9164\n#&gt;  Adelie - Gentoo     -1386.3 56.9 330 -24.359 &lt;0.0001\n#&gt;  Chinstrap - Gentoo  -1359.3 70.0 330 -19.406 &lt;0.0001\n#&gt; \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates"
  },
  {
    "objectID": "lectures/11.html#heart-disease-by-chest-pain-1",
    "href": "lectures/11.html#heart-disease-by-chest-pain-1",
    "title": "Statistical Inference",
    "section": "Heart Disease by Chest Pain",
    "text": "Heart Disease by Chest Pain\n\n\nCode\nm2 &lt;- glm(disease ~ cp, data = heart_disease, family = binomial)\ne2 &lt;- emmeans(m2, ~ cp, type = \"response\")\npairs(e2)\n\n\n#&gt;  contrast                             odds.ratio    SE  df null z.ratio p.value\n#&gt;  Asymptomatic / (Non-anginal Pain)         9.537 3.110 Inf    1   6.917 &lt;0.0001\n#&gt;  Asymptomatic / Atypical Angina           11.738 4.860 Inf    1   5.948 &lt;0.0001\n#&gt;  Asymptomatic / Typical Angina             6.037 2.960 Inf    1   3.664  0.0014\n#&gt;  (Non-anginal Pain) / Atypical Angina      1.231 0.560 Inf    1   0.456  0.9684\n#&gt;  (Non-anginal Pain) / Typical Angina       0.633 0.333 Inf    1  -0.870  0.8204\n#&gt;  Atypical Angina / Typical Angina          0.514 0.301 Inf    1  -1.138  0.6660\n#&gt; \n#&gt; P value adjustment: tukey method for comparing a family of 4 estimates \n#&gt; Tests are performed on the log odds ratio scale"
  },
  {
    "objectID": "lectures/15b.html#traditional-statistics",
    "href": "lectures/15b.html#traditional-statistics",
    "title": "Installing R and Positron",
    "section": "Traditional Statistics",
    "text": "Traditional Statistics\nTraditional Statistics methods can conducted using either linear or logistic regression.\nVisit Here for more information."
  },
  {
    "objectID": "lectures/15b.html#what-is-statistics",
    "href": "lectures/15b.html#what-is-statistics",
    "title": "Installing R and Positron",
    "section": "What is Statistics?",
    "text": "What is Statistics?\nIt is the study of variation and randomness!"
  },
  {
    "objectID": "lectures/15b.html#whats-the-goal-of-statistics",
    "href": "lectures/15b.html#whats-the-goal-of-statistics",
    "title": "Installing R and Positron",
    "section": "What’s the goal of Statistics?",
    "text": "What’s the goal of Statistics?\n\nINFERENCE\n\n\nUse our sample data to understand the larger population.\n\n\nThe data will tell us how the population generally behaves.\n\n\nThe data will guide us in the differences in units.\n\n\nData will tell us if there is a signal or just noise."
  },
  {
    "objectID": "lectures/15b.html#final-thoughts",
    "href": "lectures/15b.html#final-thoughts",
    "title": "Installing R and Positron",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n\nWhen conducting a study, literature review and study design are as equally important as statistics.\n\n\nIf you don’t see variability in the data, something is wrong.\n\n\nFocus on consistency in the methodology, not consistency in data.\n\n\nUnderstand that you can be wrong, and that is okay.\n\n\nDon’t let data influence the methodology during a study/experiment."
  },
  {
    "objectID": "lectures/15b.html#statistics-mantra",
    "href": "lectures/15b.html#statistics-mantra",
    "title": "Installing R and Positron",
    "section": "Statistics Mantra",
    "text": "Statistics Mantra\n\n\n\n\n\n\n\n\nAll models are wrong,\nsome are useful!"
  },
  {
    "objectID": "lectures/15b.html#online-course-evaluation-survey",
    "href": "lectures/15b.html#online-course-evaluation-survey",
    "title": "Installing R and Positron",
    "section": "Online Course Evaluation Survey",
    "text": "Online Course Evaluation Survey\nPlease fill out the course eval survey from your email."
  },
  {
    "objectID": "lectures/15b.html#final-class-survey",
    "href": "lectures/15b.html#final-class-survey",
    "title": "Installing R and Positron",
    "section": "Final Class Survey",
    "text": "Final Class Survey\nSurvery"
  },
  {
    "objectID": "lectures/15b.html#csuci-rebranding-survey",
    "href": "lectures/15b.html#csuci-rebranding-survey",
    "title": "Installing R and Positron",
    "section": "CSUCI Rebranding Survey",
    "text": "CSUCI Rebranding Survey\nVoice Your Opinion\nCI Rebranding\nSurvey"
  },
  {
    "objectID": "lectures/15b.html#data-200",
    "href": "lectures/15b.html#data-200",
    "title": "Installing R and Positron",
    "section": "Data 200",
    "text": "Data 200\nIntroduction to Data Science\n\nDr. Catalina Medina\nMW 3-4:15 PM\nTTH: 1:30-2:45 PM"
  },
  {
    "objectID": "lectures/15b.html#data-213",
    "href": "lectures/15b.html#data-213",
    "title": "Installing R and Positron",
    "section": "Data 213",
    "text": "Data 213\nProgramming for Data Science\n\nDr. Alona Kryshchenko\nTTH 3-4:15 PM"
  },
  {
    "objectID": "lectures/15b.html#data-260",
    "href": "lectures/15b.html#data-260",
    "title": "Installing R and Positron",
    "section": "Data 260",
    "text": "Data 260\nMathematics for Data Science\n\nDr. Cynthia Flores\nMW 2-3:50 PM"
  },
  {
    "objectID": "lectures/15b.html#installing-r",
    "href": "lectures/15b.html#installing-r",
    "title": "Installing R and Positron",
    "section": "Installing R",
    "text": "Installing R\nhttps://cloud.r-project.org/"
  },
  {
    "objectID": "lectures/15b.html#installing-visual-c-redistributable-windows",
    "href": "lectures/15b.html#installing-visual-c-redistributable-windows",
    "title": "Installing R and Positron",
    "section": "Installing Visual C++ Redistributable (Windows)",
    "text": "Installing Visual C++ Redistributable (Windows)\nhttps://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-supported-redistributable-version"
  },
  {
    "objectID": "lectures/15b.html#installing-rstudio",
    "href": "lectures/15b.html#installing-rstudio",
    "title": "Installing R and Positron",
    "section": "Installing RStudio",
    "text": "Installing RStudio\nhttps://positron.posit.co/install.html"
  },
  {
    "objectID": "lectures/15b.html#positron-layout-1",
    "href": "lectures/15b.html#positron-layout-1",
    "title": "Installing R and Positron",
    "section": "Positron Layout",
    "text": "Positron Layout\n\nScripts\nConsole\nEnvironment\nFiles\nEverything else"
  },
  {
    "objectID": "lectures/15b.html#tidyverse",
    "href": "lectures/15b.html#tidyverse",
    "title": "Installing R and Positron",
    "section": "Tidyverse",
    "text": "Tidyverse\n\ninstall.packages(\"tidyverse\")"
  },
  {
    "objectID": "lectures/15b.html#csucistats",
    "href": "lectures/15b.html#csucistats",
    "title": "Installing R and Positron",
    "section": "csucistats",
    "text": "csucistats\n\ninstall.packages('csucistats', \n                 repos = c('https://inqs909.r-universe.dev', \n                           'https://cloud.r-project.org'))"
  },
  {
    "objectID": "lectures/15b.html#other-packages",
    "href": "lectures/15b.html#other-packages",
    "title": "Installing R and Positron",
    "section": "Other Packages",
    "text": "Other Packages\n\ninstall.packages(c(\"ggthemes\", \"statmod\", \"car\", \"ggtext\", \"ggpubr\", \"lmtest\", \"rms\", \"palmerpenguins\"))"
  },
  {
    "objectID": "lectures/15b.html#load-packages",
    "href": "lectures/15b.html#load-packages",
    "title": "Installing R and Positron",
    "section": "Load Packages",
    "text": "Load Packages\n\nlibrary(tidyverse)\nlibrary(csucistats)\nlibrary(ggthemes)\nlibrary(ggtext)\nlibrary(ggpubr)\nlibrary(ThemePark)\nlibrary(car)\nlibrary(lmtest)\nlibrary(rms)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "lectures/15b.html#downloading-data",
    "href": "lectures/15b.html#downloading-data",
    "title": "Installing R and Positron",
    "section": "Downloading Data",
    "text": "Downloading Data\n\nu1 &lt;- \"https://www.inqs.info/p/plotathon/owenWilsonWows.csv\"\nu2 &lt;- \"https://www.inqs.info/p/plotathon/owenWilsonWows.xlsx\"\n\ndownload.file(u1,\n              file.path(getwd(), basename(u1)))\ndownload.file(u2,\n              file.path(getwd(), basename(u2)))"
  },
  {
    "objectID": "lectures/2.html#r-packages",
    "href": "lectures/2.html#r-packages",
    "title": "Categorical Data",
    "section": "R Packages",
    "text": "R Packages\n\nrcistats\ntidyverse"
  },
  {
    "objectID": "lectures/2.html#heart-disease-data",
    "href": "lectures/2.html#heart-disease-data",
    "title": "Categorical Data",
    "section": "Heart Disease Data",
    "text": "Heart Disease Data\n\n\nThe heart_disease data set provides heart disease information on patients from Cleveland, Ohio. The data was originally published in the American Journal or Cardiology."
  },
  {
    "objectID": "lectures/2.html#data",
    "href": "lectures/2.html#data",
    "title": "Categorical Data",
    "section": "Data",
    "text": "Data\n\n\nCode\nheart_disease |&gt; \n  DT::datatable(options = list(dom = \"t\",\n                pageLength = 4))"
  },
  {
    "objectID": "lectures/2.html#variables-of-interest",
    "href": "lectures/2.html#variables-of-interest",
    "title": "Categorical Data",
    "section": "Variables of Interest",
    "text": "Variables of Interest\n\ncp: Type of Chest Pain\ndisease: Indicating if they have heart disease"
  },
  {
    "objectID": "lectures/2.html#categorical-data-1",
    "href": "lectures/2.html#categorical-data-1",
    "title": "Categorical Data",
    "section": "Categorical Data",
    "text": "Categorical Data\nCategorical data are data recordings that represented a category.\n\nData may be recorded as a “character” or “string” data.\n\n\nData may be recorded as a whole number, with an attached code book indicating the categories each number belongs to."
  },
  {
    "objectID": "lectures/2.html#examples-of-categorical-data",
    "href": "lectures/2.html#examples-of-categorical-data",
    "title": "Categorical Data",
    "section": "Examples of Categorical Data",
    "text": "Examples of Categorical Data\n\nAre you a student?\nWhat city do you live in?\nWhat is your major?"
  },
  {
    "objectID": "lectures/2.html#likert-scale",
    "href": "lectures/2.html#likert-scale",
    "title": "Categorical Data",
    "section": "Likert Scale",
    "text": "Likert Scale\nLikert scales are the rating systems you may have answered in surveys.\n\n\nStrongly Disagree\nDisagree\nNeutral\nAgree\nStrongly Agree"
  },
  {
    "objectID": "lectures/2.html#likert-scales",
    "href": "lectures/2.html#likert-scales",
    "title": "Categorical Data",
    "section": "Likert Scales",
    "text": "Likert Scales\nLikert scales may be treated as numerical data if the jumps between scales are equal."
  },
  {
    "objectID": "lectures/2.html#summarizing-categorical-data",
    "href": "lectures/2.html#summarizing-categorical-data",
    "title": "Categorical Data",
    "section": "Summarizing Categorical Data",
    "text": "Summarizing Categorical Data\nOnce we have the data, how do we summarize it to other people."
  },
  {
    "objectID": "lectures/2.html#continguency-tables-1",
    "href": "lectures/2.html#continguency-tables-1",
    "title": "Categorical Data",
    "section": "Continguency Tables",
    "text": "Continguency Tables\nContinguency tables display how often a category is seen in the data.\n\nThere are two types of statistics that are reported in a table, the frequency and proportion."
  },
  {
    "objectID": "lectures/2.html#frequencey",
    "href": "lectures/2.html#frequencey",
    "title": "Categorical Data",
    "section": "Frequencey",
    "text": "Frequencey\nFrequency represents the count of observing a specific category in your sample.\n\n\n#&gt; [1] Asymptomatic     Asymptomatic     Atypical Angina  Asymptomatic    \n#&gt; [5] Non-anginal Pain Non-anginal Pain Atypical Angina  Non-anginal Pain\n#&gt; Levels: Asymptomatic Non-anginal Pain Atypical Angina Typical Angina"
  },
  {
    "objectID": "lectures/2.html#proportions-relative-frequencey",
    "href": "lectures/2.html#proportions-relative-frequencey",
    "title": "Categorical Data",
    "section": "Proportions (relative frequencey)",
    "text": "Proportions (relative frequencey)\nProportions represent the percentage that the category represents the sample.\n\nThis allows you to generalize your sample to the population, regardless of sample size."
  },
  {
    "objectID": "lectures/2.html#continguency-tables-in-r",
    "href": "lectures/2.html#continguency-tables-in-r",
    "title": "Categorical Data",
    "section": "Continguency Tables in R",
    "text": "Continguency Tables in R\ncat_stats(DATA$VAR)\n\nDATA: Name of the data frame (eg: heart_disease)\nVAR: Name of the variable to create a plot (eg: cp)"
  },
  {
    "objectID": "lectures/2.html#example",
    "href": "lectures/2.html#example",
    "title": "Categorical Data",
    "section": "Example",
    "text": "Example\nThe variable cp indicates the type of chest pain.\n\ncat_stats(heart_disease$cp)\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;                    n   prop\n#&gt; Asymptomatic     142 0.4781\n#&gt; Atypical Angina   49 0.1650\n#&gt; Non-anginal Pain  83 0.2795\n#&gt; Typical Angina    23 0.0774\n#&gt; \n#&gt; Number of Missing: 0\n#&gt; Proportion of Missing: 0\n#&gt; Row Variable: heart_disease$cp"
  },
  {
    "objectID": "lectures/2.html#plotting-in-r",
    "href": "lectures/2.html#plotting-in-r",
    "title": "Categorical Data",
    "section": "Plotting in R",
    "text": "Plotting in R\nPlotting in R can be done via the ggplot2, a powerful library based on the Grammar of Graphics."
  },
  {
    "objectID": "lectures/2.html#plotting-in-r-1",
    "href": "lectures/2.html#plotting-in-r-1",
    "title": "Categorical Data",
    "section": "Plotting in R",
    "text": "Plotting in R\n\nYou need to create a base plot using the ggplot()\nUse the + to change the look of the base plot\nIndicate how to transform the base plot to the desired plot\ngeom_*\nstat_*\nChange the look of the plot with other functions\nUse a theme_* function to add a theme to the plot"
  },
  {
    "objectID": "lectures/2.html#bar-plots-1",
    "href": "lectures/2.html#bar-plots-1",
    "title": "Categorical Data",
    "section": "Bar Plots",
    "text": "Bar Plots\nBar Plots can be used to display the frequency or proportions on the data."
  },
  {
    "objectID": "lectures/2.html#frequency-bar-plots-in-r",
    "href": "lectures/2.html#frequency-bar-plots-in-r",
    "title": "Categorical Data",
    "section": "Frequency Bar Plots in R",
    "text": "Frequency Bar Plots in R\nggplot(data = DATA, aes(x = VAR)) +\n  geom_bar()\n\nDATA: Name of the data frame (eg: heart_disease)\nVAR: Name of the variable to create a plot (eg: cp)"
  },
  {
    "objectID": "lectures/2.html#frequency-bar-plots-in-r-1",
    "href": "lectures/2.html#frequency-bar-plots-in-r-1",
    "title": "Categorical Data",
    "section": "Frequency Bar Plots in R",
    "text": "Frequency Bar Plots in R\n\n\nCode\nggplot(heart_disease, aes(cp)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle=-20,hjust=0)) # Used to angle x-axis"
  },
  {
    "objectID": "lectures/2.html#relative-frequency-bar-plots-in-r",
    "href": "lectures/2.html#relative-frequency-bar-plots-in-r",
    "title": "Categorical Data",
    "section": "Relative Frequency Bar Plots in R",
    "text": "Relative Frequency Bar Plots in R\nggplot(data = DATA, aes(x = VAR, y = after_stat(prop), group = 1)) +\n  geom_bar()\n\nDATA: Name of the data frame (eg: heart_disease)\nVAR: Name of the variable to create a plot (eg: cp)"
  },
  {
    "objectID": "lectures/2.html#relative-frequency-bar-plots-in-r-1",
    "href": "lectures/2.html#relative-frequency-bar-plots-in-r-1",
    "title": "Categorical Data",
    "section": "Relative Frequency Bar Plots in R",
    "text": "Relative Frequency Bar Plots in R\n\n\nCode\nggplot(heart_disease, aes(cp, after_stat(prop), group = 1)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle=-20,hjust=0)) # Used to angle x-axis"
  },
  {
    "objectID": "lectures/2.html#data-1",
    "href": "lectures/2.html#data-1",
    "title": "Categorical Data",
    "section": "Data",
    "text": "Data\nThe variable disease indicates if a patient has heart disease.\n\ncat_stats(heart_disease$disease)\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;       n   prop\n#&gt; no  160 0.5387\n#&gt; yes 137 0.4613\n#&gt; \n#&gt; Number of Missing: 0\n#&gt; Proportion of Missing: 0\n#&gt; Row Variable: heart_disease$disease"
  },
  {
    "objectID": "lectures/2.html#cross-tabulation-1",
    "href": "lectures/2.html#cross-tabulation-1",
    "title": "Categorical Data",
    "section": "Cross-Tabulation",
    "text": "Cross-Tabulation\nCross-tabulations, also known as contingency tables, are statistical tools used to analyze the relationship between two or more categorical variables by displaying their frequency distribution in a table format. Each cell in the table represents the count or frequency of observations that fall into a particular combination of categories for the variables."
  },
  {
    "objectID": "lectures/2.html#key-features-of-cross-tabulations",
    "href": "lectures/2.html#key-features-of-cross-tabulations",
    "title": "Categorical Data",
    "section": "Key Features of Cross-Tabulations",
    "text": "Key Features of Cross-Tabulations\n\nRows and Columns:\n\nRows represent the categories of one variable.\nColumns represent the categories of another variable.\n\nCells:\n\nEach cell displays the frequency or count of data points that belong to the intersection of a row and column category."
  },
  {
    "objectID": "lectures/2.html#cross-tabulations-in-r",
    "href": "lectures/2.html#cross-tabulations-in-r",
    "title": "Categorical Data",
    "section": "Cross-Tabulations in R",
    "text": "Cross-Tabulations in R\ncat_stats(DATA$VAR1, DATA$VAR2)\n\nDATA: Name of the data frame (eg: heart_disease)\nVAR1: Name of the first variable to create the cross-tab (eg: cp)\nVAR2: Name of the second variable to create the cross-tab (eg: disease)"
  },
  {
    "objectID": "lectures/2.html#cross-tabs-example",
    "href": "lectures/2.html#cross-tabs-example",
    "title": "Categorical Data",
    "section": "Cross-Tabs Example",
    "text": "Cross-Tabs Example\n\ncat_stats(heart_disease$cp, heart_disease$disease)\n\n#&gt; Continguency Table \n#&gt;  \n#&gt; Column Variable: heart_disease$disease\n#&gt; Row Variable: heart_disease$cp\n\n\n#&gt; $frequency\n#&gt;                   \n#&gt;                     no yes\n#&gt;   Asymptomatic      39 103\n#&gt;   Non-anginal Pain  65  18\n#&gt;   Atypical Angina   40   9\n#&gt;   Typical Angina    16   7\n#&gt; \n#&gt; $table_prop\n#&gt;                   \n#&gt;                        no    yes\n#&gt;   Asymptomatic     0.1313 0.3468\n#&gt;   Non-anginal Pain 0.2189 0.0606\n#&gt;   Atypical Angina  0.1347 0.0303\n#&gt;   Typical Angina   0.0539 0.0236\n#&gt; \n#&gt; $row_prop\n#&gt;                   \n#&gt;                        no    yes\n#&gt;   Asymptomatic     0.2746 0.7254\n#&gt;   Non-anginal Pain 0.7831 0.2169\n#&gt;   Atypical Angina  0.8163 0.1837\n#&gt;   Typical Angina   0.6957 0.3043\n#&gt; \n#&gt; $col_prop\n#&gt;                   \n#&gt;                        no    yes\n#&gt;   Asymptomatic     0.2438 0.7518\n#&gt;   Non-anginal Pain 0.4062 0.1314\n#&gt;   Atypical Angina  0.2500 0.0657\n#&gt;   Typical Angina   0.1000 0.0511"
  },
  {
    "objectID": "lectures/2.html#types-of-props-in-cross-tabs",
    "href": "lectures/2.html#types-of-props-in-cross-tabs",
    "title": "Categorical Data",
    "section": "Types of Props in Cross-Tabs",
    "text": "Types of Props in Cross-Tabs\n\nRow Proportions: Show the percentage of each row total represented by a cell.\nColumn Proportions: Show the percentage of each column total represented by a cell.\nTable Proportions: Show the percentage of the overall total represented by a cell."
  },
  {
    "objectID": "lectures/2.html#table-proportions",
    "href": "lectures/2.html#table-proportions",
    "title": "Categorical Data",
    "section": "Table Proportions",
    "text": "Table Proportions\nTable proportions in cross-tabulations refer to the relative frequency or percentage of counts within the entire table, calculated by dividing each cell’s count by the total sum of all counts in the table. These proportions allow you to examine the contribution of each cell to the overall data set."
  },
  {
    "objectID": "lectures/2.html#table-proportions-1",
    "href": "lectures/2.html#table-proportions-1",
    "title": "Categorical Data",
    "section": "Table Proportions",
    "text": "Table Proportions\n\ncat_stats(heart_disease$cp, heart_disease$disease, prop = \"table\")\n\n#&gt; Continguency Table \n#&gt;  \n#&gt; Column Variable: heart_disease$disease\n#&gt; Row Variable: heart_disease$cp\n\n\n#&gt; $frequency\n#&gt;                   \n#&gt;                     no yes\n#&gt;   Asymptomatic      39 103\n#&gt;   Non-anginal Pain  65  18\n#&gt;   Atypical Angina   40   9\n#&gt;   Typical Angina    16   7\n#&gt; \n#&gt; $table_prop\n#&gt;                   \n#&gt;                        no    yes\n#&gt;   Asymptomatic     0.1313 0.3468\n#&gt;   Non-anginal Pain 0.2189 0.0606\n#&gt;   Atypical Angina  0.1347 0.0303\n#&gt;   Typical Angina   0.0539 0.0236"
  },
  {
    "objectID": "lectures/2.html#row-proportions",
    "href": "lectures/2.html#row-proportions",
    "title": "Categorical Data",
    "section": "Row Proportions",
    "text": "Row Proportions\nRow proportions refer to the relative frequency or percentage of counts within each row of a contingency table. In a cross-tabulation, row proportions allow you to compare how the distribution of one variable varies within each category of another variable, within a row."
  },
  {
    "objectID": "lectures/2.html#row-proportions-1",
    "href": "lectures/2.html#row-proportions-1",
    "title": "Categorical Data",
    "section": "Row Proportions",
    "text": "Row Proportions\n\ncat_stats(heart_disease$cp, heart_disease$disease, prop = \"row\")\n\n#&gt; Continguency Table \n#&gt;  \n#&gt; Column Variable: heart_disease$disease\n#&gt; Row Variable: heart_disease$cp\n\n\n#&gt; $frequency\n#&gt;                   \n#&gt;                     no yes\n#&gt;   Asymptomatic      39 103\n#&gt;   Non-anginal Pain  65  18\n#&gt;   Atypical Angina   40   9\n#&gt;   Typical Angina    16   7\n#&gt; \n#&gt; $row_prop\n#&gt;                   \n#&gt;                        no    yes\n#&gt;   Asymptomatic     0.2746 0.7254\n#&gt;   Non-anginal Pain 0.7831 0.2169\n#&gt;   Atypical Angina  0.8163 0.1837\n#&gt;   Typical Angina   0.6957 0.3043"
  },
  {
    "objectID": "lectures/2.html#column-proportions",
    "href": "lectures/2.html#column-proportions",
    "title": "Categorical Data",
    "section": "Column Proportions",
    "text": "Column Proportions\nColumn proportions refer to the relative frequency or percentage of counts within each column of a contingency table. These proportions allow you to compare how the distribution of one variable varies across different categories of another variable, within a column."
  },
  {
    "objectID": "lectures/2.html#column-proportions-1",
    "href": "lectures/2.html#column-proportions-1",
    "title": "Categorical Data",
    "section": "Column Proportions",
    "text": "Column Proportions\n\ncat_stats(heart_disease$cp, heart_disease$disease, prop = \"col\")\n\n#&gt; Continguency Table \n#&gt;  \n#&gt; Column Variable: heart_disease$disease\n#&gt; Row Variable: heart_disease$cp\n\n\n#&gt; $frequency\n#&gt;                   \n#&gt;                     no yes\n#&gt;   Asymptomatic      39 103\n#&gt;   Non-anginal Pain  65  18\n#&gt;   Atypical Angina   40   9\n#&gt;   Typical Angina    16   7\n#&gt; \n#&gt; $col_prop\n#&gt;                   \n#&gt;                        no    yes\n#&gt;   Asymptomatic     0.2438 0.7518\n#&gt;   Non-anginal Pain 0.4062 0.1314\n#&gt;   Atypical Angina  0.2500 0.0657\n#&gt;   Typical Angina   0.1000 0.0511"
  },
  {
    "objectID": "lectures/2.html#stacked-bar-plot-in-r",
    "href": "lectures/2.html#stacked-bar-plot-in-r",
    "title": "Categorical Data",
    "section": "Stacked Bar Plot in R",
    "text": "Stacked Bar Plot in R\nggplot(DATA, aes(x = VAR1, y = after_stat(count), fill = VAR2)) +\n  geom_bar()\nOR\nggplot(DATA, aes(y = VAR1, x = after_stat(count), fill = VAR2)) +\n  geom_bar()\n\nDATA: Name of the data frame (eg: heart_disease)\nVAR1: Name of the first variable to create the cross-tab (eg: cp)\nVAR2: Name of the second variable to create the cross-tab (eg: disease)"
  },
  {
    "objectID": "lectures/2.html#stacked-bar-plot-in-r-1",
    "href": "lectures/2.html#stacked-bar-plot-in-r-1",
    "title": "Categorical Data",
    "section": "Stacked Bar Plot in R",
    "text": "Stacked Bar Plot in R\n\nggplot(heart_disease, aes(x = cp, y = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle=-20,hjust=0)) # Used to angle x-axis"
  },
  {
    "objectID": "lectures/2.html#stacked-bar-plot-in-r-2",
    "href": "lectures/2.html#stacked-bar-plot-in-r-2",
    "title": "Categorical Data",
    "section": "Stacked Bar Plot in R",
    "text": "Stacked Bar Plot in R\n\nggplot(heart_disease, aes(y = cp, x = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme(axis.text.y = element_text(size = 20)) # Used to increase y-axis font"
  },
  {
    "objectID": "lectures/2.html#pie-charts-1",
    "href": "lectures/2.html#pie-charts-1",
    "title": "Categorical Data",
    "section": "Pie Charts",
    "text": "Pie Charts\nA pie chart is a circular statistical graphic divided into slices, where each slice represents a proportion or percentage of the whole. The size of each slice is proportional to the relative frequency or magnitude of the category it represents."
  },
  {
    "objectID": "lectures/2.html#pie-charts-2",
    "href": "lectures/2.html#pie-charts-2",
    "title": "Categorical Data",
    "section": "Pie Charts",
    "text": "Pie Charts"
  },
  {
    "objectID": "lectures/2.html#key-features-of-pie-charts",
    "href": "lectures/2.html#key-features-of-pie-charts",
    "title": "Categorical Data",
    "section": "Key Features of Pie Charts",
    "text": "Key Features of Pie Charts\n\nCircular Format:\n\nThe chart is shaped like a circle, symbolizing a whole (100% or 1).\n\nSlices:\n\nEach slice corresponds to a category and its size represents the contribution of that category to the total.\n\nLabels:\n\nSlices are often labeled with the category name and the percentage or value they represent."
  },
  {
    "objectID": "lectures/2.html#pie-chart-in-r",
    "href": "lectures/2.html#pie-chart-in-r",
    "title": "Categorical Data",
    "section": "Pie Chart in R",
    "text": "Pie Chart in R\nggplot(DATA, aes(fill = VAR)) +\n  geom_pie()\n\nDATA: Name of the data frame (eg: heart_disease)\nVAR: Name of the variable to create a plot (eg: cp)"
  },
  {
    "objectID": "lectures/2.html#pie-chart-in-r-1",
    "href": "lectures/2.html#pie-chart-in-r-1",
    "title": "Categorical Data",
    "section": "Pie Chart in R",
    "text": "Pie Chart in R\n\nggplot(heart_disease, aes(fill = slope)) +\n  geom_pie() +\n  theme( # Used to change legend\n    legend.title = element_text(size = 36), # Increse title font\n    legend.text = element_text(size = 30) # Increase text font\n  )"
  },
  {
    "objectID": "lectures/2.html#themes",
    "href": "lectures/2.html#themes",
    "title": "Categorical Data",
    "section": "Themes",
    "text": "Themes\nThe R packages ThemePark and ggthemes allows you to change the overall look of a plot.\n\nAll you need to do is add the theme to the plot."
  },
  {
    "objectID": "lectures/2.html#installing-themes-in-r",
    "href": "lectures/2.html#installing-themes-in-r",
    "title": "Categorical Data",
    "section": "Installing Themes in R",
    "text": "Installing Themes in R\nInstall once on your computer or new session in google colab:\nrcistats::install_themes()\nThen, load libraries:\nlibrary(ggthemes)\nlibrary(ThemePark)"
  },
  {
    "objectID": "lectures/2.html#black-and-white-theme",
    "href": "lectures/2.html#black-and-white-theme",
    "title": "Categorical Data",
    "section": "Black and White Theme",
    "text": "Black and White Theme\n\nggplot(heart_disease, aes(y = cp, x = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme_bw()"
  },
  {
    "objectID": "lectures/2.html#excel-theme",
    "href": "lectures/2.html#excel-theme",
    "title": "Categorical Data",
    "section": "Excel Theme",
    "text": "Excel Theme\n\nggplot(heart_disease, aes(y = cp, x = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme_excel()"
  },
  {
    "objectID": "lectures/2.html#wsj-theme",
    "href": "lectures/2.html#wsj-theme",
    "title": "Categorical Data",
    "section": "WSJ Theme",
    "text": "WSJ Theme\n\nggplot(heart_disease, aes(y = cp, x = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme_wsj()"
  },
  {
    "objectID": "lectures/2.html#stata-theme",
    "href": "lectures/2.html#stata-theme",
    "title": "Categorical Data",
    "section": "Stata Theme",
    "text": "Stata Theme\n\nggplot(heart_disease, aes(y = cp, x = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme_stata()"
  },
  {
    "objectID": "lectures/2.html#barbie-theme",
    "href": "lectures/2.html#barbie-theme",
    "title": "Categorical Data",
    "section": "Barbie Theme",
    "text": "Barbie Theme\n\nggplot(heart_disease, aes(y = cp, x = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme_barbie()"
  },
  {
    "objectID": "lectures/2.html#oppenheimer-theme",
    "href": "lectures/2.html#oppenheimer-theme",
    "title": "Categorical Data",
    "section": "Oppenheimer Theme",
    "text": "Oppenheimer Theme\n\nggplot(heart_disease, aes(y = cp, x = after_stat(count), fill = disease)) +\n  geom_bar() +\n  theme_oppenheimer()"
  },
  {
    "objectID": "lectures/4.html#what-is-probability",
    "href": "lectures/4.html#what-is-probability",
    "title": "Distribution Functions",
    "section": "What is Probability?",
    "text": "What is Probability?\nProbability is the measure of how likely an event is to occur. It ranges from 0 to 1:\n\n\\(P(A) = 0\\): The event \\(A\\) will definitely not happen.\n\\(P(A) = 1\\): The event \\(A\\) will definitely happen.\nValues between 0 and 1 represent varying degrees of likelihood."
  },
  {
    "objectID": "lectures/4.html#everyday-examples",
    "href": "lectures/4.html#everyday-examples",
    "title": "Distribution Functions",
    "section": "Everyday Examples",
    "text": "Everyday Examples\n\nWhat’s the probability it will rain tomorrow?\nWhat are the chances of rolling a 6 on a standard die?\nHow likely is it that a randomly chosen student has a GPA above 3.0?"
  },
  {
    "objectID": "lectures/4.html#key-terms-and-definitions",
    "href": "lectures/4.html#key-terms-and-definitions",
    "title": "Distribution Functions",
    "section": "Key Terms and Definitions",
    "text": "Key Terms and Definitions\n\nExperimentSample SpaceEventProb. of an Event\n\n\nAn action or process that generates outcomes.\n- Example: Rolling a die.\n\n\nThe set of all possible outcomes of an experiment.\n- Example: For rolling a die, \\(S = \\{1, 2, 3, 4, 5, 6\\}\\).\n\n\nA subset of the sample space, representing outcomes of interest.\n\nExample: Rolling an even number (\\(A = \\{2, 4, 6\\}\\)).\n\n\n\nThe proportion of times an event is expected to occur if the experiment is repeated many times."
  },
  {
    "objectID": "lectures/4.html#the-probability-formula",
    "href": "lectures/4.html#the-probability-formula",
    "title": "Distribution Functions",
    "section": "The Probability Formula",
    "text": "The Probability Formula\nThe probability of an event \\(A\\) is defined as:\n\\[\nP(A) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of possible outcomes}}\n\\]"
  },
  {
    "objectID": "lectures/4.html#example",
    "href": "lectures/4.html#example",
    "title": "Distribution Functions",
    "section": "Example",
    "text": "Example\nIf we roll a die, what is the probability of rolling a 4?\n\nFavorable outcomes: 1 (rolling a 4).\nTotal outcomes: 6 (since \\(S = \\{1, 2, 3, 4, 5, 6\\}\\)).\n\n\\[\nP(\\text{rolling a 4}) = \\frac{1}{6} \\approx 0.167\n\\]"
  },
  {
    "objectID": "lectures/4.html#rules-of-probability",
    "href": "lectures/4.html#rules-of-probability",
    "title": "Distribution Functions",
    "section": "Rules of Probability",
    "text": "Rules of Probability\n\nRule 1Rule 2Rule 3\n\n\nProbability of the Sample Space\nThe probability of the sample space is always 1: \\[\nP(S) = 1\n\\]\n\n\nProbability of Impossible Events\nThe probability of an event that cannot happen is 0:\n\\[\nP(\\emptyset) = 0\n\\]\n\n\nComplement Rule\nThe probability of the complement of an event \\(A\\) (not \\(A\\)) is:\n\\[\nP(A^c) = 1 - P(A)\n\\]\n\nExample: If \\(P(\\text{rain}) = 0.3\\), then \\(P(\\text{no rain}) = 1 - 0.3 = 0.7\\)."
  },
  {
    "objectID": "lectures/4.html#applications",
    "href": "lectures/4.html#applications",
    "title": "Distribution Functions",
    "section": "Applications",
    "text": "Applications\n\nDrawing a CardTossing a Coin TwiceTraffic Lights\n\n\nIf you draw a card from a standard deck of 52 cards, what is the probability of drawing:\n\nA heart?\n\\[\nP(\\text{heart}) = \\frac{13}{52} = 0.25\n\\]\nA red card (heart or diamond)?\n\\[\nP(\\text{red card}) = \\frac{26}{52} = 0.5\n\\]\n\n\n\nWhat is the probability of getting:\n\nExactly one head?\nSample space: \\(S = \\{\\text{HH, HT, TH, TT}\\}\\).\nEvent: \\(A = \\{\\text{HT, TH}\\}\\).\n\\[\nP(A) = \\frac{2}{4} = 0.5\n\\]\nAt least one head?\nEvent: \\(B = \\{\\text{HH, HT, TH}\\}\\).\n\\[\nP(B) = \\frac{3}{4} = 0.75\n\\]\n\n\n\nA commuter encounters three traffic lights, each with a 70% chance of being green. Assuming independence, what is the probability that all three lights are green?\n\\[\nP(\\text{all green}) = 0.7 \\cdot 0.7 \\cdot 0.7 = 0.343\n\\]"
  },
  {
    "objectID": "lectures/4.html#more-problems",
    "href": "lectures/4.html#more-problems",
    "title": "Distribution Functions",
    "section": "More Problems",
    "text": "More Problems\n\nRolling a Die1234\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\n\n\n\n\n\n\\[\nP(X = 2)\n\\]\n\n\n\\[\nP(1 \\le X \\le 3)\n\\]\n\n\n\\[\nP(1 &lt; X &lt; 3)\n\\]\n\n\n\\[\nP(X &gt; 1)\n\\]"
  },
  {
    "objectID": "lectures/4.html#joint-probability-1",
    "href": "lectures/4.html#joint-probability-1",
    "title": "Distribution Functions",
    "section": "Joint Probability",
    "text": "Joint Probability\n\nOften, we’re interested in the probabilities of multiple events occurring.\nThis presentation focuses on calculating probabilities involving two events.\nWe’ll explore key concepts like:\n\nJoint Probability\nUnion of Events\nConditional Probability\nIndependence"
  },
  {
    "objectID": "lectures/4.html#joint-probability-2",
    "href": "lectures/4.html#joint-probability-2",
    "title": "Distribution Functions",
    "section": "Joint Probability",
    "text": "Joint Probability\n\nThe probability of both events A and B occurring.\nDenoted as \\(P(A\\ \\mathrm{and}\\ B)\\) or \\(P(A \\cap B)\\).\nExamples:\n\nDrawing a King and a Heart from a deck of cards.\nFlipping two coins and getting heads on both."
  },
  {
    "objectID": "lectures/4.html#union-of-events",
    "href": "lectures/4.html#union-of-events",
    "title": "Distribution Functions",
    "section": "Union of Events",
    "text": "Union of Events\n\nThe probability of either event A or event B (or both) occurring.\nDenoted as \\(P(A\\ \\mathrm{or}\\ B)\\) or \\(P(A \\cup B)\\).\nExamples:\n\nRolling a 3 or a 5 on a die.\nDrawing a red card or a face card."
  },
  {
    "objectID": "lectures/4.html#calculating-union-probability",
    "href": "lectures/4.html#calculating-union-probability",
    "title": "Distribution Functions",
    "section": "Calculating Union Probability",
    "text": "Calculating Union Probability\n\nGeneral Case: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) (Inclusion-Exclusion Principle)\nMutually Exclusive Events: If A and B are mutually exclusive (cannot both occur), then \\(P(A \\cap B) = 0\\), and \\(P(A \\cup B) = P(A) + P(B)\\)"
  },
  {
    "objectID": "lectures/4.html#example-union-probability",
    "href": "lectures/4.html#example-union-probability",
    "title": "Distribution Functions",
    "section": "Example: Union Probability",
    "text": "Example: Union Probability\n\nWhat is the probability of rolling a number greater than 4 or an even number on a six-sided die?\n\nEvent A: Rolling a number greater than 4 (5 or 6).\nEvent B: Rolling an even number (2, 4, or 6).\n\n\n\n\n\\(P(A) = 2/6\\)\n\\(P(B) = 3/6\\)\n\\(P(A \\cap B) = 1/6\\) (rolling a 6)\n\\(P(A \\cup B) = (2/6) + (3/6) - (1/6) = 4/6 = 2/3\\)"
  },
  {
    "objectID": "lectures/4.html#conditional-probability",
    "href": "lectures/4.html#conditional-probability",
    "title": "Distribution Functions",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nThe conditional probability of event A occurring given that event B has occurred: \\(P(A|B)\\) (read as “the probability of A given B”).\nFormula: \\(P(A|B) =\\frac{P(A \\cap B)}{P(B)}\\)\n\n\\(P(A|B)\\): Conditional probability of A given B.\n\\(P(A \\cap B)\\): Probability of both A and B occurring.\n\\(P(B)\\): Probability of B occurring."
  },
  {
    "objectID": "lectures/4.html#independence",
    "href": "lectures/4.html#independence",
    "title": "Distribution Functions",
    "section": "Independence",
    "text": "Independence\n\nTwo events are independent if the occurrence of one does not affect the probability of the other.\nIf A and B are independent:\n\n\\(P(A|B) = P(A)\\)\n\\(P(B|A) = P(B)\\)\n\\(P(A \\cap B) = P(A) P(B)\\)"
  },
  {
    "objectID": "lectures/4.html#bayes-theorem",
    "href": "lectures/4.html#bayes-theorem",
    "title": "Distribution Functions",
    "section": "Bayes’ Theorem",
    "text": "Bayes’ Theorem\n\nReverses the conditioning: Relates P(A|B) to P(B|A).\n\\(P(A|B) = \\frac{P(B|A) * P(A)}{P(B)}\\)\nUseful when we know P(B|A) but want P(A|B)."
  },
  {
    "objectID": "lectures/4.html#random-variable",
    "href": "lectures/4.html#random-variable",
    "title": "Distribution Functions",
    "section": "Random Variable",
    "text": "Random Variable\nA random variable is a variable whose value is a numerical outcome of a random phenomenon. It’s a way to map the outcomes of a probabilistic event to numbers. This allows us to analyze these outcomes mathematically."
  },
  {
    "objectID": "lectures/4.html#rv-key-concepts",
    "href": "lectures/4.html#rv-key-concepts",
    "title": "Distribution Functions",
    "section": "RV: Key Concepts",
    "text": "RV: Key Concepts\n\nRandom Phenomenon: This is any process or experiment whose outcome is uncertain.\nOutcomes: The possible results of a random phenomenon are called outcomes.\nNumerical Value: A random variable assigns a numerical value to each outcome."
  },
  {
    "objectID": "lectures/4.html#types-of-random-variables",
    "href": "lectures/4.html#types-of-random-variables",
    "title": "Distribution Functions",
    "section": "Types of Random Variables",
    "text": "Types of Random Variables\n\nDiscrete Random VariableContinuous Random Variable\n\n\nA discrete random variable can only take on a finite number of values or a countably infinite number of values. The values are often integers. Examples:\n\nThe number of heads in three coin flips (0, 1, 2, or 3).\nThe number of defective light bulbs in a box of 100.\nThe number of customers entering a store in an hour.\n\n\n\nA continuous random variable can take on any value within a given range. Examples:\n\nThe height of a person.\nThe temperature of a room.\nThe time it takes to complete a task."
  },
  {
    "objectID": "lectures/4.html#distribution-functions-1",
    "href": "lectures/4.html#distribution-functions-1",
    "title": "Distribution Functions",
    "section": "Distribution Functions",
    "text": "Distribution Functions\nA distribution function describes the probabilities of a random variable across its possible values. It answers questions like:\n\nHow likely is a random variable to take on a specific value or fall within a range?\nWhat is the overall “shape” of the distribution of outcomes?"
  },
  {
    "objectID": "lectures/4.html#cumulative-distribution-function",
    "href": "lectures/4.html#cumulative-distribution-function",
    "title": "Distribution Functions",
    "section": "Cumulative Distribution Function",
    "text": "Cumulative Distribution Function\nThe Cumulative Distribution Function (CDF) describes the probability that a random variable \\(X\\) is less than or equal to a certain value \\(x\\):\n\\[\nF_X(x) = P(X \\leq x)\n\\]"
  },
  {
    "objectID": "lectures/4.html#properties-of-the-cdf",
    "href": "lectures/4.html#properties-of-the-cdf",
    "title": "Distribution Functions",
    "section": "Properties of the CDF",
    "text": "Properties of the CDF\n\nRange: The CDF is always between 0 and 1: \\[\n0 \\leq F_X(x) \\leq 1\n\\]\nNon-Decreasing: The CDF never decreases as \\(x\\) increases.\nAsymptotic Limits:\n\n\\(\\lim_{x \\to -\\infty} F_X(x) = 0\\)\n\\(\\lim_{x \\to \\infty} F_X(x) = 1\\)"
  },
  {
    "objectID": "lectures/4.html#cdf-example",
    "href": "lectures/4.html#cdf-example",
    "title": "Distribution Functions",
    "section": "CDF Example",
    "text": "CDF Example\nFor a die roll (discrete case):\n\n\\(F_X(2) = P(X \\leq 2) = P(X = 1) + P(X = 2) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6}\\).\n\nFor a normal distribution (continuous case):\n\nUse the CDF to find probabilities, typically provided via tables or software."
  },
  {
    "objectID": "lectures/4.html#probability-density-function-pdf",
    "href": "lectures/4.html#probability-density-function-pdf",
    "title": "Distribution Functions",
    "section": "Probability Density Function (PDF)",
    "text": "Probability Density Function (PDF)\nThe Probability Density Function (PDF) is used for continuous random variables and describes the likelihood of the variable falling within a small interval.\n\\[\nP(a \\leq X \\leq b) = \\int_a^b f_X(x) \\, dx\n\\]\n\n\n\n\n\n\n\nImportant\n\n\n\\[\nP(X = a) = P(a \\leq X \\leq a) = \\int_a^a f_X(x) \\, dx = 0\n\\]"
  },
  {
    "objectID": "lectures/4.html#normal-pdf",
    "href": "lectures/4.html#normal-pdf",
    "title": "Distribution Functions",
    "section": "Normal PDF",
    "text": "Normal PDF\nThe PDF of the normal distribution is: \\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\]\nHere, \\(\\mu\\) is the mean and \\(\\sigma\\) is the standard deviation."
  },
  {
    "objectID": "lectures/4.html#probability-mass-function-pmf",
    "href": "lectures/4.html#probability-mass-function-pmf",
    "title": "Distribution Functions",
    "section": "Probability Mass Function (PMF)",
    "text": "Probability Mass Function (PMF)\nThe Probability Mass Function (PMF) is used for discrete random variables and gives the probability of each possible value: \\[\nP(X = x) = p_X(x)\n\\]"
  },
  {
    "objectID": "lectures/4.html#properties-of-the-pmf",
    "href": "lectures/4.html#properties-of-the-pmf",
    "title": "Distribution Functions",
    "section": "Properties of the PMF",
    "text": "Properties of the PMF\n\nNon-Negative: \\[\np_X(x) \\geq 0 \\quad \\forall x\n\\]\nSum of Probabilities: \\[\n\\sum_x p_X(x) = 1\n\\]"
  },
  {
    "objectID": "lectures/4.html#pmf-example",
    "href": "lectures/4.html#pmf-example",
    "title": "Distribution Functions",
    "section": "PMF Example",
    "text": "PMF Example\nFor a fair die, the PMF is: \\[\np_X(x) = \\frac{1}{6}, \\quad x \\in \\{1, 2, 3, 4, 5, 6\\}\n\\]"
  },
  {
    "objectID": "lectures/4.html#percentiles",
    "href": "lectures/4.html#percentiles",
    "title": "Distribution Functions",
    "section": "Percentiles",
    "text": "Percentiles\nA percentile is a measure indicating the value below which a given percentage of observations in a group of observations falls. It is used in statistics to provide information about the relative standing of a particular value within a dataset."
  },
  {
    "objectID": "lectures/4.html#percentile-example",
    "href": "lectures/4.html#percentile-example",
    "title": "Distribution Functions",
    "section": "Percentile Example",
    "text": "Percentile Example\nSuppose we have a random variable X representing the height of adults in a population. If the 90th percentile of X is 180 cm, it means that the probability of a randomly selected adult being 180 cm or shorter is 90%."
  },
  {
    "objectID": "lectures/4.html#percentile",
    "href": "lectures/4.html#percentile",
    "title": "Distribution Functions",
    "section": "Percentile",
    "text": "Percentile\n\n\nCode\ndata &lt;- rnorm(500000, mean = 100, sd = 15) |&gt; data.frame(x = _)  # Example: normally distributed data\n\n# Calculate the 75th percentile\npercentile_75 &lt;- qnorm(0.75, 100, 15)\n\nggplot(data = data, aes(x = x)) +\n  geom_density(fill = \"plum\", alpha = 0.5) +  # Density curve\n  geom_vline(xintercept = percentile_75, color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Density Plot with 75th Percentile\", x = \"Data Value\", y = \"Density\")"
  },
  {
    "objectID": "lectures/4.html#applications-1",
    "href": "lectures/4.html#applications-1",
    "title": "Distribution Functions",
    "section": "Applications",
    "text": "Applications\n\nPMF of a Coin TossCDF of an Exp. Dist.Apps. in Real Life\n\n\nFor a fair coin tossed once:\n\n\\(X = 0\\): Tails, \\(P(X = 0) = 0.5\\)\n\\(X = 1\\): Heads, \\(P(X = 1) = 0.5\\)\n\nThe PMF is: \\[\np_X(x) =\n\\begin{cases}\n0.5 & x = 0 \\text{ or } x = 1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\n\nAn exponential random variable with rate \\(\\lambda &gt; 0\\) has a CDF: \\[\nF_X(x) =\n\\begin{cases}\n1 - e^{-\\lambda x}, & x \\geq 0 \\\\\n0, & x &lt; 0\n\\end{cases}\n\\]\nThis can be used to model waiting times between events.\n\n\n\nPMF:\n\nNumber of emails received per hour.\n\nPDF:\n\nHeights of students in a class.\n\nCDF:\n\nThe likelihood of completing a task within a certain time frame."
  },
  {
    "objectID": "lectures/4.html#common-contisuous-rv",
    "href": "lectures/4.html#common-contisuous-rv",
    "title": "Distribution Functions",
    "section": "Common Contisuous RV",
    "text": "Common Contisuous RV\n\n\n\n\n\n\n\n\n\nContinuous RV\nParameters\nNotation\nSupport\n\n\n\n\nUniform\na (minimum), b (maximum)\nUnif(a, b)\n[a, b]\n\n\nNormal (Gaussian)\nμ (mean), σ (standard deviation)\nN(μ, σ²)\n(-∞, ∞)\n\n\nExponential\nλ (rate)\nExp(λ)\n[0, ∞)\n\n\nGamma\nk (shape), θ (scale)\nΓ(k, θ)\n[0, ∞)\n\n\nBeta\nα (shape 1), β (shape 2)\nBeta(α, β)\n[0,1]\n\n\nChi-Squared\nk (degrees of freedom)\nχ²(k)\n[0, ∞)\n\n\nt-distribution\nν (degrees of freedom)\nt(ν)\n(-∞, ∞)\n\n\nF-distribution\nν₁ (degrees of freedom 1), ν₂ (degrees of freedom 2)\nF(ν₁, ν₂)\n[0, ∞)\n\n\nWeibull\nk (shape), λ (scale)\nWeibull(k, λ)\n[0, ∞)\n\n\nLognormal\nμ (location), σ (scale)\nLognormal(μ, σ)\n[0, ∞)"
  },
  {
    "objectID": "lectures/4.html#common-discrete-rv",
    "href": "lectures/4.html#common-discrete-rv",
    "title": "Distribution Functions",
    "section": "Common Discrete RV",
    "text": "Common Discrete RV\n\n\n\n\n\n\n\n\n\nDiscrete RV\nParameters\nNotation\nSupport\n\n\n\n\nBernoulli\np (probability of success)\nBernoulli(p)\n{0, 1}\n\n\nBinomial\nn (number of trials), p (probability of success)\nBin(n, p)\n{0, 1, 2, …, n}\n\n\nGeometric\np (probability of success)\nGeo(p)\n{1, 2, 3, …}\n\n\nPoisson\nλ (average rate of events)\nPois(λ)\n{0, 1, 2, …}\n\n\nNegative Binomial\nr (number of successes), p (probability of success)\nNB(r, p)\n{r, r+1, r+2, …}\n\n\nDiscrete Uniform\nn (number of possible outcomes)\nDUnif(1, n)\n{1, 2, …, n} or a set of n values"
  },
  {
    "objectID": "lectures/4.html#probability-and-pdmf",
    "href": "lectures/4.html#probability-and-pdmf",
    "title": "Distribution Functions",
    "section": "Probability and PD/MF",
    "text": "Probability and PD/MF\n\nContinuousDiscrete\n\n\n\n\nCode\nmean &lt;- 0  # Mean of the distribution\nsd &lt;- 1   # Standard deviation of the distribution\n\n# Generate data points for the curve (more points = smoother curve)\nx &lt;- seq(mean - 3*sd, mean + 3*sd, length.out = 100)  # Range covering most of the distribution\ny &lt;- dnorm(x, mean = mean, sd = sd)  # Calculate the density at each x value\n\n# Create the plot\nggplot(data = data.frame(x, y), aes(x = x, y = y)) +\n  geom_line(color = \"sienna\", size = 1) +  # Line for the distribution curve\n  labs(x = \"X\",\n       y = \"Probability Density\") +\n  scale_x_continuous(breaks = seq(mean - 3*sd, mean + 3*sd, by = sd)) # Ticks at standard deviations\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nn &lt;- 10   # Number of trials\np &lt;- 0.3  # Probability of success on each trial\n\n# Generate the data for the plot\nx &lt;- 0:n  # Possible values for the random variable (number of successes)\ny &lt;- dbinom(x, size = n, prob = p)  # Calculate the probabilities\n\n# Create the plot using geom_col (for discrete data)\nggplot(data = data.frame(x, y), aes(x = factor(x), y = y)) +  # x as factor for discrete bars\n  geom_col(fill = \"bisque4\", color = \"black\", alpha =  0.75) +\n  labs(title = paste(\"Binomial Distribution (n =\", n, \", p =\", p, \")\"),\n       x = \"Number of Successes (x)\",\n       y = \"Probability P(X = x)\")"
  },
  {
    "objectID": "lectures/4.html#normal-distribution-1",
    "href": "lectures/4.html#normal-distribution-1",
    "title": "Distribution Functions",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nThe Normal Distribution is a probability distribution that is symmetric, with most of the data points clustering around the mean.\n\nIt’s bell-shaped and is defined mathematically by two parameters:\n\nMean (\\(\\mu\\)): The center or peak of the distribution.\nStandard Deviation (\\(\\sigma\\)): Controls the spread of the distribution.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nFor any normally distributed data, the highest probability density is at the mean, and as you move away from the mean, the probability density gradually decreases."
  },
  {
    "objectID": "lectures/4.html#properties",
    "href": "lectures/4.html#properties",
    "title": "Distribution Functions",
    "section": "Properties",
    "text": "Properties\n\nSymmetry: It is perfectly symmetric about the mean, meaning the left side is a mirror image of the right.\nUnimodal: There is a single peak at the mean.\nMean, Median, and Mode are Equal: In a normal distribution, these three measures of central tendency are located at the same point.\n68-95-99.7 Rule (Empirical Rule)\n\n\nThis rule helps us understand how data is distributed in a normal curve and provides a quick way to estimate probabilities for normally distributed data."
  },
  {
    "objectID": "lectures/4.html#normal-distribution-2",
    "href": "lectures/4.html#normal-distribution-2",
    "title": "Distribution Functions",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\n\\[\nX\\sim N(\\mu, \\sigma)\n\\]\n\\[\n-\\infty &lt; X &lt; \\infty\n\\]\n\n\\[\nf_X(x) = \\frac{1}{\\sqrt{2\\pi \\sigma}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\]"
  },
  {
    "objectID": "lectures/4.html#normal-pdf-1",
    "href": "lectures/4.html#normal-pdf-1",
    "title": "Distribution Functions",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "lectures/4.html#standard-normal-distribution",
    "href": "lectures/4.html#standard-normal-distribution",
    "title": "Distribution Functions",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\nThe Standard Normal Distribution is a special type of normal distribution with a mean of 0 and a standard deviation of 1. It’s often used as a reference to convert any normal distribution to a standard form."
  },
  {
    "objectID": "lectures/4.html#standard-normal-distribution-1",
    "href": "lectures/4.html#standard-normal-distribution-1",
    "title": "Distribution Functions",
    "section": "Standard Normal Distribution",
    "text": "Standard Normal Distribution\n\n\nCode\nmean &lt;- 0  # Mean of the distribution\nsd &lt;- 1   # Standard deviation of the distribution\n\n# Generate data points for the curve (more points = smoother curve)\nx &lt;- seq(mean - 3*sd, mean + 3*sd, length.out = 100)  # Range covering most of the distribution\ny &lt;- dnorm(x, mean = mean, sd = sd)  # Calculate the density at each x value\n\n# Create the plot\nggplot(data = data.frame(x, y), aes(x = x, y = y)) +\n  geom_line(color = \"palegreen4\", size = 1) +  # Line for the distribution curve\n  labs(x = \"X\",\n       y = \"Probability Density\") +\n  scale_x_continuous(breaks = seq(mean - 3*sd, mean + 3*sd, by = sd)) # Ticks at standard deviations"
  },
  {
    "objectID": "lectures/4.html#z-scores",
    "href": "lectures/4.html#z-scores",
    "title": "Distribution Functions",
    "section": "Z-Scores",
    "text": "Z-Scores\nA Z-score (or standard score) tells us how many standard deviations an individual data point is from the mean. It’s calculated as:\n\\[\nZ = \\frac{X - \\mu}{\\sigma}\n\\]\n\nIf \\(Z\\) is positive, the data point is above the mean.\nIf \\(Z\\) is negative, the data point is below the mean.\nUsing Z-scores, we can compare values across different normal distributions or find the probability associated with a particular score."
  },
  {
    "objectID": "lectures/4.html#why-the-normal-distribution-is-important",
    "href": "lectures/4.html#why-the-normal-distribution-is-important",
    "title": "Distribution Functions",
    "section": "Why the Normal Distribution is Important",
    "text": "Why the Normal Distribution is Important\n\nIt Describes Many Natural Phenomena: Heights, weights, test scores, measurement errors, and countless other variables follow a normal distribution, especially when influenced by many small, random factors.\nPredictive Power: With normally distributed data, we can make predictions and infer probabilities, thanks to the 68-95-99.7 rule.\nCentral Limit Theorem: The normal distribution is foundational to the Central Limit Theorem, which tells us that, regardless of the original data distribution, the sampling distribution of the sample mean will approach a normal distribution as sample size increases.\nEase of Use in Statistical Methods: Many statistical tests and methods assume normality, allowing for simplified calculations and reliable inferences."
  },
  {
    "objectID": "lectures/4.html#apps-of-the-normal-dist.",
    "href": "lectures/4.html#apps-of-the-normal-dist.",
    "title": "Distribution Functions",
    "section": "Apps of the Normal Dist.",
    "text": "Apps of the Normal Dist.\n\nStandardized TestingFinance\n\n\nScores on standardized tests, such as IQ tests or the SAT, are often designed to follow a normal distribution. By knowing a student’s score in terms of Z-scores, we can determine their percentile or how they compare to other test-takers.\n\n\nIn finance, stock returns and other economic factors are often modeled with a normal distribution to estimate risk, forecast trends, and make informed investment decisions."
  },
  {
    "objectID": "lectures/4.html#finding-probability",
    "href": "lectures/4.html#finding-probability",
    "title": "Distribution Functions",
    "section": "Finding Probability",
    "text": "Finding Probability\n\\[\nX \\sim N(\\mu, \\sigma)\n\\]\n\n\\[\nP(a \\leq X \\leq b) = P(a &lt; X &lt; b) = \\int_a^b \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} dx\n\\]"
  },
  {
    "objectID": "lectures/4.html#what-is-the-empirical-rule",
    "href": "lectures/4.html#what-is-the-empirical-rule",
    "title": "Distribution Functions",
    "section": "What is the Empirical Rule?",
    "text": "What is the Empirical Rule?\nThe Empirical Rule provides a way to understand the spread of data in a normal distribution by describing how data points cluster around the mean. According to this rule:\n\nApproximately 68% of data points fall within one standard deviation of the mean.\nApproximately 95% of data points fall within two standard deviations of the mean.\nApproximately 99.7% of data points fall within three standard deviations of the mean.\n\nThe empirical rule is very helpful because, with just the mean and standard deviation, we can quickly estimate how data is distributed within a normal curve."
  },
  {
    "objectID": "lectures/4.html#empirical-rule-to-the-normal-dist.",
    "href": "lectures/4.html#empirical-rule-to-the-normal-dist.",
    "title": "Distribution Functions",
    "section": "Empirical Rule to the Normal Dist.",
    "text": "Empirical Rule to the Normal Dist.\nLet’s define the key terms and apply the empirical rule to the normal distribution.\n\nMean (μ): This is the central point of the normal distribution where the data clusters around.\nStandard Deviation (σ): This is a measure of how spread out the data points are from the mean."
  },
  {
    "objectID": "lectures/4.html#empirical-rule-to-the-normal-dist.-1",
    "href": "lectures/4.html#empirical-rule-to-the-normal-dist.-1",
    "title": "Distribution Functions",
    "section": "Empirical Rule to the Normal Dist.",
    "text": "Empirical Rule to the Normal Dist.\nIn a normal distribution:\n\n68% of data lies between \\((\\mu - \\sigma)\\) and \\((\\mu + \\sigma)\\).\n95% of data lies between \\((\\mu - 2\\sigma)\\) and \\((\\mu + 2\\sigma)\\).\n99.7% of data lies between \\((\\mu - 3\\sigma)\\) and \\((\\mu + 3\\sigma)\\).\n\nThese intervals allow us to estimate probabilities for data within each range without needing to calculate exact probabilities."
  },
  {
    "objectID": "lectures/4.html#visualizing-the-empirical-rule",
    "href": "lectures/4.html#visualizing-the-empirical-rule",
    "title": "Distribution Functions",
    "section": "Visualizing the Empirical Rule",
    "text": "Visualizing the Empirical Rule\nTo better understand the empirical rule, imagine a symmetric, bell-shaped normal curve. Here’s how it would look based on the empirical rule:\n\nThe 68% region represents the middle of the curve, starting one standard deviation left of the mean and ending one standard deviation right.\nThe 95% region stretches further out, covering almost the entire curve except for the outer tails.\nThe 99.7% region includes nearly all data points, covering the entire curve except for a tiny fraction at each extreme.\n\nThis visualization shows how the data is most concentrated around the mean, with less data appearing as we move further away."
  },
  {
    "objectID": "lectures/4.html#using-the-empirical-rule-for-probabilities",
    "href": "lectures/4.html#using-the-empirical-rule-for-probabilities",
    "title": "Distribution Functions",
    "section": "Using the Empirical Rule for Probabilities",
    "text": "Using the Empirical Rule for Probabilities\nThe empirical rule helps us answer questions like:\n\nWhat percentage of data points fall within a certain range?\nHow unusual is a data point located far from the mean?"
  },
  {
    "objectID": "lectures/4.html#examples",
    "href": "lectures/4.html#examples",
    "title": "Distribution Functions",
    "section": "Examples",
    "text": "Examples\n\nIf we know that a data point lies more than two standard deviations away from the mean, we know it’s in the outer 5% of the distribution, making it relatively rare.\nUsing the rule, we can estimate that around 95% of values should lie within two standard deviations of the mean. If we observe data points outside of this range, we might consider them outliers."
  },
  {
    "objectID": "lectures/4.html#more-examples",
    "href": "lectures/4.html#more-examples",
    "title": "Distribution Functions",
    "section": "More Examples",
    "text": "More Examples\n\nExam ScoresHeights of Adults\n\n\nSuppose exam scores are normally distributed with a mean of 70 and a standard deviation of 10.\n\n68% of students scored between 60 and 80 (70 ± 10).\n95% of students scored between 50 and 90 (70 ± 20).\n99.7% of students scored between 40 and 100 (70 ± 30).\n\n\n\nAssume that adult heights follow a normal distribution with a mean height of 170 cm and a standard deviation of 8 cm.\n\n68% of adults have heights between 162 cm and 178 cm (170 ± 8).\n95% of adults have heights between 154 cm and 186 cm (170 ± 16).\n99.7% of adults have heights between 146 cm and 194 cm (170 ± 24)."
  },
  {
    "objectID": "lectures/4.html#binomial-distribution-1",
    "href": "lectures/4.html#binomial-distribution-1",
    "title": "Distribution Functions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\nThe Binomial Distribution is a probability distribution that models the number of successes in a fixed number of trials, where each trial has:\n\nTwo possible outcomes: typically called “success” and “failure.”\nA constant probability of success, \\(p\\), on each trial."
  },
  {
    "objectID": "lectures/4.html#real-world-examples",
    "href": "lectures/4.html#real-world-examples",
    "title": "Distribution Functions",
    "section": "Real-World Examples:",
    "text": "Real-World Examples:\n\nTossing a coin \\(n\\) times and counting how many heads you get.\nRolling a die \\(n\\) times and counting how many times you roll a 6.\nAdministering a medical treatment to \\(n\\) patients and recording how many recover.\n\n\nThe binomial distribution answers questions like:\n\n“What is the probability of getting exactly 3 heads in 5 coin tosses?”\n“What is the likelihood of at least 4 successes in 10 trials?”"
  },
  {
    "objectID": "lectures/4.html#conditions-for-a-binomial-experiment",
    "href": "lectures/4.html#conditions-for-a-binomial-experiment",
    "title": "Distribution Functions",
    "section": "Conditions for a Binomial Experiment",
    "text": "Conditions for a Binomial Experiment\n\nFixed Number of Trials (\\(n\\)):\n\nThe experiment consists of a set number of trials.\n\nTwo Possible Outcomes:\n\nEach trial results in either a success (e.g., heads) or a failure (e.g., tails).\n\nConstant Probability of Success (\\(p\\)):\n\nThe probability of success remains the same for each trial.\n\nIndependence:\n\nThe outcome of one trial does not affect the outcomes of other trials."
  },
  {
    "objectID": "lectures/4.html#the-binomial-probability-formula",
    "href": "lectures/4.html#the-binomial-probability-formula",
    "title": "Distribution Functions",
    "section": "The Binomial Probability Formula",
    "text": "The Binomial Probability Formula\n\\[\nP(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\n\\]\nWhere:\n\n\\(P(X = k)\\): Probability of exactly \\(k\\) successes.\n\\(n\\): Number of trials.\n\\(k\\): Number of successes.\n\\(p\\): Probability of success on a single trial.\n\\(1-p\\): Probability of failure.\n\\(\\binom{n}{k} = \\frac{n!}{k!(n-k)!}\\): Represents the number of ways to choose \\(k\\) successes from \\(n\\) trials"
  },
  {
    "objectID": "lectures/4.html#binomial-distribution-2",
    "href": "lectures/4.html#binomial-distribution-2",
    "title": "Distribution Functions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution"
  },
  {
    "objectID": "lectures/4.html#example-calculation",
    "href": "lectures/4.html#example-calculation",
    "title": "Distribution Functions",
    "section": "Example Calculation",
    "text": "Example Calculation\nSuppose you flip a fair coin 5 times (\\(n = 5, p = 0.5\\)) and want to know the probability of getting exactly 3 heads (\\(k = 3\\)).\n\n\\[\nP(X = 3) = \\binom{5}{3} (0.5)^3 (1-0.5)^{5-3}\n\\]"
  },
  {
    "objectID": "lectures/4.html#properties-of-the-binomial-dist.",
    "href": "lectures/4.html#properties-of-the-binomial-dist.",
    "title": "Distribution Functions",
    "section": "Properties of the Binomial Dist.",
    "text": "Properties of the Binomial Dist.\n\nMean and VarianceShape of the Distribution\n\n\nFor a binomial random variable \\(X\\):\n\nMean (Expected Value): \\(\\mu = n \\cdot p\\)\nVariance: \\(\\sigma^2 = n \\cdot p \\cdot (1-p)\\)\nStandard Deviation: \\(\\sigma = \\sqrt{n \\cdot p \\cdot (1-p)}\\)\n\n\n\n\nIf \\(p = 0.5\\), the distribution is symmetric.\nIf \\(p &gt; 0.5\\), the distribution is skewed left.\nIf \\(p &lt; 0.5\\), the distribution is skewed right."
  },
  {
    "objectID": "lectures/4.html#applications-2",
    "href": "lectures/4.html#applications-2",
    "title": "Distribution Functions",
    "section": "Applications",
    "text": "Applications\n\nQuality ControlSportsClinical Trials\n\n\nA factory produces lightbulbs, and 95% of them meet quality standards. If you randomly test 10 bulbs, what is the probability that exactly 8 bulbs pass the test?\nHere:\n\n\\(n = 10\\), \\(p = 0.95\\), \\(k = 8\\).\n\n\\[\nP(X = 8) = \\binom{10}{8} (0.95)^8 (0.05)^2\n\\]\n\n\nA basketball player has a 60% chance of making a free throw. If they take 5 shots, what is the probability of making at least 3 shots?\nHere: - \\(n = 5\\), \\(p = 0.6\\).\n\\[\nP(X \\geq 3) = P(X = 3) + P(X = 4) + P(X = 5)\n\\]\n\n\nIn a clinical trial, a new drug has a 70% success rate. If 15 patients are treated, what is the probability that exactly 10 respond positively to the treatment?"
  },
  {
    "objectID": "lectures/4.html#poisson-distribution-1",
    "href": "lectures/4.html#poisson-distribution-1",
    "title": "Distribution Functions",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution\nThe Poisson Distribution is a discrete probability distribution that models the number of events occurring within a fixed interval. These events must happen independently and at a constant average rate."
  },
  {
    "objectID": "lectures/4.html#real-world-examples-1",
    "href": "lectures/4.html#real-world-examples-1",
    "title": "Distribution Functions",
    "section": "Real-World Examples",
    "text": "Real-World Examples\n\nThe number of emails you receive in an hour.\nThe number of cars passing through a toll booth in 10 minutes.\nThe number of defects in a square meter of fabric.\n\n\nThe Poisson distribution helps us answer questions like:\n\n“What is the probability of receiving 5 emails in the next hour?”\n“How likely is it to have 2 defects in a single square meter?”"
  },
  {
    "objectID": "lectures/4.html#conditions-for-the-poisson-dist.",
    "href": "lectures/4.html#conditions-for-the-poisson-dist.",
    "title": "Distribution Functions",
    "section": "Conditions for the Poisson Dist.",
    "text": "Conditions for the Poisson Dist.\n\nEvents Occur Randomly:\n\nThe events are random and unpredictable.\n\nIndependence:\n\nThe occurrence of one event does not affect the probability of another event occurring.\n\nConstant Average Rate (\\(\\lambda\\)):\n\nThe average number of events (\\(\\lambda\\)) over a fixed interval remains constant.\n\nNon-Overlapping Intervals:\n\nEvents in one interval do not influence events in another."
  },
  {
    "objectID": "lectures/4.html#the-poisson-probability-formula",
    "href": "lectures/4.html#the-poisson-probability-formula",
    "title": "Distribution Functions",
    "section": "The Poisson Probability Formula",
    "text": "The Poisson Probability Formula\n\\[\nP(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n\\]\nWhere:\n\n\\(P(X = k)\\): Probability of \\(k\\) events occurring.\n\\(\\lambda\\): Average number of events in the interval.\n\\(e \\approx 2.718\\)\n\\(k!\\): Factorial of \\(k\\), calculated as \\(k \\times (k-1) \\times \\dots \\times 1\\)."
  },
  {
    "objectID": "lectures/4.html#poisson-distribution-2",
    "href": "lectures/4.html#poisson-distribution-2",
    "title": "Distribution Functions",
    "section": "Poisson Distribution",
    "text": "Poisson Distribution"
  },
  {
    "objectID": "lectures/4.html#example-calculation-1",
    "href": "lectures/4.html#example-calculation-1",
    "title": "Distribution Functions",
    "section": "Example Calculation",
    "text": "Example Calculation\nSuppose a call center receives an average of 10 calls per hour (\\(\\lambda = 10\\)). What is the probability of receiving exactly 7 calls in the next hour ($ k = 7 $)?\n\\[\nP(X = 7) = \\frac{10^7 e^{-10}}{7!}\n\\]"
  },
  {
    "objectID": "lectures/4.html#poisson-distribution-properties",
    "href": "lectures/4.html#poisson-distribution-properties",
    "title": "Distribution Functions",
    "section": "Poisson Distribution Properties",
    "text": "Poisson Distribution Properties\n\nMean: \\(\\mu = \\lambda\\)\nVariance: \\(\\sigma^2 = \\lambda\\)\nStandard Deviation: \\(\\sigma = \\sqrt{\\lambda}\\)"
  },
  {
    "objectID": "lectures/4.html#applications-3",
    "href": "lectures/4.html#applications-3",
    "title": "Distribution Functions",
    "section": "Applications",
    "text": "Applications\n\nTraffic FlowDefective Products\n\n\nA toll booth observes an average of 3 cars passing through every 5 minutes (\\(\\lambda = 3\\)). What is the probability of seeing exactly 5 cars in the next 5 minutes?\nUsing the formula: \\[\nP(X = 5) = \\frac{3^5 e^{-3}}{5!} = \\frac{243 \\cdot 0.0498}{120} \\approx 0.1008\n\\]\n\n\nA factory produces an average of 2 defective items per day (\\(\\lambda = 2\\)). What is the probability of finding no defective items in a day (\\(k = 0\\))?\n\\[\nP(X = 0) = \\frac{2^0 e^{-2}}{0!} = e^{-2} \\approx 0.1353\n\\]"
  },
  {
    "objectID": "lectures/4.html#distributions-in-r",
    "href": "lectures/4.html#distributions-in-r",
    "title": "Distribution Functions",
    "section": "Distributions in R",
    "text": "Distributions in R\n\n?Distributions"
  },
  {
    "objectID": "lectures/4.html#function-structure",
    "href": "lectures/4.html#function-structure",
    "title": "Distribution Functions",
    "section": "Function Structure",
    "text": "Function Structure\n\n\n\nLetter\nFunctionality\n\n\n\n\n“d”\nreturns the height of the probability density function\n\n\n“p”\nreturns the cummulative density function value\n\n\n“q”\nreturns the inverse cummulative density function (percentiles)\n\n\n“r”\nreturns a randomly generated number"
  },
  {
    "objectID": "lectures/4.html#probabilities",
    "href": "lectures/4.html#probabilities",
    "title": "Distribution Functions",
    "section": "Probabilities",
    "text": "Probabilities\nR can compute the probabilities of a distribution given the correct parameters:\n\nCummulative probability: p is used in front of the distribution R function\nProbability for a discrete distribution: d is used in front of the distribution R function\n\nNote: Continuous Distribution Functions will not yield a valid probability value."
  },
  {
    "objectID": "lectures/4.html#examples-1",
    "href": "lectures/4.html#examples-1",
    "title": "Distribution Functions",
    "section": "Examples",
    "text": "Examples\n\n123\n\n\nFind \\(P(X \\leq 5 )\\) where \\(X \\sim N(6,2)\\).\n\n\nCode\npnorm(5, mean = 6, sd = 2)\n\n\n\n\nFind \\(P(X \\geq 7 )\\) where \\(X \\sim N(6,2)\\).\n\n\nCode\n1 - pnorm(7, mean = 6, sd = 2)\n\n\n\n\nFind \\(P(X = 20 )\\) where \\(X \\sim Bin(30,0.8)\\).\n\n\nCode\ndbinom(20, size = 30, prob = 0.8)"
  },
  {
    "objectID": "lectures/4.html#more-examples-1",
    "href": "lectures/4.html#more-examples-1",
    "title": "Distribution Functions",
    "section": "More Examples",
    "text": "More Examples\n\n123\n\n\nFind \\(P(2 \\leq X \\leq 5 )\\) where \\(X \\sim N(6,2)\\).\n\n\nCode\npnorm(5, 6, 2) - pnorm(2, 6, 2) \n\n\n\n\nFind \\(P(14 &lt; X &lt; 20)\\) where \\(X \\sim Pois(16)\\).\n\n\nCode\nppois(19, lambda = 16) - ppois(14, lambda = 16)\n\n## OR\n\ndpois(15, 16) + dpois(16, 16) + dpois(17, 16) + dpois(18, 16) + dpois(19, 16)\n\n\n\n\nFind \\(P(23 &lt; X)\\) where \\(X \\sim Pois(12)\\).\n\n\nCode\n1 - ppois(23, 12)"
  },
  {
    "objectID": "lectures/4.html#percentiles-1",
    "href": "lectures/4.html#percentiles-1",
    "title": "Distribution Functions",
    "section": "Percentiles",
    "text": "Percentiles\nFinding the values (percentiles) for any distributions can be found by using the q-based distribution R function such as qnorm(), qpois(), and qbinom() functions."
  },
  {
    "objectID": "lectures/4.html#examples-2",
    "href": "lectures/4.html#examples-2",
    "title": "Distribution Functions",
    "section": "Examples",
    "text": "Examples\n\n123\n\n\nFinding the \\(95^{th}\\) percentile from \\(N(0,1)\\), we will use the qnorm().\n\n\nCode\nqnorm(.95, 0, 1)\n\n\n\n\nFinding the \\(95^{th}\\) percentile from a Poisson distribution with \\(\\lambda = 9.5\\).\n\n\nCode\nqpois(.95, 9.5)\n\n\n\n\nFinding the \\(75^{th}\\) percentile for \\(Bin(45,.4)\\).\n\n\nCode\nqbinom(.75, 45, .4)"
  },
  {
    "objectID": "lectures/4.html#random-number-generator",
    "href": "lectures/4.html#random-number-generator",
    "title": "Distribution Functions",
    "section": "Random Number Generator",
    "text": "Random Number Generator\nR is capable of generating random numbers. For example if we want to generate a random sample of size fifty from a normal distribution with mean eight and variance three, we will use the rnorm(). If we want to generate a random sample from any distribution, use the distribution function with r in front of it."
  },
  {
    "objectID": "lectures/4.html#examples-3",
    "href": "lectures/4.html#examples-3",
    "title": "Distribution Functions",
    "section": "Examples",
    "text": "Examples\n\n1234\n\n\nLet’s first generate the random sample of fifty from \\(X \\sim N(8,3)\\).\n\n\nCode\nrnorm(50, 8, sqrt(3))\n\n\n\n\nGenerate a random sample of 100 form an \\(X \\sim Gamma (2,3)\\).\n\n\nCode\nrgamma(100, 2,3)\n\n\n\n\nGenerate a random sample of 100 form an \\(X \\sim Binom (25,.23)\\).\n\n\nCode\nrbinom(n = 100, size  = 25, prob = 0.23)\n\n\n\n\nGenerate a random sample of 100 form an \\(X \\sim Pois (34.4)\\).\n\n\nCode\nrpois(n = 100, lambda = 34.4)"
  },
  {
    "objectID": "lectures/6.html#r-packages",
    "href": "lectures/6.html#r-packages",
    "title": "Simple  Logistic Regression",
    "section": "R Packages",
    "text": "R Packages\n\nrcistats\ntidyverse"
  },
  {
    "objectID": "lectures/6.html#heart-disease-data",
    "href": "lectures/6.html#heart-disease-data",
    "title": "Simple  Logistic Regression",
    "section": "Heart Disease Data",
    "text": "Heart Disease Data\n\n\nVariables of Interest\n\nage: Age of patient\ndisease: Indicating if they have heart disease"
  },
  {
    "objectID": "lectures/6.html#modeling-binary-outcomes-1",
    "href": "lectures/6.html#modeling-binary-outcomes-1",
    "title": "Simple  Logistic Regression",
    "section": "Modeling Binary Outcomes",
    "text": "Modeling Binary Outcomes"
  },
  {
    "objectID": "lectures/6.html#modeling-binary-outcomes-2",
    "href": "lectures/6.html#modeling-binary-outcomes-2",
    "title": "Simple  Logistic Regression",
    "section": "Modeling Binary Outcomes",
    "text": "Modeling Binary Outcomes"
  },
  {
    "objectID": "lectures/6.html#mathematical-model",
    "href": "lectures/6.html#mathematical-model",
    "title": "Simple  Logistic Regression",
    "section": "Mathematical Model",
    "text": "Mathematical Model\n\\[\n\\left(\\begin{array}{c}\nYes \\\\\nNo\n\\end{array}\\right) = \\beta_0 + \\beta_1X\n\\]"
  },
  {
    "objectID": "lectures/6.html#let",
    "href": "lectures/6.html#let",
    "title": "Simple  Logistic Regression",
    "section": "Let …",
    "text": "Let …\n\\[\nY = \\left\\{\\begin{array}{cc}\n1 & Yes \\\\\n0 & No\n\\end{array}\\right.\n\\]"
  },
  {
    "objectID": "lectures/6.html#construct-a-model",
    "href": "lectures/6.html#construct-a-model",
    "title": "Simple  Logistic Regression",
    "section": "Construct a Model",
    "text": "Construct a Model\n\\[\nP\\left(Y = 1\\right) = \\beta_0 + \\beta_1X\n\\]"
  },
  {
    "objectID": "lectures/6.html#construct-a-model-1",
    "href": "lectures/6.html#construct-a-model-1",
    "title": "Simple  Logistic Regression",
    "section": "Construct a Model",
    "text": "Construct a Model\n\\[\nP\\left(Y = 1\\right) = \\frac{e^{\\beta_0 + \\beta_1X}}{1 + e^{\\beta_0 + \\beta_1X}}\n\\]"
  },
  {
    "objectID": "lectures/6.html#construct-a-model-2",
    "href": "lectures/6.html#construct-a-model-2",
    "title": "Simple  Logistic Regression",
    "section": "Construct a Model",
    "text": "Construct a Model\n\\[\n\\frac{P(Y = 1)}{P(Y = 0)} = e^{\\beta_0 + \\beta_1X}\n\\]\nwhere \\(\\frac{P(Y = 1)}{P(Y = 0)}\\) are considered the odds of observing \\(Y = 1\\)."
  },
  {
    "objectID": "lectures/6.html#the-logistic-model",
    "href": "lectures/6.html#the-logistic-model",
    "title": "Simple  Logistic Regression",
    "section": "The Logistic Model",
    "text": "The Logistic Model\n\\[\n\\log\\left\\{\\frac{P(Y = 1)}{P(Y = 0)}\\right\\} = \\beta_0 + \\beta_1X\n\\]"
  },
  {
    "objectID": "lectures/6.html#notation",
    "href": "lectures/6.html#notation",
    "title": "Simple  Logistic Regression",
    "section": "Notation",
    "text": "Notation\n\\[\n\\log\\left\\{\\frac{P(Y = 1)}{P(Y = 0)}\\right\\} =\n\\log\\left\\{odds\\ of \\ 1\\right\\} =\nlo(1)\n\\]"
  },
  {
    "objectID": "lectures/6.html#logistic-regression-1",
    "href": "lectures/6.html#logistic-regression-1",
    "title": "Simple  Logistic Regression",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nLogistic Regression is used to model the association between a predictor and a binary outcome variable.\n\nThis is similar Linear Regression which models the association between a predictor and a numerical outcome variable."
  },
  {
    "objectID": "lectures/6.html#logistic-regression-2",
    "href": "lectures/6.html#logistic-regression-2",
    "title": "Simple  Logistic Regression",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nLogistic Regression uses the logistic model to formulate the relationship between a predictor and the outcome.\n\nMore specifically, for an outcome of Y:\n\\[\nY = \\left\\{\\begin{array}{cc}\n1 & \\text{Category 1} \\\\\n0 & \\text{Category 2}\n\\end{array}\\right.\n\\]\nThe predictor variable will model the probability of observing category 1 (\\(P(Y=1)\\))"
  },
  {
    "objectID": "lectures/6.html#logistic-model",
    "href": "lectures/6.html#logistic-model",
    "title": "Simple  Logistic Regression",
    "section": "Logistic Model",
    "text": "Logistic Model\n\\[\n\\log\\left\\{\\frac{P(Y = 1)}{P(Y = 0)}\\right\\} = \\beta_0 + \\beta_1X\n\\]"
  },
  {
    "objectID": "lectures/6.html#regression-coefficients-beta",
    "href": "lectures/6.html#regression-coefficients-beta",
    "title": "Simple  Logistic Regression",
    "section": "Regression Coefficients \\(\\beta\\)",
    "text": "Regression Coefficients \\(\\beta\\)\nThe regression coefficients quantify how a specific predictor changes the odds of observing the first category of the outcome (\\(Y = 1\\))"
  },
  {
    "objectID": "lectures/6.html#estimating-beta",
    "href": "lectures/6.html#estimating-beta",
    "title": "Simple  Logistic Regression",
    "section": "Estimating \\(\\beta\\)",
    "text": "Estimating \\(\\beta\\)\nTo obtain the numerical value for \\(\\beta\\), denoted as \\(\\hat \\beta\\), we will be finding the values of \\(\\hat \\beta\\) that maximizes the likelihood function:\n\\[\nL(\\boldsymbol \\beta) = \\prod_{i=1}^n \\left(\\frac{e^{\\beta_0 + \\beta_1X}}{1 + e^{\\beta_0 + \\beta_1X}}\\right)^{Y_i}\\left(\\frac{1}{1 + e^{\\beta_0 + \\beta_1X}}\\right)^{1-Y_i}\n\\]\nThe likelihood function can be thought as the probability of observing the entire data set. Therefore, we want to choose the values the \\(\\beta_0\\) and \\(\\beta_1\\) that will result in the highest probability of observing the data."
  },
  {
    "objectID": "lectures/6.html#estimated-parameters",
    "href": "lectures/6.html#estimated-parameters",
    "title": "Simple  Logistic Regression",
    "section": "Estimated Parameters",
    "text": "Estimated Parameters\nThe values you obtain (\\(\\hat \\beta\\)) tell you the relationship between the a predictor variable and the log odds of observing the first category of the outcome \\(Y=1\\).\n\nExponentiating the estimate (\\(e^{\\hat \\beta}\\)) will give you the relationship between a predictor variable and the odds of observing the first category of the outcome \\(Y=1\\)."
  },
  {
    "objectID": "lectures/6.html#interpreting-hat-beta",
    "href": "lectures/6.html#interpreting-hat-beta",
    "title": "Simple  Logistic Regression",
    "section": "Interpreting \\(\\hat \\beta\\)",
    "text": "Interpreting \\(\\hat \\beta\\)\nFor a continuous predictor variable:\nAs X increases by 1 unit, the odds of observing the first category (\\(Y = 1\\)) increases by a factor of \\(e^{\\hat\\beta}\\)."
  },
  {
    "objectID": "lectures/6.html#logistic-regression-in-r-1",
    "href": "lectures/6.html#logistic-regression-in-r-1",
    "title": "Simple  Logistic Regression",
    "section": "Logistic Regression in R",
    "text": "Logistic Regression in R\nxglm &lt;- glm(Y ~ X,\n            data = DATA,\n            family = binomial())\nxglm\n\nDATA: Name of the data frame\nY: Outcome Variable of Interest in the data frame DATA\nX: Predictor Variable in the data frame DATA"
  },
  {
    "objectID": "lectures/6.html#model-information",
    "href": "lectures/6.html#model-information",
    "title": "Simple  Logistic Regression",
    "section": "Model Information",
    "text": "Model Information\nThe model_info function can provide basic information about a linear or logistic regression model.\n\nIt can provide what is being modeled (yes, 1) in logistic regression.\n\n\nIt can provide basic info of the predictor variables."
  },
  {
    "objectID": "lectures/6.html#model-information-in-r",
    "href": "lectures/6.html#model-information-in-r",
    "title": "Simple  Logistic Regression",
    "section": "Model Information in R",
    "text": "Model Information in R\nmodel_info(MODEL)\n\nMODEL: fitted model from lm() or glm"
  },
  {
    "objectID": "lectures/6.html#example",
    "href": "lectures/6.html#example",
    "title": "Simple  Logistic Regression",
    "section": "Example",
    "text": "Example\nModelling disease by age:\n\n\nCode\nxglm &lt;- glm(disease ~ cp + age + sex + restecg + fbs,\n            data = heart_disease,\n            family = binomial())\nmodel_info(xglm)\nxglm\n\n\n#&gt; \n#&gt; Call:  glm(formula = disease ~ cp + age + sex + restecg + fbs, family = binomial(), \n#&gt;     data = heart_disease)\n#&gt; \n#&gt; Coefficients:\n#&gt;                         (Intercept)                   cpNon-anginal Pain  \n#&gt;                            -3.97563                             -2.30854  \n#&gt;                   cpAtypical Angina                     cpTypical Angina  \n#&gt;                            -2.38883                             -2.31736  \n#&gt;                                 age                              sexMale  \n#&gt;                             0.06316                              1.77141  \n#&gt;        restecgST-T wave Abnormality  restecgLeft Ventricular Hypertrophy  \n#&gt;                             1.62429                              0.50215  \n#&gt;         fbsFasting Blood Sugar &gt;120  \n#&gt;                             0.08444  \n#&gt; \n#&gt; Degrees of Freedom: 296 Total (i.e. Null);  288 Residual\n#&gt; Null Deviance:       409.9 \n#&gt; Residual Deviance: 286.6     AIC: 304.6"
  },
  {
    "objectID": "lectures/6.html#section",
    "href": "lectures/6.html#section",
    "title": "Simple  Logistic Regression",
    "section": "",
    "text": "\\[\nlo(disease) = -3.0512 + 0.0529 (age)\n\\]"
  },
  {
    "objectID": "lectures/6.html#interpretation",
    "href": "lectures/6.html#interpretation",
    "title": "Simple  Logistic Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\\[\nlo(disease) = -3.0512 + 0.0529 (age)\n\\]\n\n\nCode\nexp(0.05291)\n\n\n#&gt; [1] 1.054335\n\n\n\nAs age increases by 1 year, the odds of having heart disease increases by a factor of 1.054."
  },
  {
    "objectID": "lectures/6.html#working-with-probabilities",
    "href": "lectures/6.html#working-with-probabilities",
    "title": "Simple  Logistic Regression",
    "section": "Working with probabilities",
    "text": "Working with probabilities\nAs you can see, working with odds may be unintuitive for the average person. It will be better to predict the probability and display those results to individuals."
  },
  {
    "objectID": "lectures/6.html#predicting-probability",
    "href": "lectures/6.html#predicting-probability",
    "title": "Simple  Logistic Regression",
    "section": "Predicting Probability",
    "text": "Predicting Probability\n\\[\n\\hat P\\left(Y = 1\\right) = \\frac{e^{\\hat\\beta_0 + \\hat\\beta_1X}}{1 + e^{\\hat\\beta_0 + \\hat\\beta_1X}}\n\\]"
  },
  {
    "objectID": "lectures/6.html#prediction-in-r",
    "href": "lectures/6.html#prediction-in-r",
    "title": "Simple  Logistic Regression",
    "section": "Prediction in R",
    "text": "Prediction in R\nxglm &lt;- glm(Y ~ X,\n            data = DATA,\n            family = binomial())\nndf &lt;- data.frame(X = VAL)\npredict(xglm,\n        ndf,\n        type = \"response\")"
  },
  {
    "objectID": "lectures/6.html#example-1",
    "href": "lectures/6.html#example-1",
    "title": "Simple  Logistic Regression",
    "section": "Example 1",
    "text": "Example 1\nPredict the probability of having heart disease for a patient who is 40 years old.\n\n\nCode\nxglm &lt;- glm(disease ~ age,\n            data = heart_disease,\n            family = binomial())\nndf &lt;- data.frame(age = 40)\npredict(xglm, ndf, type = \"response\")\n\n\n#&gt;         1 \n#&gt; 0.2819196"
  },
  {
    "objectID": "lectures/6.html#example-2",
    "href": "lectures/6.html#example-2",
    "title": "Simple  Logistic Regression",
    "section": "Example 2",
    "text": "Example 2\nPredict the probability of having heart disease for a patient who is 55 years old.\n\n\nCode\nxglm &lt;- glm(disease ~ age,\n            data = heart_disease,\n            family = binomial())\nndf &lt;- data.frame(age = 55)\npredict(xglm, ndf, type = \"response\")\n\n\n#&gt;         1 \n#&gt; 0.4647183"
  },
  {
    "objectID": "lectures/6.html#example-3",
    "href": "lectures/6.html#example-3",
    "title": "Simple  Logistic Regression",
    "section": "Example 3",
    "text": "Example 3\nPredict the probability of having heart disease for a patient who is 70 years old.\n\n\nCode\nxglm &lt;- glm(disease ~ age,\n            data = heart_disease,\n            family = binomial())\nndf &lt;- data.frame(age = 70)\npredict(xglm, ndf, type = \"response\")\n\n\n#&gt;         1 \n#&gt; 0.6575143"
  },
  {
    "objectID": "lectures/6.html#example-4",
    "href": "lectures/6.html#example-4",
    "title": "Simple  Logistic Regression",
    "section": "Example",
    "text": "Example\n\n\n\nAge\n40\n55\n70\n\n\n\n\nProbabiltiy\n28.2%\n46.5%\n65.8%"
  },
  {
    "objectID": "lectures/8.html#r-packages",
    "href": "lectures/8.html#r-packages",
    "title": "Multivariable  Regression",
    "section": "R Packages",
    "text": "R Packages\n\nrcistats\ntidyverse"
  },
  {
    "objectID": "lectures/8.html#palmer-penguins-data",
    "href": "lectures/8.html#palmer-penguins-data",
    "title": "Multivariable  Regression",
    "section": "Palmer Penguins Data",
    "text": "Palmer Penguins Data\n\n\nVariables of Interest\n\nspecies: Penguin species\nflipper_len: Flipper Length in millimeters\nbody_mass: Body mass in grams\n\n\n\n\n\nArtwork by @allison_horst"
  },
  {
    "objectID": "lectures/8.html#heart-disease-data",
    "href": "lectures/8.html#heart-disease-data",
    "title": "Multivariable  Regression",
    "section": "Heart Disease Data",
    "text": "Heart Disease Data\n\n\nVariables of Interest\n\nthal: Thallium stress test result\nthalach: Maximum heart rate achieved\ndisease: Indicating if they have heart disease"
  },
  {
    "objectID": "lectures/8.html#penguins-body-mass",
    "href": "lectures/8.html#penguins-body-mass",
    "title": "Multivariable  Regression",
    "section": "Penguins: Body Mass",
    "text": "Penguins: Body Mass\n\nBody MassFlipper LengthSpeciesLines\n\n\n\n\nCode\nggplot(penguins, aes(body_mass)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(penguins, aes(x = flipper_len, y = body_mass)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(penguins, aes(x = flipper_len, y = body_mass, color = species)) +\n  geom_point() +\n  stat_density_2d(aes(fill = after_stat(level))) +\n  xlim(c(170, 236)) +\n  ylim(c(2500, 6250))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(penguins, aes(x = flipper_len, y = body_mass, color = species)) +\n  geom_point() +\n  stat_smooth(method = \"lm\")"
  },
  {
    "objectID": "lectures/8.html#heart-disease",
    "href": "lectures/8.html#heart-disease",
    "title": "Multivariable  Regression",
    "section": "Heart Disease",
    "text": "Heart Disease\n\nDiseasethalachthal\n\n\n\n\nCode\n# Fit logistic model\n\nggplot(heart_disease, aes(disease)) +\n  geom_bar() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Fit logistic model\n\nhdf &lt;- heart_disease\nhdf$plot &lt;- ifelse(hdf$disease==\"yes\", 1, 0)\nggplot(hdf, aes(thalach, plot)) +\n  geom_point(alpha = 0.3) +\n  stat_smooth(method = \"glm\",\n              method.args = list(family = \"binomial\"),\n              se = FALSE) +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Fit logistic model\n\nggplot(hdf, aes(thalach, plot, col = thal)) +\n  geom_point(alpha = 0.3) +\n  stat_smooth(method = \"glm\",\n              method.args = list(family = \"binomial\"),\n              se = FALSE) +\n  labs(x = NULL, y = NULL)"
  },
  {
    "objectID": "lectures/8.html#multivariable-linear-regression-1",
    "href": "lectures/8.html#multivariable-linear-regression-1",
    "title": "Multivariable  Regression",
    "section": "Multivariable Linear Regression",
    "text": "Multivariable Linear Regression\nMultivariable Linear Regression (MLR) is used to model an outcome variable (\\(Y\\)) by multiple predictor variables (\\(X_1, X_2, \\ldots, X_p\\)).\n\nUsing MLR, you propose that the ouctome variable was constructed from a set of predictors, with their corresponding regression coefficients (\\(\\beta\\)), and a bit of error\n\n\n\\[\nY = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p + \\varepsilon\n\\]\n\\[\n\\varepsilon \\sim DGP\n\\]"
  },
  {
    "objectID": "lectures/8.html#model-data",
    "href": "lectures/8.html#model-data",
    "title": "Multivariable  Regression",
    "section": "Model Data",
    "text": "Model Data\n\\[\nY = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p + \\varepsilon\n\\]\n\\[\n\\varepsilon \\sim DGP\n\\]\n\n\\[\nY_i = \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\cdots + \\beta_p X_{ip} + \\varepsilon_i\n\\]\n\\[\n\\varepsilon_i \\sim DGP\n\\]"
  },
  {
    "objectID": "lectures/8.html#unknown-parameters",
    "href": "lectures/8.html#unknown-parameters",
    "title": "Multivariable  Regression",
    "section": "Unknown Parameters",
    "text": "Unknown Parameters\n\\[\nY_i = \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\cdots + \\beta_p X_{ip} + \\varepsilon_i\n\\]\n\n\\[\n\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\ldots, \\beta_p\n\\]"
  },
  {
    "objectID": "lectures/8.html#estimated-model",
    "href": "lectures/8.html#estimated-model",
    "title": "Multivariable  Regression",
    "section": "Estimated Model",
    "text": "Estimated Model\n\\[\nY_i = \\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\cdots + \\beta_p X_{ip} + \\varepsilon_i\n\\]\n\\[\n\\hat Y_i = \\hat\\beta_0 + \\hat\\beta_1 X_{i1} + \\hat\\beta_2 X_{i2} + \\cdots + \\hat\\beta_p X_{ip}\n\\]"
  },
  {
    "objectID": "lectures/8.html#estimating-prameters",
    "href": "lectures/8.html#estimating-prameters",
    "title": "Multivariable  Regression",
    "section": "Estimating Prameters",
    "text": "Estimating Prameters\n\\(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\ldots, \\beta_p\\) are estimated by minimizing the following function:\n\\[\n\\sum^n_{i=1} (Y_i-\\hat Y_i)^2\n\\]"
  },
  {
    "objectID": "lectures/8.html#fitting-a-lm-in-r",
    "href": "lectures/8.html#fitting-a-lm-in-r",
    "title": "Multivariable  Regression",
    "section": "Fitting a LM in R",
    "text": "Fitting a LM in R\nxlm &lt;- lm(Y ~ X1 + X2 + ... + Xp, data = DATA)\nxlm\n\nDATA: Name of the data frame\nY: Outcome Variable of Interest in the data frame DATA\nX1, X2, … , X_p : Predictor variables in the data frame DATA"
  },
  {
    "objectID": "lectures/8.html#multivariable-logistic-regression-1",
    "href": "lectures/8.html#multivariable-logistic-regression-1",
    "title": "Multivariable  Regression",
    "section": "Multivariable Logistic Regression",
    "text": "Multivariable Logistic Regression\nMultivariable Logistic Regression is used to model a binary outcome variable (\\(Y\\)) with multiple predictor variables (\\(X_1, X_2, \\ldots, X_p\\)).\n\nUsing Multivariable Logistic Regression, you propose that the ouctome variable was constructed from a set of predictors, with their corresponding regression coefficients (\\(\\beta_j\\)), and generated from a Bernoulli model."
  },
  {
    "objectID": "lectures/8.html#logistic-model",
    "href": "lectures/8.html#logistic-model",
    "title": "Multivariable  Regression",
    "section": "Logistic Model",
    "text": "Logistic Model\n\\[\nlo(Y=1) = \\beta_0 + \\beta_1X_1 + \\cdots + \\beta_p X_p\n\\]"
  },
  {
    "objectID": "lectures/8.html#regression-coefficients-beta",
    "href": "lectures/8.html#regression-coefficients-beta",
    "title": "Multivariable  Regression",
    "section": "Regression Coefficients \\(\\beta\\)",
    "text": "Regression Coefficients \\(\\beta\\)\nThe regression coefficients quantify how a specific predictor changes the odds of observing the first category of the outcome (\\(Y = 1\\))"
  },
  {
    "objectID": "lectures/8.html#estimating-beta",
    "href": "lectures/8.html#estimating-beta",
    "title": "Multivariable  Regression",
    "section": "Estimating \\(\\beta\\)",
    "text": "Estimating \\(\\beta\\)\nTo obtain the numerical value for \\(\\beta_j\\), denoted as \\(\\hat \\beta_j\\), we will be finding the values of \\(\\hat \\beta_j\\) that maximizes the likelihood function:\n\\[\nL(\\boldsymbol \\beta) = \\prod_{i=1}^n \\left(\\frac{e^{\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_p X_p}}{1 + e^{\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_p X_p}}\\right)^{Y_i}\\left(\\frac{1}{1 + e^{\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_p X_p}}\\right)^{1-Y_i}\n\\]\nThe likelihood function can be thought as the probability of observing the entire data set. Therefore, we want to choose the values the \\(\\beta_0\\) and \\(\\beta_1\\) that will result in the highest probability of observing the data."
  },
  {
    "objectID": "lectures/8.html#estimated-parameters",
    "href": "lectures/8.html#estimated-parameters",
    "title": "Multivariable  Regression",
    "section": "Estimated Parameters",
    "text": "Estimated Parameters\nThe values you obtain (\\(\\hat \\beta\\)) tell you the relationship between the a predictor variable and the log odds of observing the first category of the outcome \\(Y=1\\), adjusting for all the other covariates.\n\nExponentiating the estimate (\\(e^{\\hat \\beta}\\)) will give you the relationship between a predictor variable and the odds of observing the first category of the outcome \\(Y=1\\), adjusting for all the other covariates."
  },
  {
    "objectID": "lectures/8.html#interpreting-hat-beta_j",
    "href": "lectures/8.html#interpreting-hat-beta_j",
    "title": "Multivariable  Regression",
    "section": "Interpreting \\(\\hat \\beta_j\\)",
    "text": "Interpreting \\(\\hat \\beta_j\\)\nFor a continuous predictor variable:\nAs X increases by 1 unit, the odds of observing the first category (\\(Y = 1\\)) increases by a factor of \\(e^{\\hat\\beta_j}\\), adjusting for alll the other predictor variables.\nFor a categorical predictor variable (first dummy variable):\nThe odds of observing the first category (\\(Y = 1\\)) in the indicated category (\\(D=1\\)) is \\(e^{\\hat\\beta_j}\\) times higher/lower compared to the reference category (\\(D=0\\)), adjusting for alll the other predictor variables."
  },
  {
    "objectID": "lectures/8.html#fitting-a-glm-in-r",
    "href": "lectures/8.html#fitting-a-glm-in-r",
    "title": "Multivariable  Regression",
    "section": "Fitting a GLM in R",
    "text": "Fitting a GLM in R\nxglm &lt;- glm(Y ~ X1 + X2 + ... + Xp, \n           data = DATA,\n           family = binomial)\nxglm\n\nDATA: Name of the data frame\nY: Outcome Variable of Interest in the data frame DATA\nX1, X2, … , X_p : Predictor variables in the data frame DATA"
  },
  {
    "objectID": "lectures/8.html#modelling-body-mass-1",
    "href": "lectures/8.html#modelling-body-mass-1",
    "title": "Multivariable  Regression",
    "section": "Modelling Body Mass",
    "text": "Modelling Body Mass\n\\[\nbody\\_mass = \\beta_0 + \\boldsymbol \\beta_1 (species) + \\beta_2 (flipper\\_len)\n\\]"
  },
  {
    "objectID": "lectures/8.html#fitting-model",
    "href": "lectures/8.html#fitting-model",
    "title": "Multivariable  Regression",
    "section": "Fitting Model",
    "text": "Fitting Model\n\nxlm &lt;- lm(body_mass ~ species + flipper_len, \n          data = penguins)\nmodel_info(xlm)\n\n#&gt; Outcome Variable: body_mass\n\n\n#&gt; Numerical Predictors: \n#&gt;    flipper_len\n\n\n#&gt; Categorical Predictors: \n#&gt;   species: \n#&gt;      Adelie (Reference)  \n#&gt;      Chinstrap  \n#&gt;      Gentoo\n\n\n\nxlm\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ species + flipper_len, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt;      (Intercept)  speciesChinstrap     speciesGentoo       flipper_len  \n#&gt;         -4013.18           -205.38            284.52             40.61"
  },
  {
    "objectID": "lectures/8.html#estimated-model-1",
    "href": "lectures/8.html#estimated-model-1",
    "title": "Multivariable  Regression",
    "section": "Estimated Model",
    "text": "Estimated Model\n\\[\nbody\\_mass = -4013.18 -205.38 (Chinstrap)\\\\ + 284.52 (Gentoo) + 40.61 (flipper\\_len)\n\\]"
  },
  {
    "objectID": "lectures/8.html#intepreting-flipper_len-coefficient",
    "href": "lectures/8.html#intepreting-flipper_len-coefficient",
    "title": "Multivariable  Regression",
    "section": "Intepreting \\(flipper\\_len\\) coefficient",
    "text": "Intepreting \\(flipper\\_len\\) coefficient\n\\[\nbody\\_mass = -4013.18 -205.38 (Chinstrap)\\\\ + 284.52 (Gentoo) + 40.61 (flipper\\_len)\n\\]\nAs flipper length increased by 1 unit, body mass increases by an average of 40.61, adjusting for penguin species."
  },
  {
    "objectID": "lectures/8.html#intepreting-species-coefficient",
    "href": "lectures/8.html#intepreting-species-coefficient",
    "title": "Multivariable  Regression",
    "section": "Intepreting \\(species\\) coefficient",
    "text": "Intepreting \\(species\\) coefficient\n\\[\nbody\\_mass = -4013.18 -205.38 (Chinstrap)\\\\ + 284.52 (Gentoo) + 40.61 (flipper\\_len)\n\\]\n\nChinstrapGentoo\n\n\nOn average, the body mass of a Chinstrap species is 205.6 grams lower than an Adelie species, adjusting for flipper length.\n\n\nOn average, the body mass of a Gentoo species is 205.6 grams higher than an Adelie species, adjusting for flipper length."
  },
  {
    "objectID": "lectures/8.html#modelling-heart-disease",
    "href": "lectures/8.html#modelling-heart-disease",
    "title": "Multivariable  Regression",
    "section": "Modelling Heart Disease",
    "text": "Modelling Heart Disease\n\\[\nlo(disease) = \\beta_0 + \\boldsymbol \\beta_1 (thal)\\\\ + \\beta_2 (thalach)\n\\]"
  },
  {
    "objectID": "lectures/8.html#fitting-model-1",
    "href": "lectures/8.html#fitting-model-1",
    "title": "Multivariable  Regression",
    "section": "Fitting Model",
    "text": "Fitting Model\n\nxglm &lt;- lm(disease ~ thal + thalach, \n           data = heart_disease,\n           family = binomial)\nmodel_info(xglm)\n\n#&gt; Outcome Variable: disease\n\n\n#&gt; Numerical Predictors: \n#&gt;    thalach\n\n\n#&gt; Categorical Predictors: \n#&gt;   thal: \n#&gt;      Normal (Reference)  \n#&gt;      Fixed Defect  \n#&gt;      Reversible Defect\n\n\n\nxglm\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = disease ~ thal + thalach, data = heart_disease, \n#&gt;     family = binomial)\n#&gt; \n#&gt; Coefficients:\n#&gt;           (Intercept)       thalFixed Defect  thalReversible Defect  \n#&gt;              2.255233               0.305984               0.459645  \n#&gt;               thalach  \n#&gt;             -0.006621"
  },
  {
    "objectID": "lectures/8.html#estimated-model-2",
    "href": "lectures/8.html#estimated-model-2",
    "title": "Multivariable  Regression",
    "section": "Estimated Model",
    "text": "Estimated Model\n\\[\nlo(disease) = 2.255 + 0.305 (Fixed) + 0.46 (Reversible)\\\\ - 0.006 (thalach)\n\\]"
  },
  {
    "objectID": "lectures/8.html#intepreting-thalach-coefficient",
    "href": "lectures/8.html#intepreting-thalach-coefficient",
    "title": "Multivariable  Regression",
    "section": "Intepreting \\(thalach\\) coefficient",
    "text": "Intepreting \\(thalach\\) coefficient\n\\[\nlo(disease) = 2.255 + 0.305 (Fixed) + 0.46 (Reversible)\\\\ - 0.006 (thalach)\n\\]\n\nexp(-0.006)\n\n#&gt; [1] 0.994018\n\n\nAs maximum heart rate achieved increases by 1 unit, the odds of having heart disease decresease by a factor of 0.994, adjusting for thallium stress test results."
  },
  {
    "objectID": "lectures/8.html#intepreting-thal-coefficient",
    "href": "lectures/8.html#intepreting-thal-coefficient",
    "title": "Multivariable  Regression",
    "section": "Intepreting \\(thal\\) coefficient",
    "text": "Intepreting \\(thal\\) coefficient\n\\[\nlo(disease) = 2.255 + 0.305 (Fixed) + 0.46 (Reversible)\\\\ - 0.006 (thalach)\n\\]\n\nFixed DefectReversible Defect\n\n\n\nexp(0.305)\n\n#&gt; [1] 1.356625\n\n\nThe odds of having heart disease is 1.356 times higher in patients with fixed defects thallium stress results than patients with normal thallium stress results, adjusting for maximum heart rate achieved.\n\n\n\nexp(0.46)\n\n#&gt; [1] 1.584074\n\n\nThe odds of having heart disease is 1.584 times higher in patients with reversible defects thallium stress results than patients with normal thallium stress results, adjusting for maximum heart rate achieved."
  },
  {
    "objectID": "lectures/8.html#model-building-1",
    "href": "lectures/8.html#model-building-1",
    "title": "Multivariable  Regression",
    "section": "Model Building",
    "text": "Model Building\nModel Building is the process of obtaining a “final” model containing all the necessary predictors, and eliminating any that are not necessary."
  },
  {
    "objectID": "lectures/8.html#forward-selection",
    "href": "lectures/8.html#forward-selection",
    "title": "Multivariable  Regression",
    "section": "Forward Selection",
    "text": "Forward Selection\nBegin with the null model (\\(Y\\sim 1\\)) and add predictor variables until a final model is chosen."
  },
  {
    "objectID": "lectures/8.html#backward-selection",
    "href": "lectures/8.html#backward-selection",
    "title": "Multivariable  Regression",
    "section": "Backward Selection",
    "text": "Backward Selection\nBegin with the full model, and remove predictor variable until the final model is chosen."
  },
  {
    "objectID": "lectures/8.html#hybrid-selection",
    "href": "lectures/8.html#hybrid-selection",
    "title": "Multivariable  Regression",
    "section": "Hybrid Selection",
    "text": "Hybrid Selection\nA hybrid approach between the forward and backward building approach."
  },
  {
    "objectID": "lectures/8.html#about-model-selection",
    "href": "lectures/8.html#about-model-selection",
    "title": "Multivariable  Regression",
    "section": "About Model Selection",
    "text": "About Model Selection\nGenerally, it is not a good idea to conduct model selection. The predictor variables in your model should be guided by a literature review that illustrates important predictor variables in a model. Add predictor variables based on consultation with experts and a literature review."
  },
  {
    "objectID": "rcode/cat_stats.html",
    "href": "rcode/cat_stats.html",
    "title": "Categorical Data",
    "section": "",
    "text": "Recognize and work with categorical variables in R.\nSummarize categories using frequencies and proportions (a.k.a. relative frequency).\nCreate standard plots for categorical data: bar, stacked bar, pie, mosaic, and waffle.K\nRead and interpret cross‑tabulations (two‑way tables) with row/column/table proportions.\n\n\n\n\n\n\n\nTip\n\n\n\nUse the Copy button on each code chunk. Many chunks include a template version followed by a worked example."
  },
  {
    "objectID": "rcode/cat_stats.html#data-for-this-handout",
    "href": "rcode/cat_stats.html#data-for-this-handout",
    "title": "Categorical Data",
    "section": "2.1 Data for this handout",
    "text": "2.1 Data for this handout\nWe will use the Great American Coffee Taste Test survey data from TidyTuesday. Below is a subset of the data.\n\n\nCode\ncoffee &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-05-14/coffee_survey.csv\")"
  },
  {
    "objectID": "rcode/cat_stats.html#using-the-templates-what-to-change",
    "href": "rcode/cat_stats.html#using-the-templates-what-to-change",
    "title": "Categorical Data",
    "section": "2.2 Using the templates: what to change",
    "text": "2.2 Using the templates: what to change\nUse this legend whenever you see a Template code block.\n\nDATA → replace with your data frame/tibble name (e.g., coffee).\nVAR → replace with the single categorical variable you want (e.g., caffeine).\n\nIn ggplot(DATA, aes(x = VAR)), write ggplot(coffee, aes(x = caffeine)).\nIn functions that take a vector (e.g., cat_stats(DATA$VAR)), write cat_stats(coffee$caffeine).\n\nVAR1 and VAR2 → replace with the first and second categorical variables for two‑way tables/stacked bars (e.g., caffeine, taste).\nDF / wdf / df_pie / waffle_df → these are intermediate objects created in the chunk. You can keep the same names or rename them; if you rename, update the subsequent line that uses them.\ngroup = 1 → keep this as‑is for one‑variable proportion bar charts; it ensures correct normalization.\n\n\n2.2.1 Quick replace checklist\n\nSwap DATA for your data frame (usually coffee).\nSwap VAR for your categorical column (e.g., caffeine).\nFor two‑variable templates, set VAR1 and VAR2 (e.g., caffeine and taste).\nIf you change any intermediate object name (like df_pie), update it on the next line as well.\n\n\n\n2.2.2 Tiny example\nTemplate\n# Frequency bar (template)\n ggplot(DATA, aes(x = VAR)) +\n   geom_bar()\nFilled‑in\n# Frequency bar (coffee example)\n ggplot(coffee, aes(x = caffeine)) +\n   geom_bar()\nTemplate\n# Crosstab row proportions (template)\n cat_stats(VAR1, VAR2, prop = \"row\")\nFilled‑in\n# Crosstab row proportions (coffee example)\n cat_stats(coffee$caffeine, coffee$taste, prop = \"row\")"
  },
  {
    "objectID": "rcode/cat_stats.html#frequency-counts",
    "href": "rcode/cat_stats.html#frequency-counts",
    "title": "Categorical Data",
    "section": "4.1 Frequency (counts)",
    "text": "4.1 Frequency (counts)\nDefinition: number of observations in each category.\nTemplate:\n# Replace DATA$VAR with your variable\n# freq table (counts)\ncat_stats(DATA$VAR)\nExample: caffeine preference (coffee$caffeine)\n\ncat_stats(coffee$caffeine)\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;                  n   prop\n#&gt; Decaf          136 0.0347\n#&gt; Full caffeine 3576 0.9129\n#&gt; Half caff      205 0.0523\n#&gt; \n#&gt; Number of Missing: 125\n#&gt; Proportion of Missing: 0.0309252845126175\n#&gt; Row Variable: coffee$caffeine"
  },
  {
    "objectID": "rcode/cat_stats.html#proportion-relative-frequency",
    "href": "rcode/cat_stats.html#proportion-relative-frequency",
    "title": "Categorical Data",
    "section": "4.2 Proportion (relative frequency)",
    "text": "4.2 Proportion (relative frequency)\nDefinition: share of the sample in each category; comparable across sample sizes.\nTemplate:\n# proportions only\ncat_stats(DATA$VAR)\nExample:\n\ncat_stats(coffee$caffeine)\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;                  n   prop\n#&gt; Decaf          136 0.0347\n#&gt; Full caffeine 3576 0.9129\n#&gt; Half caff      205 0.0523\n#&gt; \n#&gt; Number of Missing: 125\n#&gt; Proportion of Missing: 0.0309252845126175\n#&gt; Row Variable: coffee$caffeine"
  },
  {
    "objectID": "rcode/cat_stats.html#crosstabulation-twoway-table",
    "href": "rcode/cat_stats.html#crosstabulation-twoway-table",
    "title": "Categorical Data",
    "section": "5.1 Cross‑tabulation (two‑way table)",
    "text": "5.1 Cross‑tabulation (two‑way table)\n\nRows: categories of one variable\nColumns: categories of the second variable\nReport counts or proportions by table, row, or column\n\nALL:\n\ncat_stats(coffee$caffeine, coffee$taste)\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;               No                              Yes                              \n#&gt; Decaf         \"26 / 0.0073 / 0.208 / 0.2653\"  \"99 / 0.0279 / 0.792 / 0.0287\"   \n#&gt; Full caffeine \"66 / 0.0186 / 0.0203 / 0.6735\" \"3178 / 0.8957 / 0.9797 / 0.9212\"\n#&gt; Half caff     \"6 / 0.0017 / 0.0335 / 0.0612\"  \"173 / 0.0488 / 0.9665 / 0.0501\" \n#&gt; Col Totals    \"98 / 0.0276\"                   \"3450 / 0.9724\"                  \n#&gt;               Row Totals     \n#&gt; Decaf         \"125 / 0.0352\" \n#&gt; Full caffeine \"3244 / 0.9143\"\n#&gt; Half caff     \"179 / 0.0505\" \n#&gt; Col Totals    \"Total: 3548\"  \n#&gt; \n#&gt; Cell Contents: n / tbl % / row % / col % \n#&gt; Col Totals Contents: n / row % \n#&gt; Row Totals Contents: n / col % \n#&gt; Column Variable: coffee$taste\n#&gt; Row Variable: coffee$caffeine\n\n\nTable proportions (each cell ÷ grand total):\n\ncat_stats(coffee$caffeine, coffee$taste, prop = \"table\")\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;               No            Yes             Row Totals     \n#&gt; Decaf         \"26 / 0.0073\" \"99 / 0.0279\"   \"125 / 0.0352\" \n#&gt; Full caffeine \"66 / 0.0186\" \"3178 / 0.8957\" \"3244 / 0.9143\"\n#&gt; Half caff     \"6 / 0.0017\"  \"173 / 0.0488\"  \"179 / 0.0505\" \n#&gt; Col Totals    \"98 / 0.0276\" \"3450 / 0.9724\" \"Total: 3548\"  \n#&gt; \n#&gt; Cell Contents: n / tbl % \n#&gt; Col Totals Contents: n / row % \n#&gt; Row Totals Contents: n / col % \n#&gt; Column Variable: coffee$taste\n#&gt; Row Variable: coffee$caffeine\n\n\nRow proportions (each cell ÷ its row total):\n\ncat_stats(coffee$caffeine, coffee$taste, prop = \"row\")\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;               No            Yes             Row Totals     \n#&gt; Decaf         \"26 / 0.208\"  \"99 / 0.792\"    \"125 / 0.0352\" \n#&gt; Full caffeine \"66 / 0.0203\" \"3178 / 0.9797\" \"3244 / 0.9143\"\n#&gt; Half caff     \"6 / 0.0335\"  \"173 / 0.9665\"  \"179 / 0.0505\" \n#&gt; Col Totals    \"98 / 0.0276\" \"3450 / 0.9724\" \"Total: 3548\"  \n#&gt; \n#&gt; Cell Contents: n / row % \n#&gt; Col Totals Contents: n / row % \n#&gt; Row Totals Contents: n / col % \n#&gt; Column Variable: coffee$taste\n#&gt; Row Variable: coffee$caffeine\n\n\nColumn proportions (each cell ÷ its column total):\n\ncat_stats(coffee$caffeine, coffee$taste, prop = \"col\")\n\n#&gt; Continguency Table \n#&gt;  \n#&gt;               No            Yes             Row Totals     \n#&gt; Decaf         \"26 / 0.2653\" \"99 / 0.0287\"   \"125 / 0.0352\" \n#&gt; Full caffeine \"66 / 0.6735\" \"3178 / 0.9212\" \"3244 / 0.9143\"\n#&gt; Half caff     \"6 / 0.0612\"  \"173 / 0.0501\"  \"179 / 0.0505\" \n#&gt; Col Totals    \"98 / 0.0276\" \"3450 / 0.9724\" \"Total: 3548\"  \n#&gt; \n#&gt; Cell Contents: n / col % \n#&gt; Col Totals Contents: n / row % \n#&gt; Row Totals Contents: n / col % \n#&gt; Column Variable: coffee$taste\n#&gt; Row Variable: coffee$caffeine"
  },
  {
    "objectID": "rcode/cat_stats.html#bar-plots",
    "href": "rcode/cat_stats.html#bar-plots",
    "title": "Categorical Data",
    "section": "6.1 Bar plots",
    "text": "6.1 Bar plots\n\n6.1.1 Frequency bar plot\nTemplate (frequency):\n# ggplot() + geom_bar() counts rows per category by default\nggplot(DATA, aes(x = VAR)) +\n  geom_bar()\nExample:\n\nggplot(coffee, aes(x = caffeine)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n6.1.2 Relative frequency bar plot\nTemplate (proportion):\n# after_stat(prop) computes proportions within the layer\nggplot(DATA, aes(x = VAR, y = after_stat(prop), group = 1)) +\n  geom_bar()\nExample:\n\nggplot(coffee, aes(x = caffeine, y = after_stat(prop), group = 1)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTip: Add labels/theme as needed: labs(x = \"\", y = \"Proportion\") + theme_minimal()"
  },
  {
    "objectID": "rcode/cat_stats.html#stacked-bar-plots",
    "href": "rcode/cat_stats.html#stacked-bar-plots",
    "title": "Categorical Data",
    "section": "6.2 Stacked bar plots",
    "text": "6.2 Stacked bar plots\nTemplate:\nggplot(DATA, aes(x = VAR1, fill = VAR2)) +\n  geom_bar()\nExample (stacked counts):\n\nggplot(coffee, aes(x = caffeine, fill = taste)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nExample (horizontal):\n\nggplot(coffee, aes(y = caffeine, fill = taste)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nTemplate (stacked proportions):\nggplot(DATA, aes(x = VAR1, fill = VAR2)) +\n  geom_bar(position = \"fill\") +\n  labs(y = \"Proportion\")"
  },
  {
    "objectID": "rcode/cat_stats.html#pie-charts-use-sparingly",
    "href": "rcode/cat_stats.html#pie-charts-use-sparingly",
    "title": "Categorical Data",
    "section": "6.3 Pie charts (use sparingly)",
    "text": "6.3 Pie charts (use sparingly)\nNote: Pie charts can be harder to compare precisely than bars. If you use them, label clearly.\nTemplate:\ndf_pie &lt;- cat_stats(DATA$VAR, tbl_df = TRUE)$table\nggplot(df_pie, aes(cat = Category, val = n, fill = Category)) +\n  geom_pie()\nExample:\n\ncoffee_pie &lt;- cat_stats(coffee$caffeine, tbl_df = TRUE)$table\nggplot(coffee_pie, aes(cat = Category, val = n, fill = Category)) +\n  geom_pie()"
  },
  {
    "objectID": "rcode/cat_stats.html#frequency-table",
    "href": "rcode/cat_stats.html#frequency-table",
    "title": "Categorical Data",
    "section": "7.1 Frequency table",
    "text": "7.1 Frequency table\ncat_stats(DATA$VAR)   \n\nDATA → the name of your dataset (e.g., coffee).\nVAR → a single categorical variable (e.g., caffeine)."
  },
  {
    "objectID": "rcode/cat_stats.html#proportions-only",
    "href": "rcode/cat_stats.html#proportions-only",
    "title": "Categorical Data",
    "section": "7.2 Proportions only",
    "text": "7.2 Proportions only\ncat_stats(DATA$VAR, prop_only = TRUE)\n\nDATA → the name of your dataset (e.g., coffee).\nVAR → a single categorical variable (e.g., caffeine)."
  },
  {
    "objectID": "rcode/cat_stats.html#bar-plot-frequency",
    "href": "rcode/cat_stats.html#bar-plot-frequency",
    "title": "Categorical Data",
    "section": "7.3 Bar Plot: Frequency",
    "text": "7.3 Bar Plot: Frequency\nggplot(DATA, aes(x = VAR)) + \n    geom_bar()\n\nDATA → the name of your dataset (e.g., coffee).\nVAR → a single categorical variable (e.g., caffeine)."
  },
  {
    "objectID": "rcode/cat_stats.html#bar-plot-proportion",
    "href": "rcode/cat_stats.html#bar-plot-proportion",
    "title": "Categorical Data",
    "section": "7.4 Bar Plot: Proportion",
    "text": "7.4 Bar Plot: Proportion\nggplot(DATA, aes(x = VAR, y = after_stat(prop), group = 1)) + \n    geom_bar()\n\nDATA → the name of your dataset (e.g., coffee).\nVAR → a single categorical variable (e.g., caffeine)."
  },
  {
    "objectID": "rcode/cat_stats.html#cross-tabulations-all",
    "href": "rcode/cat_stats.html#cross-tabulations-all",
    "title": "Categorical Data",
    "section": "7.5 Cross-tabulations (all)",
    "text": "7.5 Cross-tabulations (all)\ncat_stats(DATA$VAR1, DATA$VAR2)\n\nDATA → the name of your dataset (e.g., coffee).\nVAR1 → a single categorical variable (e.g., caffeine).\nVAR2 → a single categorical variable (e.g., taste)."
  },
  {
    "objectID": "rcode/cat_stats.html#cross-tabulations-proportions",
    "href": "rcode/cat_stats.html#cross-tabulations-proportions",
    "title": "Categorical Data",
    "section": "7.6 Cross-tabulations (proportions)",
    "text": "7.6 Cross-tabulations (proportions)\ncat_stats(DATA$VAR1, DATA$VAR2, prop = \"table\")\ncat_stats(DATA$VAR1, DATA$VAR2, prop = \"row\")\ncat_stats(DATA$VAR1, DATA$VAR2, prop = \"col\")\n\nDATA → the name of your dataset (e.g., coffee).\nVAR1 → a single categorical variable (e.g., caffeine).\nVAR2 → a single categorical variable (e.g., taste)."
  },
  {
    "objectID": "rcode/cat_stats.html#stacked-bar-counts",
    "href": "rcode/cat_stats.html#stacked-bar-counts",
    "title": "Categorical Data",
    "section": "7.7 Stacked bar (counts)",
    "text": "7.7 Stacked bar (counts)\nggplot(DATA, aes(x = VAR1, fill = VAR2)) + geom_bar()\n\nDATA → the name of your dataset (e.g., coffee).\nVAR1 → a single categorical variable (e.g., caffeine).\nVAR2 → a single categorical variable (e.g., taste)."
  },
  {
    "objectID": "rcode/cat_stats.html#stacked-bar-proportions",
    "href": "rcode/cat_stats.html#stacked-bar-proportions",
    "title": "Categorical Data",
    "section": "7.8 Stacked bar (proportions)",
    "text": "7.8 Stacked bar (proportions)\nggplot(DATA, aes(x = VAR1, fill = VAR2)) +\n  geom_bar(position = \"fill\") + labs(y = \"Proportion\")\n\nDATA → the name of your dataset (e.g., coffee).\nVAR1 → a single categorical variable (e.g., caffeine).\nVAR2 → a single categorical variable (e.g., taste)."
  },
  {
    "objectID": "rcode/cat_stats.html#pie-chart",
    "href": "rcode/cat_stats.html#pie-chart",
    "title": "Categorical Data",
    "section": "7.9 Pie Chart",
    "text": "7.9 Pie Chart\ndf_pie &lt;- cat_stats(DATA$VAR, tbl_df = TRUE)$table\nggplot(df_pie, aes(cat = Category, val = n, fill = Category)) + \n    geom_pie()\n\nDATA → the name of your dataset (e.g., coffee).\nVAR → a single categorical variable (e.g., caffeine)."
  },
  {
    "objectID": "rcode/num_stats.html",
    "href": "rcode/num_stats.html",
    "title": "Numerical Data",
    "section": "",
    "text": "Identify numerical (quantitative) variables and read their distributions.\nCompute core descriptive statistics: min, Q1, median (Q2), mean, Q3, max, IQR, variance, sd.\nMake and interpret histograms, box plots, dot plots, and scatter plots.\nRecognize outliers and what they may indicate.\nUse copy‑paste templates and replace placeholders with your data/columns.\n\n\n\n\n\n\n\nTip\n\n\n\nUse the Copy button on each code chunk. Most topics have a template first and a worked example using the Mr. Trash Wheel dataset."
  },
  {
    "objectID": "rcode/num_stats.html#data-for-this-handout",
    "href": "rcode/num_stats.html#data-for-this-handout",
    "title": "Numerical Data",
    "section": "2.1 Data for this handout",
    "text": "2.1 Data for this handout\nWe will use the Mr. Trash Wheel dataset from TidyTuesday.\n\n\nCode\ntrashwheel &lt;- read_csv(\n  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-03-05/trashwheel.csv\")"
  },
  {
    "objectID": "rcode/num_stats.html#using-the-templates-what-to-change",
    "href": "rcode/num_stats.html#using-the-templates-what-to-change",
    "title": "Numerical Data",
    "section": "2.2 Using the templates: what to change",
    "text": "2.2 Using the templates: what to change\nUse this legend whenever you see a Template code block.\n\nDATA → replace with your data frame/tibble name (e.g., trashwheel).\nVAR → replace with the single numerical variable you want (e.g., PlasticBottles).\n\nIn ggplot(DATA, aes(x = VAR)), write ggplot(trashwheel, aes(x = PlasticBottles)).\nIn functions that take a vector (e.g., mean(DATA$VAR)), write mean(trashwheel$PlasticBottles).\n\nVAR1 and VAR2 → replace with the x and y variables for scatter plots (e.g., PlasticBottles, PlasticBags).\nbins = X, binwidth = X → choose a sensible number/width for your data scale.\n\n\n2.2.1 Quick replace checklist\n\nSwap DATA for your data frame (usually trashwheel).\nSwap VAR for your numerical column (e.g., PlasticBottles).\nFor scatter plots, set VAR1 and VAR2.\nAdjust bins or binwidth for histograms/dot plots to show the distribution clearly."
  },
  {
    "objectID": "rcode/num_stats.html#what-is-numerical-data",
    "href": "rcode/num_stats.html#what-is-numerical-data",
    "title": "Numerical Data",
    "section": "3.1 What is numerical data?",
    "text": "3.1 What is numerical data?\nNumerical (quantitative) variables record numbers for which arithmetic makes sense (e.g., items collected, weights, costs).\nExample (first few values):\n\nhead(trashwheel$PlasticBottles)\n\n#&gt; [1] 1450 1120 2450 2380  980 1430"
  },
  {
    "objectID": "rcode/num_stats.html#central-tendency",
    "href": "rcode/num_stats.html#central-tendency",
    "title": "Numerical Data",
    "section": "3.2 Central tendency",
    "text": "3.2 Central tendency\nCentral tendency summarizes a distribution with a representative value (mean or median).\n\nMedian (Q2) is the 50th percentile: half the data lie below it.\nMean is the arithmetic average: sensitive to outliers/skew."
  },
  {
    "objectID": "rcode/num_stats.html#variation-spread",
    "href": "rcode/num_stats.html#variation-spread",
    "title": "Numerical Data",
    "section": "3.3 Variation (spread)",
    "text": "3.3 Variation (spread)\nVariation describes how far data tend to fall from the center.\n\nRange = max − min\nIQR = Q3 − Q1 (middle 50%)\nVariance/SD measure average squared/root‑mean‑squared distance from the mean."
  },
  {
    "objectID": "rcode/num_stats.html#summary-statistics",
    "href": "rcode/num_stats.html#summary-statistics",
    "title": "Numerical Data",
    "section": "3.4 Summary Statistics",
    "text": "3.4 Summary Statistics\nTemplate:\nnum_stats(DATA$VAR)           # five-number summary + mean\nExample:\n\nnum_stats(trashwheel$PlasticBottles)\n\n#&gt;   min   q25     mean median  q75  max       sd     var    iqr missing\n#&gt; 1   0 987.5 2219.331   1900 2900 9830 1650.449 2723984 1912.5       1\n\n\nAlternative:\nsummary(DATA$VAR)           # five-number summary + mean"
  },
  {
    "objectID": "rcode/num_stats.html#mean-median-variance-sd",
    "href": "rcode/num_stats.html#mean-median-variance-sd",
    "title": "Numerical Data",
    "section": "3.5 Mean, median, variance, sd",
    "text": "3.5 Mean, median, variance, sd\nTemplate:\nmean(DATA$VAR)\nmedian(DATA$VAR)\nvar(DATA$VAR)\nsd(DATA$VAR)\nWith Missing Data:\nmean(DATA$VAR, na.rm = TRUE)\nmedian(DATA$VAR, na.rm = TRUE)\nvar(DATA$VAR, na.rm = TRUE)\nsd(DATA$VAR, na.rm = TRUE)\nExample:\n\nmean(trashwheel$PlasticBottles, na.rm = TRUE)\n\n#&gt; [1] 2219.331\n\nmedian(trashwheel$PlasticBottles, na.rm = TRUE)\n\n#&gt; [1] 1900\n\nvar(trashwheel$PlasticBottles, na.rm = TRUE)\n\n#&gt; [1] 2723984\n\nsd(trashwheel$PlasticBottles, na.rm = TRUE)\n\n#&gt; [1] 1650.449"
  },
  {
    "objectID": "rcode/num_stats.html#quantiles",
    "href": "rcode/num_stats.html#quantiles",
    "title": "Numerical Data",
    "section": "3.6 Quantiles",
    "text": "3.6 Quantiles\nTemplate:\nquantile(DATA$VAR, probs = c(0.25, 0.5, 0.75))\nExample:\n\nquantile(trashwheel$PlasticBottles, \n         probs = c(0.25, 0.5, 0.75), \n         na.rm = TRUE)\n\n#&gt;    25%    50%    75% \n#&gt;  987.5 1900.0 2900.0"
  },
  {
    "objectID": "rcode/num_stats.html#histograms",
    "href": "rcode/num_stats.html#histograms",
    "title": "Numerical Data",
    "section": "4.1 Histograms",
    "text": "4.1 Histograms\nA histogram shows the distribution by binning values and counting how many fall in each bin.\nTemplate (Frequency-based):\nggplot(DATA, aes(x = VAR)) +\n  geom_histogram(bins = X) \nExample:\n\nggplot(trashwheel, aes(x = PlasticBottles)) +\n  geom_histogram(bins = 20)\n\n#&gt; Warning: Removed 1 row containing non-finite outside the scale range\n#&gt; (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nTemplate (Density-based):\nggplot(DATA, aes(x = VAR, y = after_stat(density))) +\n  geom_histogram(bins = X)\nExample:\n\nggplot(trashwheel, aes(x = PlasticBottles, y = after_stat(density))) +\n  geom_histogram(bins = 20)\n\n#&gt; Warning: Removed 1 row containing non-finite outside the scale range\n#&gt; (`stat_bin()`)."
  },
  {
    "objectID": "rcode/num_stats.html#density-plot",
    "href": "rcode/num_stats.html#density-plot",
    "title": "Numerical Data",
    "section": "4.2 Density plot",
    "text": "4.2 Density plot\nA density plot is a way to visualize the distribution of a continuous variable — it shows where data values are concentrated (dense) and where they are sparse.\nTemplate:\nggplot(DATA, aes(x = VAR)) +\n  geom_density()\nExample:\n\nggplot(trashwheel, aes(x = PlasticBottles)) +\n  geom_density()\n\n#&gt; Warning: Removed 1 row containing non-finite outside the scale range\n#&gt; (`stat_density()`)."
  },
  {
    "objectID": "rcode/num_stats.html#box-plots",
    "href": "rcode/num_stats.html#box-plots",
    "title": "Numerical Data",
    "section": "4.3 Box plots",
    "text": "4.3 Box plots\nA box plot summarizes median, quartiles, and potential outliers.\nTemplate:\nggplot(DATA, aes(VAR)) +\n  geom_boxplot()\nExample:\n\nggplot(trashwheel, aes(PlasticBottles)) +\n  geom_boxplot() \n\n#&gt; Warning: Removed 1 row containing non-finite outside the scale range\n#&gt; (`stat_boxplot()`)."
  },
  {
    "objectID": "rcode/num_stats.html#dot-plots",
    "href": "rcode/num_stats.html#dot-plots",
    "title": "Numerical Data",
    "section": "4.4 Dot plots",
    "text": "4.4 Dot plots\nA dot plot stacks dots within bins to show distribution.\nTemplate:\nggplot(DATA, aes(x = VAR)) +\n  geom_dotplot(binwidth = X)  # choose a sensible binwidth\nExample:\n\nggplot(trashwheel, aes(x = PlasticBottles)) +\n  geom_dotplot(binwidth = 100)\n\n#&gt; Warning: Removed 1 row containing missing values or values outside the scale range\n#&gt; (`stat_bindot()`)."
  },
  {
    "objectID": "rcode/num_stats.html#scatter-plots-two-numerical-variables",
    "href": "rcode/num_stats.html#scatter-plots-two-numerical-variables",
    "title": "Numerical Data",
    "section": "4.5 Scatter plots (two numerical variables)",
    "text": "4.5 Scatter plots (two numerical variables)\nA scatter plot reveals association, trend direction, and form.\nTemplate:\nggplot(DATA, aes(x = VAR1, y = VAR2)) +\n  geom_point()\nExample:\n\nggplot(trashwheel, aes(x = PlasticBottles, y = PlasticBags)) +\n  geom_point()\n\n#&gt; Warning: Removed 1 row containing missing values or values outside the scale range\n#&gt; (`geom_point()`).\n\n\n\n\n\n\n\n\n\nAdd a trend line (optional):\n\nggplot(trashwheel, aes(x = PlasticBottles, y = PlasticBags)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = TRUE)\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n#&gt; Warning: Removed 1 row containing non-finite outside the scale range\n#&gt; (`stat_smooth()`).\n\n\n#&gt; Warning: Removed 1 row containing missing values or values outside the scale range\n#&gt; (`geom_point()`)."
  },
  {
    "objectID": "rcode/num_stats.html#basic-statistics",
    "href": "rcode/num_stats.html#basic-statistics",
    "title": "Numerical Data",
    "section": "6.1 Basic Statistics",
    "text": "6.1 Basic Statistics\n# Mean / Median / Var / SD\nmean(DATA$VAR)\nmedian(DATA$VAR)\nvar(DATA$VAR)\nsd(DATA$VAR)\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles).\n\n# Quantiles\nquantile(DATA$VAR, probs = c(0.25, 0.5, 0.75))\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles)."
  },
  {
    "objectID": "rcode/num_stats.html#summary-statistics-csucistats",
    "href": "rcode/num_stats.html#summary-statistics-csucistats",
    "title": "Numerical Data",
    "section": "6.2 Summary Statistics (csucistats)",
    "text": "6.2 Summary Statistics (csucistats)\nnum_stats(DATA$VAR)\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles)."
  },
  {
    "objectID": "rcode/num_stats.html#histogram-frequency-based",
    "href": "rcode/num_stats.html#histogram-frequency-based",
    "title": "Numerical Data",
    "section": "6.3 Histogram (Frequency-based)",
    "text": "6.3 Histogram (Frequency-based)\nggplot(DATA, aes(VAR)) + \n    geom_histogram()\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles)."
  },
  {
    "objectID": "rcode/num_stats.html#histogram-density-based",
    "href": "rcode/num_stats.html#histogram-density-based",
    "title": "Numerical Data",
    "section": "6.4 Histogram (density-based)",
    "text": "6.4 Histogram (density-based)\nggplot(DATA, aes(x = VAR, y = after_stat(density))) +\n  geom_histogram()\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles)."
  },
  {
    "objectID": "rcode/num_stats.html#histogram-frequency-based-with-bins",
    "href": "rcode/num_stats.html#histogram-frequency-based-with-bins",
    "title": "Numerical Data",
    "section": "6.5 Histogram (Frequency-based) with bins",
    "text": "6.5 Histogram (Frequency-based) with bins\nggplot(DATA, aes(VAR)) + \n    geom_histogram(bins = X)\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles).\nX → the number of bins (e.g., 15-30)"
  },
  {
    "objectID": "rcode/num_stats.html#histogram-density-based-with-bins",
    "href": "rcode/num_stats.html#histogram-density-based-with-bins",
    "title": "Numerical Data",
    "section": "6.6 Histogram (Density-based) with bins",
    "text": "6.6 Histogram (Density-based) with bins\nggplot(DATA, aes(x = VAR, y = after_stat(density))) +\n    geom_histogram(bins = X)\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles).\nX → the number of bins (e.g., 15-30)"
  },
  {
    "objectID": "rcode/num_stats.html#density-plot-1",
    "href": "rcode/num_stats.html#density-plot-1",
    "title": "Numerical Data",
    "section": "6.7 Density Plot",
    "text": "6.7 Density Plot\nggplot(DATA, aes(VAR)) + \n    geom_density()\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles)."
  },
  {
    "objectID": "rcode/num_stats.html#box-plot",
    "href": "rcode/num_stats.html#box-plot",
    "title": "Numerical Data",
    "section": "6.8 Box plot",
    "text": "6.8 Box plot\nggplot(DATA, aes(VAR)) + \n    geom_boxplot() \n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles)."
  },
  {
    "objectID": "rcode/num_stats.html#dot-plot",
    "href": "rcode/num_stats.html#dot-plot",
    "title": "Numerical Data",
    "section": "6.9 Dot plot",
    "text": "6.9 Dot plot\nggplot(DATA, aes(x = VAR)) + \n    geom_dotplot(binwidth = X)\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR → a single categorical variable (e.g., PlasticBottles)."
  },
  {
    "objectID": "rcode/num_stats.html#scatter-plot",
    "href": "rcode/num_stats.html#scatter-plot",
    "title": "Numerical Data",
    "section": "6.10 Scatter Plot",
    "text": "6.10 Scatter Plot\nggplot(DATA, aes(x = VAR1, y = VAR2)) + \n    geom_point()\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR1 → a single categorical variable (e.g., PlasticBottles).\nVAR2 → a single categorical variable (e.g., PlasticBags)."
  },
  {
    "objectID": "rcode/num_stats.html#scatter-plot-trend-line",
    "href": "rcode/num_stats.html#scatter-plot-trend-line",
    "title": "Numerical Data",
    "section": "6.11 Scatter Plot + trend line",
    "text": "6.11 Scatter Plot + trend line\nggplot(DATA, aes(x = VAR1, y = VAR2)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = TRUE)\n\nDATA → the name of your dataset (e.g., trashwheel).\nVAR1 → a single categorical variable (e.g., PlasticBottles).\nVAR2 → a single categorical variable (e.g., PlasticBags)."
  },
  {
    "objectID": "rcode/regression.html",
    "href": "rcode/regression.html",
    "title": "Linear Regression Models",
    "section": "",
    "text": "Copy the following code and put it in a code cell in Google Colab. Only do this if you are using a completely new notebook.\n# This code will load the R packages we will use\ninstall.packages(c(\"rcistats\", \"taylor\",,\n                 repos = c(\"https://inqs909.r-universe.dev\", \n                           \"https://cloud.r-project.org\"))\n\n# Uncomment and run for themes\n# csucistats::install_themes()\n# library(ThemePark)\n# library(ggthemes)\n\nlibrary(rcistats)\nlibrary(tidyverse)\nlibrary(taylor)\n\n\n\n\nDATA → your data frame/tibble (e.g., penguins)\nY → the outcome variable (e.g., body_mass_g)\nX, X1, X2, …, Xp → predictor variables (e.g flipper_length_mm, species)\nFor categorical predictors: ensure the predictor is a factor (use factor(X) if needed)."
  },
  {
    "objectID": "rcode/regression.html#google-colab",
    "href": "rcode/regression.html#google-colab",
    "title": "Linear Regression Models",
    "section": "",
    "text": "Copy the following code and put it in a code cell in Google Colab. Only do this if you are using a completely new notebook.\n# This code will load the R packages we will use\ninstall.packages(c(\"rcistats\", \"taylor\",,\n                 repos = c(\"https://inqs909.r-universe.dev\", \n                           \"https://cloud.r-project.org\"))\n\n# Uncomment and run for themes\n# csucistats::install_themes()\n# library(ThemePark)\n# library(ggthemes)\n\nlibrary(rcistats)\nlibrary(tidyverse)\nlibrary(taylor)"
  },
  {
    "objectID": "rcode/regression.html#using-the-templates-what-to-change",
    "href": "rcode/regression.html#using-the-templates-what-to-change",
    "title": "Linear Regression Models",
    "section": "",
    "text": "DATA → your data frame/tibble (e.g., penguins)\nY → the outcome variable (e.g., body_mass_g)\nX, X1, X2, …, Xp → predictor variables (e.g flipper_length_mm, species)\nFor categorical predictors: ensure the predictor is a factor (use factor(X) if needed)."
  },
  {
    "objectID": "rcode/regression.html#scatter-plot-continuous-vs-continuous",
    "href": "rcode/regression.html#scatter-plot-continuous-vs-continuous",
    "title": "Linear Regression Models",
    "section": "2.1 Scatter Plot (Continuous vs Continuous)",
    "text": "2.1 Scatter Plot (Continuous vs Continuous)\nA scatter plot reveals association, trend direction, and form.\nTemplate:\nggplot(DATA, aes(x = VAR1, y = VAR2)) +\n  geom_point()\nExample:\n\nggplot(penguins, aes(x = flipper_len, y = body_mass)) +\n  geom_point()"
  },
  {
    "objectID": "rcode/regression.html#multi-densigy-plot-continuous-vs-categorical",
    "href": "rcode/regression.html#multi-densigy-plot-continuous-vs-categorical",
    "title": "Linear Regression Models",
    "section": "2.2 Multi Densigy Plot (Continuous vs Categorical)",
    "text": "2.2 Multi Densigy Plot (Continuous vs Categorical)\nA density plot is a way to visualize the distribution of a continuous variable — it shows where data values are concentrated (dense) and where they are sparse.\n\nColorFillGroup\n\n\nTemplate:\nggplot(DATA, aes(x = NUM, color = CAT)) +\n  geom_density()\nExample:\n\nggplot(penguins, aes(x = flipper_len, color = species)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nTemplate:\nggplot(DATA, aes(x = NUM, fill = CAT)) +\n  geom_density()\nExample:\n\nggplot(penguins, aes(x = flipper_len, group = species)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nTemplate:\nggplot(DATA, aes(x = NUM, group = CAT)) +\n  geom_density()\nExample:\n\nggplot(penguins, aes(x = flipper_len, group = species)) +\n  geom_density()"
  },
  {
    "objectID": "rcode/regression.html#multi-box-plot-continuous-vs-categorical",
    "href": "rcode/regression.html#multi-box-plot-continuous-vs-categorical",
    "title": "Linear Regression Models",
    "section": "2.3 Multi Box Plot (Continuous vs Categorical)",
    "text": "2.3 Multi Box Plot (Continuous vs Categorical)\nA box plot summarizes median, quartiles, and potential outliers.\nTemplate:\nggplot(DATA, aes(x = NUM, y = CAT)) +\n  geom_boxplot()\nExample:\n\nggplot(penguins, aes(x = flipper_len, y = species)) +\n  geom_boxplot()"
  },
  {
    "objectID": "rcode/regression.html#explaining-variation",
    "href": "rcode/regression.html#explaining-variation",
    "title": "Linear Regression Models",
    "section": "3.1 Explaining variation",
    "text": "3.1 Explaining variation\nThis is the process of trying to reduce unexplained variation in an outcome by using informative predictors — think getting it less wrong with an educated guess.\n\nggplot(penguins, aes(body_mass)) +\n  geom_density()\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nIf we know some information, we can get less wrong over time.\n\n# Same variable, grouped by a category (species)\nggplot(penguins, aes(body_mass, fill = species)) +\n  geom_density(alpha = .5)"
  },
  {
    "objectID": "rcode/regression.html#a-simple-model-intercept-only",
    "href": "rcode/regression.html#a-simple-model-intercept-only",
    "title": "Linear Regression Models",
    "section": "3.2 A simple model (intercept-only)",
    "text": "3.2 A simple model (intercept-only)\nWe believe the outcome (\\(Y\\)) is generated by an unknown data generated process (\\(DGP_1\\)): \\(Y \\sim DGP_1\\). A minimal model says all outcomes are generated from a number (labeled as \\(\\beta_0\\)) plus or minus some error (\\(\\varepsilon\\)):\n\\[ Y = \\beta_0 + \\varepsilon \\]\nThis is known as a simple model and the errors are simulated by a different DGP \\(\\varepsilon \\sim DGP_2\\). The simple model is unknown, so we construct and estimated simple model for our best guess on how the data is generated:\n\\[\n\\hat Y = \\hat\\beta_0\n\\]\nThe carats above the letters are known as hats, which means best guess.\n\n\n\n\n\n\nTip\n\n\n\nObserved vs. estimated:\n\nObserved \\(Y = \\beta_0 + \\varepsilon\\)\nEstimated \\(\\hat Y = \\hat\\beta_0\\)\n\n\n\n\n3.2.1 Fitting Simple Model\nTemplate:\nlm(Y ~ 1, data = DATA)\n\nDATA → your data (e.g., penguins).\n\nY → the outcome variable (e.g., body_mass_g).\n\nExample:\n\n# Fit the null (intercept-only) model\nm0 &lt;- lm(body_mass ~ 1, data = penguins)\nm0\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ 1, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)  \n#&gt;        4207"
  },
  {
    "objectID": "rcode/regression.html#linear-regression-model-with-one-predictor",
    "href": "rcode/regression.html#linear-regression-model-with-one-predictor",
    "title": "Linear Regression Models",
    "section": "3.3 Linear regression model with one predictor",
    "text": "3.3 Linear regression model with one predictor\nModel form:\n\\[\nY = \\beta_0 + \\beta_1 X + \\varepsilon, \\quad \\hat Y = \\hat\\beta_0 + \\hat\\beta_1 X.\n\\]\n\n# Scatter plot\nggplot(penguins, aes(flipper_len, body_mass)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n# Add a least-squares line\nggplot(penguins, aes(flipper_len, body_mass)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\n\n\n\n\n# Fit the model\nm1 &lt;- lm(body_mass ~ flipper_len, data = penguins)\nm1\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ flipper_len, data = penguins)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)  flipper_len  \n#&gt;    -5872.09        50.15\n\n\nTemplate:\nlm(Y ~ X, data = DATA)"
  },
  {
    "objectID": "rcode/regression.html#general-idea",
    "href": "rcode/regression.html#general-idea",
    "title": "Linear Regression Models",
    "section": "4.1 General idea",
    "text": "4.1 General idea\n\nSuppose we have a categorical variable with C categories.\n\nWe create C − 1 dummy variables, each taking value:\n\n1 if the observation belongs to that category\n\n0 otherwise\n\n\nThe category without a dummy variable becomes the reference (baseline) group.\n\nExample: Penguin species:\nThe species variable has 3 categories: Adelie, Chinstrap, Gentoo.\nWe create two dummy variables:\n\n\\(D_1\\): 1 if Chinstrap, 0 otherwise\n\n\\(D_2\\): 1 if Gentoo, 0 otherwise\n\nAdelie is the reference (when both \\(D_1 = 0, D_2 = 0\\))\n\n\n\n\nSpecies\n\\(D_1\\) (Chinstrap)\n\\(D_2\\) (Gentoo)\n\n\n\n\nAdelie\n0\n0\n\n\nChinstrap\n1\n0\n\n\nGentoo\n0\n1"
  },
  {
    "objectID": "rcode/regression.html#regression-model-with-dummy-variables",
    "href": "rcode/regression.html#regression-model-with-dummy-variables",
    "title": "Linear Regression Models",
    "section": "4.2 Regression model with dummy variables",
    "text": "4.2 Regression model with dummy variables\nIf we model penguin body mass (\\(Y\\)) with species:\n\\[\n\\hat Y_i = \\beta_0 + \\beta_1 D_{1i} + \\beta_2 D_{2i}\n\\]\n\n\\(\\beta_0\\): mean of Adelie (reference group)\n\n\\(\\beta_1\\): difference in mean body mass between Chinstrap and Adelie\n\n\\(\\beta_2\\): difference in mean body mass between Gentoo and Adelie\n\nPredictions:\n- Adelie: \\(\\hat Y = \\beta_0\\)\n- Chinstrap: \\(\\hat Y = \\beta_0 + \\beta_1\\)\n- Gentoo: \\(\\hat Y = \\beta_0 + \\beta_2\\)"
  },
  {
    "objectID": "rcode/regression.html#r-implementation",
    "href": "rcode/regression.html#r-implementation",
    "title": "Linear Regression Models",
    "section": "4.3 R Implementation",
    "text": "4.3 R Implementation\nR automatically creates dummy variables when you use a factor in lm().\nThe first level of the factor is used as the reference group (by default).\n\n# Fit model with species (factor) as predictor\nm &lt;- lm(body_mass ~ species, data = penguins)\nsummary(m)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = body_mass ~ species, data = penguins)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -1142.44  -342.44   -33.09   307.56  1207.56 \n#&gt; \n#&gt; Coefficients:\n#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)       3706.16      38.14  97.184   &lt;2e-16 ***\n#&gt; speciesChinstrap    26.92      67.65   0.398    0.691    \n#&gt; speciesGentoo     1386.27      56.91  24.359   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 460.8 on 330 degrees of freedom\n#&gt; Multiple R-squared:  0.6745, Adjusted R-squared:  0.6725 \n#&gt; F-statistic: 341.9 on 2 and 330 DF,  p-value: &lt; 2.2e-16\n\n\nTemplates:\nlm(Y ~ X, data = DATA)           # if X is already a factor\nlm(Y ~ factor(X), data = DATA)   # force X to be treated as factor"
  },
  {
    "objectID": "rcode/regression.html#group-statistics",
    "href": "rcode/regression.html#group-statistics",
    "title": "Linear Regression Models",
    "section": "4.4 Group Statistics",
    "text": "4.4 Group Statistics\nThe function num_by_cat_stats() quickly computes descriptive statistics of a numerical variable grouped by a categorical variable.\nTemplate:\nnum_by_cat_stats(DATA, NUM, CAT)\n\nDATA: the data frame (e.g., penguins)\nNUM: the numerical variable you want to summarize (e.g., body_mass_g)\nCAT: the categorical variable that defines groups (e.g., species)\n\nExample:\n\nnum_by_cat_stats(penguins, body_mass, species)\n\n#&gt;   Categories  min    q25     mean median  q75  max      sd      var   iqr\n#&gt; 1     Adelie 2850 3362.5 3706.164   3700 4000 4775 458.620 210332.4 637.5\n#&gt; 2  Chinstrap 2700 3487.5 3733.088   3700 3950 4800 384.335 147713.5 462.5\n#&gt; 3     Gentoo 3950 4700.0 5092.437   5050 5500 6300 501.476 251478.3 800.0\n#&gt;   missing\n#&gt; 1       0\n#&gt; 2       0\n#&gt; 3       0"
  },
  {
    "objectID": "rcode/regression.html#adjusted-r2",
    "href": "rcode/regression.html#adjusted-r2",
    "title": "Linear Regression Models",
    "section": "7.1 Adjusted \\(R^2\\)",
    "text": "7.1 Adjusted \\(R^2\\)\n\\[R^2 = 1 - \\frac{\\text{Var(resid)}}{\\text{Var}(Y)}, \\quad\nR^2_{adj} = 1 - \\Big(\\frac{\\text{Var(resid)}}{\\text{Var}(Y)}\\Big) \\cdot \\frac{n-1}{n-k-1}\\]\n\nm &lt;- lm(danceability ~ mode_name + valence + energy, data = taylor_album_songs)\nar2(m)\n\n#&gt; [1] 0.09148268"
  },
  {
    "objectID": "rcode/regression.html#simple-model",
    "href": "rcode/regression.html#simple-model",
    "title": "Linear Regression Models",
    "section": "8.1 Simple Model",
    "text": "8.1 Simple Model\nlm(Y ~ 1, data = DATA)\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)"
  },
  {
    "objectID": "rcode/regression.html#simple-linear-regression",
    "href": "rcode/regression.html#simple-linear-regression",
    "title": "Linear Regression Models",
    "section": "8.2 Simple linear regression",
    "text": "8.2 Simple linear regression\nlm(Y ~ X, data = DATA)\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX → predictor variables (e.g flipper_length_mm)"
  },
  {
    "objectID": "rcode/regression.html#slr-categorical-predictor",
    "href": "rcode/regression.html#slr-categorical-predictor",
    "title": "Linear Regression Models",
    "section": "8.3 SLR: Categorical predictor",
    "text": "8.3 SLR: Categorical predictor\nlm(Y ~ X, data = DATA) \n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX → predictor variables (e.g species)"
  },
  {
    "objectID": "rcode/regression.html#slr-categorical-predictor-create-factor",
    "href": "rcode/regression.html#slr-categorical-predictor-create-factor",
    "title": "Linear Regression Models",
    "section": "8.4 SLR: Categorical predictor (Create Factor)",
    "text": "8.4 SLR: Categorical predictor (Create Factor)\nlm(Y ~ factor(X), data = DATA)   # coerce X to factor\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX → predictor variables (e.g species)"
  },
  {
    "objectID": "rcode/regression.html#numerical-statistics-by-categories",
    "href": "rcode/regression.html#numerical-statistics-by-categories",
    "title": "Linear Regression Models",
    "section": "8.5 Numerical Statistics by Categories",
    "text": "8.5 Numerical Statistics by Categories\nnum_by_cat_stats(DATA, NUM, CAT)\n\nDATA: the data frame (e.g., penguins)\nNUM: the numerical variable you want to summarize (e.g., body_mass)\nCAT: the categorical variable that defines groups (e.g., species)"
  },
  {
    "objectID": "rcode/regression.html#correlation",
    "href": "rcode/regression.html#correlation",
    "title": "Linear Regression Models",
    "section": "8.6 Correlation",
    "text": "8.6 Correlation\ncor(DATA$Y, DATA$X, use = \"complete.obs\")\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX → predictor variables (e.g flipper_len)"
  },
  {
    "objectID": "rcode/regression.html#r2",
    "href": "rcode/regression.html#r2",
    "title": "Linear Regression Models",
    "section": "8.7 \\(R^2\\)",
    "text": "8.7 \\(R^2\\)\nm &lt;- lm(Y ~ X, data = DATA)\nr2(m)\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX → predictor variables (e.g flipper_len)"
  },
  {
    "objectID": "rcode/regression.html#multiple-linear-regression",
    "href": "rcode/regression.html#multiple-linear-regression",
    "title": "Linear Regression Models",
    "section": "8.8 Multiple linear regression",
    "text": "8.8 Multiple linear regression\nlm(Y ~ X1 + X2 + ... + Xp, data = DATA)\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX1, X2, …, Xp → predictor variables (e.g flipper_len, species)"
  },
  {
    "objectID": "rcode/regression.html#adjusted-r2-1",
    "href": "rcode/regression.html#adjusted-r2-1",
    "title": "Linear Regression Models",
    "section": "8.9 Adjusted \\(R^2\\)",
    "text": "8.9 Adjusted \\(R^2\\)\n# Adjusted R^2\nm &lt;- lm(Y ~ X1 + X2 + ... + Xp, data = DATA)\nar2(m)\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX1, X2, …, Xp → predictor variables (e.g flipper_len, species)"
  },
  {
    "objectID": "rcode/regression.html#prediction-slr",
    "href": "rcode/regression.html#prediction-slr",
    "title": "Linear Regression Models",
    "section": "8.10 Prediction: SLR",
    "text": "8.10 Prediction: SLR\nm &lt;- lm(Y ~ X, data = DATA)\nndf &lt;- data.frame(X = VAL)\npredict(m, newdata = ndf)\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX → predictor variables (e.g flipper_len)"
  },
  {
    "objectID": "rcode/regression.html#prediction-mlr",
    "href": "rcode/regression.html#prediction-mlr",
    "title": "Linear Regression Models",
    "section": "8.11 Prediction: MLR",
    "text": "8.11 Prediction: MLR\nm &lt;- lm(Y ~ X1 + X2 + ... + Xp, data = DATA)\nndf &lt;- data.frame(X1 = VAL1, X2 = VAL2, ..., Xp = VALp)\npredict(m, newdata = ndf)\n\nDATA → your data frame (e.g., penguins)\nY → the outcome variable (e.g., body_mass)\nX1, X2, …, Xp → predictor variables (e.g flipper_len, species)\nVAL1, VAL2, …, VALp → predictor values (e.g 150, \"Gentoo\")"
  },
  {
    "objectID": "rcode/regression.html#scatter-plot",
    "href": "rcode/regression.html#scatter-plot",
    "title": "Linear Regression Models",
    "section": "8.12 Scatter Plot",
    "text": "8.12 Scatter Plot\nggplot(DATA, aes(x = VAR1, y = VAR2)) + \n    geom_point()\n\nDATA → the name of your dataset (e.g., penguins).\nVAR1 → a single numerical variable (e.g., body_mass).\nVAR2 → a single numerical variable (e.g., flipper_len)."
  },
  {
    "objectID": "rcode/regression.html#scatter-plot-trend-line",
    "href": "rcode/regression.html#scatter-plot-trend-line",
    "title": "Linear Regression Models",
    "section": "8.13 Scatter Plot + trend line",
    "text": "8.13 Scatter Plot + trend line\nggplot(DATA, aes(x = VAR1, y = VAR2)) + \n    geom_point() + \n    geom_smooth(method = \"lm\", se = TRUE)\n\nDATA → the name of your dataset (e.g., penguins).\nVAR1 → a single numerical variable (e.g., body_mass).\nVAR2 → a single numerical variable (e.g., flipper_len)."
  },
  {
    "objectID": "rcode/regression.html#multiple-density-plot-continous-vs-categorical",
    "href": "rcode/regression.html#multiple-density-plot-continous-vs-categorical",
    "title": "Linear Regression Models",
    "section": "8.14 Multiple Density Plot (Continous vs Categorical)",
    "text": "8.14 Multiple Density Plot (Continous vs Categorical)\nggplot(DATA, aes(x = NUM, color = CAT)) + \n    geom_density() \n\nDATA → the name of your dataset (e.g., penguins).\nNUM → a single numerical variable (e.g., body_mass).\nCAT → a single categorical variable (e.g., species)."
  },
  {
    "objectID": "rcode/regression.html#multiple-box-plots-continous-vs-categorical",
    "href": "rcode/regression.html#multiple-box-plots-continous-vs-categorical",
    "title": "Linear Regression Models",
    "section": "8.15 Multiple Box Plots (Continous vs Categorical)",
    "text": "8.15 Multiple Box Plots (Continous vs Categorical)\nggplot(DATA, aes(x = NUM, y = CAT)) + \n    geom_boxplot() \n\nDATA → the name of your dataset (e.g., penguins).\nNUM → a single numerical variable (e.g., body_mass).\nCAT → a single categorical variable (e.g., species)."
  }
]